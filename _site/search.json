[
  {
    "objectID": "posts/scrap_learning/index.html",
    "href": "posts/scrap_learning/index.html",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "En Recursos Humanos una de las obsesiones principales es medir el Retorno de la Inversión (ROI) de la capacitación, lo cual, si bien es posible de medir, requiere un esfuerzo enorme. En cambio, poder medir cuánta plata se desperdicia por la no aplicación del conocimiento adquirido en las capacitaciones es mucho más sencillo, y también es una métrica muy valiosa para utilizar.\nEl Scrap Learning es una forma de medir cuántos de los conocimientos adquiridos en las capacitaciones no se trasladan al trabajo, lo cual es mucho más sencillo y tan valioso de medir como el ROI.\nLa investigación indica el promedio de mercado de Scrap Learning entre las empresas que no lo miden es del 45%. Es decir que si tenemos un presupuesto anual de $ 500.000 para las capacitaciones, $ 225.000 es dinero mal invertido y por ende, la capacitación deja de ser una inversión para convertirse en un costo.\n\n\n\nUna forma sencilla de medir el Scrap Learning es preguntando a los participantes de un curso cuánto del conocimiento adquirido se aplicará al trabajo. El porcentaje de contenido que NO aplicarán al trabajo forma parte del Scrap Learning.\nEjemplo: Le preguntamos a un participante cuántos de los conocimientos adquiridos en una capacitación estima aplicar en sus tareas cotidianas. Si dice que piensa aplicar el 60% del contenido a su trabajo, el scrap learning es del 40%.\n\n\n\n\n\n\n\n\nUna de las primeras cosas que debemos hacer los Responsables de Capacitación y Desarrollo es aclarar para qué sirve una capacitación. ¿Cuántas veces hemos escuchado “Fulano está desmotivado… mándalo a hacer un curso”? ¿O cuántas veces acordamos con un empleado conflictivo o de bajo desempeño pagarle un posgrado? ¿Hemos enviado alguna vez a una persona a una capacitación sobre una tecnología que no usamos en nuestras empresas?\nIncluso de parte de los colaboradores hay una percepción imprecisa sobre la capacitación. Una encuesta que hicimos a empleados de nuestros clientes, frente a la pregunta “¿Qué beneficio que no tenés hoy, te gustaría tener?”, prácticamente 1 de cada 4 respuestas estaba relacionada con capacitación o beneficios en posgrados.\nEsto deja entrever, que lo primero que necesitamos hacer desde Capacitación y Desarrollo es “re-educar” a la empresa sobre cuál es la utilidad y finalidad de las capacitaciones y en qué casos usarlas.\n\n\n\n“Una capacitación efectiva mejorará el desempeño del participante y del área donde trabaja.”\nPor el contrario, cuando las capacitaciones no son efectivas y el scrap learning es alto, la performance del colaborador y del sector no mejorarán aún cuando asistan al mejor curso del mundo. Una actividad de formación debe aportar valor al participante y a su área. Para ello, hay 3 preguntas claves para hacer:\n\n¿Cuánto espera que su performance mejore relacionado con el contexto del curso relacionado con todos los factores, incluido el programa de desarrollo?\n¿Cuánto de esa mejora se la atribuiría exclusivamente a la capacitación?\n¿Cuánto tiempo dedica realmente a tareas relacionadas con el programa de desarrollo?\n\n\n\n\nEn nuestra experiencia, existen varias causas que provocan el scrap learning. La tabla a continuación resume algunos de los principales factores que inciden en esta métrica.\nEn la primera columna hay causas que están bajo el control del área de Capacitación y Desarrollo, como ser la calidad del instructor, del material, la alineación con las necesidades del negocio, entre otras. Pero sin dudas uno de los factores más importantes e influyentes es la involucración de los Jefes y Gerencias en el proceso de Capacitación.\n\n\n\n\n\nComo en muchas cosas de Recursos Humanos, la clave son los líderes. ¿De qué manera pueden influir en la reducción del scrap learning? Básicamente hay 5 factores preponderantes:\n\nElegir a la persona idónea para asistir a un curso y que sea el indicado para adquirir y aplicar nuevos conocimientos a sus tareas.\nDefinir las expectativas con el participante antes del inicio de la capacitación.\nInvolucrarse con la aplicación de los conocimientos nuevos una vez terminada la actividad de formación.\nRealizar un seguimiento de las expectativas fijadas antes de la capacitación.\nProveer recursos necesarios para dar soporte al rendimiento.\n\nOtro dato clave es que, si el conocimiento adquirido durante una capacitación no se aplica dentro de las 6 semanas posteriores a la capacitación, ningún conocimiento adquirido en esa actividad se trasladará al trabajo.\n\n\n\n\nMedir la información de todos los cursos planificados de la misma manera, usando las mismas herramientas y preguntas. Esto nos brindará consistencia para comparar los resultados y realizar estimaciones más sofisticadas.\nCrear una hoja de cálculo en Excel, o un tablero con métricas con algunas métricas clave: scrap learning, desempeño, e inversión por ejemplo para cada curso.\nCrear una serie de reglas que brinden un marco para el proceso de mejora continuo, por ejemplo:\n\nPara el top 5 de los cursos, no realizar cambios, reinvertir en ellos, continuar desarrollándolos, y si ocurrieran cambios que sean en pos de conseguir una reducción de costos siempre y cuando la calidad no se vea afectada, y de esa manera mejorar el ROI.\nPara el 10% más bajo de los cursos, eliminar cualquier curso que no esté alineado con los objetivos de la empresa. Para aquellos que están alineados con las necesidades de negocio, reinvertir para revisarlos.\nPara el 85% de los cursos que están en el medio, continuar realizándolos, pero buscando opciones que permitan reducir el scrap y maximizar los beneficios.\n\n\n\n\n\nEl Retorno de Inversión (ROI) de una capacitación es una medida compleja de estimar, en cambio, el Scrap Learning es más sencillo de medir y de solucionar.\nMantener un bajo nivel de Scrap Learning, no sólo se materializa en resultados en la organización, sino que además aumenta la confianza sobre el proceso de capacitación generando un “círculo virtuoso” que contribuye a mantenerlo en ese estado.\nÉsta es una métrica poderosa para evaluar la efectividad de las capacitaciones que realizamos dentro de una organización. Como Responsables de Capacitación y Desarrollo, es nuestro deber asegurar la calidad de la capacitación (del instructor, del contenido, y la alineación con necesidades de negocio), pero los jefes juegan un rol clave a la hora de trasladar los conocimientos de la formación al trabajo cotidiano. De esto surge la necesidad de trabajar codo a codo con las áreas para involucrar a sus jefaturas y gerencias, dándoles el soporte necesario para mejorar el impacto de las capacitaciones, mejorar el rendimiento de sus equipos e incrementar sus propios resultados e imagen."
  },
  {
    "objectID": "posts/scrap_learning/index.html#para-muestra-basta-con-un-botón",
    "href": "posts/scrap_learning/index.html#para-muestra-basta-con-un-botón",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "Una forma sencilla de medir el Scrap Learning es preguntando a los participantes de un curso cuánto del conocimiento adquirido se aplicará al trabajo. El porcentaje de contenido que NO aplicarán al trabajo forma parte del Scrap Learning.\nEjemplo: Le preguntamos a un participante cuántos de los conocimientos adquiridos en una capacitación estima aplicar en sus tareas cotidianas. Si dice que piensa aplicar el 60% del contenido a su trabajo, el scrap learning es del 40%."
  },
  {
    "objectID": "posts/scrap_learning/index.html#capacitar-sobre-capacitar",
    "href": "posts/scrap_learning/index.html#capacitar-sobre-capacitar",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "Una de las primeras cosas que debemos hacer los Responsables de Capacitación y Desarrollo es aclarar para qué sirve una capacitación. ¿Cuántas veces hemos escuchado “Fulano está desmotivado… mándalo a hacer un curso”? ¿O cuántas veces acordamos con un empleado conflictivo o de bajo desempeño pagarle un posgrado? ¿Hemos enviado alguna vez a una persona a una capacitación sobre una tecnología que no usamos en nuestras empresas?\nIncluso de parte de los colaboradores hay una percepción imprecisa sobre la capacitación. Una encuesta que hicimos a empleados de nuestros clientes, frente a la pregunta “¿Qué beneficio que no tenés hoy, te gustaría tener?”, prácticamente 1 de cada 4 respuestas estaba relacionada con capacitación o beneficios en posgrados.\nEsto deja entrever, que lo primero que necesitamos hacer desde Capacitación y Desarrollo es “re-educar” a la empresa sobre cuál es la utilidad y finalidad de las capacitaciones y en qué casos usarlas."
  },
  {
    "objectID": "posts/scrap_learning/index.html#las-preguntas-clave",
    "href": "posts/scrap_learning/index.html#las-preguntas-clave",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "“Una capacitación efectiva mejorará el desempeño del participante y del área donde trabaja.”\nPor el contrario, cuando las capacitaciones no son efectivas y el scrap learning es alto, la performance del colaborador y del sector no mejorarán aún cuando asistan al mejor curso del mundo. Una actividad de formación debe aportar valor al participante y a su área. Para ello, hay 3 preguntas claves para hacer:\n\n¿Cuánto espera que su performance mejore relacionado con el contexto del curso relacionado con todos los factores, incluido el programa de desarrollo?\n¿Cuánto de esa mejora se la atribuiría exclusivamente a la capacitación?\n¿Cuánto tiempo dedica realmente a tareas relacionadas con el programa de desarrollo?"
  },
  {
    "objectID": "posts/scrap_learning/index.html#factores-a-tener-en-cuenta",
    "href": "posts/scrap_learning/index.html#factores-a-tener-en-cuenta",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "En nuestra experiencia, existen varias causas que provocan el scrap learning. La tabla a continuación resume algunos de los principales factores que inciden en esta métrica.\nEn la primera columna hay causas que están bajo el control del área de Capacitación y Desarrollo, como ser la calidad del instructor, del material, la alineación con las necesidades del negocio, entre otras. Pero sin dudas uno de los factores más importantes e influyentes es la involucración de los Jefes y Gerencias en el proceso de Capacitación.\n\n\n\n\n\nComo en muchas cosas de Recursos Humanos, la clave son los líderes. ¿De qué manera pueden influir en la reducción del scrap learning? Básicamente hay 5 factores preponderantes:\n\nElegir a la persona idónea para asistir a un curso y que sea el indicado para adquirir y aplicar nuevos conocimientos a sus tareas.\nDefinir las expectativas con el participante antes del inicio de la capacitación.\nInvolucrarse con la aplicación de los conocimientos nuevos una vez terminada la actividad de formación.\nRealizar un seguimiento de las expectativas fijadas antes de la capacitación.\nProveer recursos necesarios para dar soporte al rendimiento.\n\nOtro dato clave es que, si el conocimiento adquirido durante una capacitación no se aplica dentro de las 6 semanas posteriores a la capacitación, ningún conocimiento adquirido en esa actividad se trasladará al trabajo."
  },
  {
    "objectID": "posts/scrap_learning/index.html#recomendaciones",
    "href": "posts/scrap_learning/index.html#recomendaciones",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "Medir la información de todos los cursos planificados de la misma manera, usando las mismas herramientas y preguntas. Esto nos brindará consistencia para comparar los resultados y realizar estimaciones más sofisticadas.\nCrear una hoja de cálculo en Excel, o un tablero con métricas con algunas métricas clave: scrap learning, desempeño, e inversión por ejemplo para cada curso.\nCrear una serie de reglas que brinden un marco para el proceso de mejora continuo, por ejemplo:\n\nPara el top 5 de los cursos, no realizar cambios, reinvertir en ellos, continuar desarrollándolos, y si ocurrieran cambios que sean en pos de conseguir una reducción de costos siempre y cuando la calidad no se vea afectada, y de esa manera mejorar el ROI.\nPara el 10% más bajo de los cursos, eliminar cualquier curso que no esté alineado con los objetivos de la empresa. Para aquellos que están alineados con las necesidades de negocio, reinvertir para revisarlos.\nPara el 85% de los cursos que están en el medio, continuar realizándolos, pero buscando opciones que permitan reducir el scrap y maximizar los beneficios."
  },
  {
    "objectID": "posts/scrap_learning/index.html#conclusión",
    "href": "posts/scrap_learning/index.html#conclusión",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "El Retorno de Inversión (ROI) de una capacitación es una medida compleja de estimar, en cambio, el Scrap Learning es más sencillo de medir y de solucionar.\nMantener un bajo nivel de Scrap Learning, no sólo se materializa en resultados en la organización, sino que además aumenta la confianza sobre el proceso de capacitación generando un “círculo virtuoso” que contribuye a mantenerlo en ese estado.\nÉsta es una métrica poderosa para evaluar la efectividad de las capacitaciones que realizamos dentro de una organización. Como Responsables de Capacitación y Desarrollo, es nuestro deber asegurar la calidad de la capacitación (del instructor, del contenido, y la alineación con necesidades de negocio), pero los jefes juegan un rol clave a la hora de trasladar los conocimientos de la formación al trabajo cotidiano. De esto surge la necesidad de trabajar codo a codo con las áreas para involucrar a sus jefaturas y gerencias, dándoles el soporte necesario para mejorar el impacto de las capacitaciones, mejorar el rendimiento de sus equipos e incrementar sus propios resultados e imagen."
  },
  {
    "objectID": "posts/maximo-valor-fila/index.html",
    "href": "posts/maximo-valor-fila/index.html",
    "title": "Extraer el máximo valor de una fila",
    "section": "",
    "text": "En este pequeño tutorial (por eso el tag de tipito, o sea un tip chiquito), voy a contar cómo resolví un problema que me encontré en el trabajo y me trajo más de un dolor de cabeza.\nEstaba trabajando con una tabla en la que tenía varios cursos, con sus fechas de finalización, y para el análisis que estaba haciendo necesitaba extraer la fecha del último curso completado por cada persona (el valor más alto).\nEl problema es que cuando estaba ejecutando la función max() en vez de obtener el valor más alto de la fila, obtenía el valor más alto de la columna. Así que en este post vamos a ver la función rowwise() que permite resolver este inconveniente.\nEn este ejemplo vamos a reemplazar las fechas por un número, que a los fines prácticos plantea el mismo problema.\n\n\nPrimero carguemos la librería dplyr que además de contener la función rowwise() nos permite trabajar con el pipe %&gt;% para simplificar la lectura del código. Luego crearemos un data frame de ejemplo con datos inventados\n\n# En caso que no esté instalado 'dplyr' primero ejecutar install.package(\"dplyr\")\nlibrary(dplyr)\n\n# Creación de datos\nejemplo &lt;- data.frame(\"Nombre\" = c(\"Carla\", \"Daniela\", \"Sergio\", \"Yanel\"),\n                    \"Valor A\" = c(12, 8, 300, 17),\n                    \"Valor B\" = c(5, 21, 18, 400),\n                    \"Valor C\" = c(39, 200, 26, 64), \n                    \"Valor D\" = c(100, 43, 86, 12))\n\nAhora veamos cómo quedan los datos\n\n# Ejecutar para ver el contenido del data frame\nejemplo\n\n   Nombre Valor.A Valor.B Valor.C Valor.D\n1   Carla      12       5      39     100\n2 Daniela       8      21     200      43\n3  Sergio     300      18      26      86\n4   Yanel      17     400      64      12\n\n\nLo que necesitaba lograr (en un archivo con muchas más columnas que en este ejemplo) es poner en una columna nueva el valor más alto para cada persona. Entonces para Carla esperaba que el resultado fuera 100, para Daniela 200 y así sucesivamente.\nInstintivamente lo que hice para intentar obtener el valor más alto de cada caso, fue usar dentro de una función mutate() (para crear una columna nueva) la función max() a un vector con los nombres de las 4 columnas.\n\nejemplo %&gt;% \n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n   Nombre Valor.A Valor.B Valor.C Valor.D Valor Máximo\n1   Carla      12       5      39     100          400\n2 Daniela       8      21     200      43          400\n3  Sergio     300      18      26      86          400\n4   Yanel      17     400      64      12          400\n\n\nClaramente no es es el resultado que esperaba, así que mi reacción fue la siguiente:\n\n\n\n\nEl problema del enfoque anterior es que la función max() busca entre todos los datos que le pasamos, las 4 columnas con los valores numéricos, y lo que nos devuelve el valor máximo de entre todas las celdas. Este es un claro ejemplo de que R está haciendo lo que le dijimos que haga, no lo que estábamos queriendo que haga.\nPara resolver esto, antes de crear una columna nueva con mutate(), usamos la función rowwise().\n\nejemplo %&gt;% \n  rowwise() %&gt;%   # Con esta función indicamos que queremos los cálculos sobre las filas\n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n# A tibble: 4 × 6\n# Rowwise: \n  Nombre  Valor.A Valor.B Valor.C Valor.D `Valor Máximo`\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1 Carla        12       5      39     100            100\n2 Daniela       8      21     200      43            200\n3 Sergio      300      18      26      86            300\n4 Yanel        17     400      64      12            400\n\n\nLa función rowwise() lo que nos permite hacer es cálculos sobre las filas. Dependiendo el caso de uso se puede usar esta alternativa, o “pivotear” o transponer la tabla para que las columnas queden dentro de las filas y luego combinar group_by() y summarise() para calcular el valor máximo para cada persona.\nEste enfoque sería así:\n\nlibrary(tidyr)\n\nejemplo_largo &lt;- ejemplo %&gt;% \n  # Pivoteamos los datos a un formato 'largo'\n  pivot_longer(cols = c(\"Valor.A\", \"Valor.B\", \"Valor.C\", \"Valor.D\"), \n               names_to = \"Variable\",\n               values_to = \"Valor\")\n\n# Veamos el dataset transformado\nejemplo_largo\n\n# A tibble: 16 × 3\n   Nombre  Variable Valor\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n 1 Carla   Valor.A     12\n 2 Carla   Valor.B      5\n 3 Carla   Valor.C     39\n 4 Carla   Valor.D    100\n 5 Daniela Valor.A      8\n 6 Daniela Valor.B     21\n 7 Daniela Valor.C    200\n 8 Daniela Valor.D     43\n 9 Sergio  Valor.A    300\n10 Sergio  Valor.B     18\n11 Sergio  Valor.C     26\n12 Sergio  Valor.D     86\n13 Yanel   Valor.A     17\n14 Yanel   Valor.B    400\n15 Yanel   Valor.C     64\n16 Yanel   Valor.D     12\n\n# Ahora hacemos el cálculo combinando 'group_by' y 'summarise'\nejemplo_largo %&gt;% \n  group_by(Nombre) %&gt;% \n  summarise(\"Valor Máximo\" = max(Valor))\n\n# A tibble: 4 × 2\n  Nombre  `Valor Máximo`\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Carla              100\n2 Daniela            200\n3 Sergio             300\n4 Yanel              400\n\n\nClaramente este es otro enfoque, y depende de la necesidad es una opción válida. Pero en este caso particular necesitaba mantener una fila para cada persona porque después iba a exportar esta tabla a un archivo que luego es cargado en un tablero en Power BI.\nAsí que, una vez logrado mi objetivo, me dispuse a celebrar como corresponde."
  },
  {
    "objectID": "posts/maximo-valor-fila/index.html#datos-de-ejemplo",
    "href": "posts/maximo-valor-fila/index.html#datos-de-ejemplo",
    "title": "Extraer el máximo valor de una fila",
    "section": "",
    "text": "Primero carguemos la librería dplyr que además de contener la función rowwise() nos permite trabajar con el pipe %&gt;% para simplificar la lectura del código. Luego crearemos un data frame de ejemplo con datos inventados\n\n# En caso que no esté instalado 'dplyr' primero ejecutar install.package(\"dplyr\")\nlibrary(dplyr)\n\n# Creación de datos\nejemplo &lt;- data.frame(\"Nombre\" = c(\"Carla\", \"Daniela\", \"Sergio\", \"Yanel\"),\n                    \"Valor A\" = c(12, 8, 300, 17),\n                    \"Valor B\" = c(5, 21, 18, 400),\n                    \"Valor C\" = c(39, 200, 26, 64), \n                    \"Valor D\" = c(100, 43, 86, 12))\n\nAhora veamos cómo quedan los datos\n\n# Ejecutar para ver el contenido del data frame\nejemplo\n\n   Nombre Valor.A Valor.B Valor.C Valor.D\n1   Carla      12       5      39     100\n2 Daniela       8      21     200      43\n3  Sergio     300      18      26      86\n4   Yanel      17     400      64      12\n\n\nLo que necesitaba lograr (en un archivo con muchas más columnas que en este ejemplo) es poner en una columna nueva el valor más alto para cada persona. Entonces para Carla esperaba que el resultado fuera 100, para Daniela 200 y así sucesivamente.\nInstintivamente lo que hice para intentar obtener el valor más alto de cada caso, fue usar dentro de una función mutate() (para crear una columna nueva) la función max() a un vector con los nombres de las 4 columnas.\n\nejemplo %&gt;% \n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n   Nombre Valor.A Valor.B Valor.C Valor.D Valor Máximo\n1   Carla      12       5      39     100          400\n2 Daniela       8      21     200      43          400\n3  Sergio     300      18      26      86          400\n4   Yanel      17     400      64      12          400\n\n\nClaramente no es es el resultado que esperaba, así que mi reacción fue la siguiente:"
  },
  {
    "objectID": "posts/maximo-valor-fila/index.html#la-solución",
    "href": "posts/maximo-valor-fila/index.html#la-solución",
    "title": "Extraer el máximo valor de una fila",
    "section": "",
    "text": "El problema del enfoque anterior es que la función max() busca entre todos los datos que le pasamos, las 4 columnas con los valores numéricos, y lo que nos devuelve el valor máximo de entre todas las celdas. Este es un claro ejemplo de que R está haciendo lo que le dijimos que haga, no lo que estábamos queriendo que haga.\nPara resolver esto, antes de crear una columna nueva con mutate(), usamos la función rowwise().\n\nejemplo %&gt;% \n  rowwise() %&gt;%   # Con esta función indicamos que queremos los cálculos sobre las filas\n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n# A tibble: 4 × 6\n# Rowwise: \n  Nombre  Valor.A Valor.B Valor.C Valor.D `Valor Máximo`\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1 Carla        12       5      39     100            100\n2 Daniela       8      21     200      43            200\n3 Sergio      300      18      26      86            300\n4 Yanel        17     400      64      12            400\n\n\nLa función rowwise() lo que nos permite hacer es cálculos sobre las filas. Dependiendo el caso de uso se puede usar esta alternativa, o “pivotear” o transponer la tabla para que las columnas queden dentro de las filas y luego combinar group_by() y summarise() para calcular el valor máximo para cada persona.\nEste enfoque sería así:\n\nlibrary(tidyr)\n\nejemplo_largo &lt;- ejemplo %&gt;% \n  # Pivoteamos los datos a un formato 'largo'\n  pivot_longer(cols = c(\"Valor.A\", \"Valor.B\", \"Valor.C\", \"Valor.D\"), \n               names_to = \"Variable\",\n               values_to = \"Valor\")\n\n# Veamos el dataset transformado\nejemplo_largo\n\n# A tibble: 16 × 3\n   Nombre  Variable Valor\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n 1 Carla   Valor.A     12\n 2 Carla   Valor.B      5\n 3 Carla   Valor.C     39\n 4 Carla   Valor.D    100\n 5 Daniela Valor.A      8\n 6 Daniela Valor.B     21\n 7 Daniela Valor.C    200\n 8 Daniela Valor.D     43\n 9 Sergio  Valor.A    300\n10 Sergio  Valor.B     18\n11 Sergio  Valor.C     26\n12 Sergio  Valor.D     86\n13 Yanel   Valor.A     17\n14 Yanel   Valor.B    400\n15 Yanel   Valor.C     64\n16 Yanel   Valor.D     12\n\n# Ahora hacemos el cálculo combinando 'group_by' y 'summarise'\nejemplo_largo %&gt;% \n  group_by(Nombre) %&gt;% \n  summarise(\"Valor Máximo\" = max(Valor))\n\n# A tibble: 4 × 2\n  Nombre  `Valor Máximo`\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Carla              100\n2 Daniela            200\n3 Sergio             300\n4 Yanel              400\n\n\nClaramente este es otro enfoque, y depende de la necesidad es una opción válida. Pero en este caso particular necesitaba mantener una fila para cada persona porque después iba a exportar esta tabla a un archivo que luego es cargado en un tablero en Power BI.\nAsí que, una vez logrado mi objetivo, me dispuse a celebrar como corresponde."
  },
  {
    "objectID": "posts/haciendo-boludeces-en-r/index.html",
    "href": "posts/haciendo-boludeces-en-r/index.html",
    "title": "Haciendo pavadas en R",
    "section": "",
    "text": "Una vez vi una charla de Ryan Timpe, un Data Scientist de Lego, que en una charla en la RStudio Conference contaba cómo a veces hacía proyectos que fueran divertidos para aprender nuevos skills de análisis de datos. En su charla cuenta por ejemplo, que hizo un análisis de los diálogos de la serie The Golden Girls usando técnicas de text mining para detectar cuáles eran las palabras más frecuentes, entonces cada vez que una protagonista decía esa palabra ellos hacían un fondo blanco de lo que estuvieran tomando.\nEste post va de lo mismo. Yo quería aprender a usar imágenes en mis visualizaciones, así nació este proyecto en el que usé imágenes de personas con rasgos “similares” a los míos e incluir las fotos en un gráfico de dispersión.\nEsto que es una boludez implicó:\n\nCrear un formulario en Google Forms\nLevantar los datos de las respuestas\nProcesar los resultados\nE incluir visualizaciones usando las imágenes de las personas.\n\nEste tipo de proyectos lo que permite es que el esfuerzo que dedicás a aprender no se sienta pesado, y que te da una motivación extra para buscar la solución para lograr el resultado."
  },
  {
    "objectID": "posts/haciendo-boludeces-en-r/index.html#génesis-de-la-idea-k-nn",
    "href": "posts/haciendo-boludeces-en-r/index.html#génesis-de-la-idea-k-nn",
    "title": "Haciendo pavadas en R",
    "section": "Génesis de la idea: k-nn",
    "text": "Génesis de la idea: k-nn\nLa idea de este análisis surgió un día después de hacer una explicación sobre un método de clustering llamado k-nn. Los métodos de clustering son técnicas de ciencia de datos que permiten hallar grupos entre los datos (llamados clusters en la jerga).\nEl método k-nn, k nearest neighbors o de vecinos más cercanos lo que hace es asignar a cada individuo a un cluster en función de las características de sus “vecinos”. Es decir que determina a qué grupo pertenece cada caso en función a qué casos se parece más.\nLa forma que se me ocurrió para explicar esto de manera visual fue con este dibujo que hice en Paint:\n\nLa explicación es que yo, dentro de ese conjunto de datos, estoy más cerca de pertenecer al cluster del Mono Burgos y de Nicolás del Caño, más que del cluster de Keanu Reeves, Jeff Bridges y Brad Pitt.\nY después tuve una idea. ¿Y si hago esto con datos?"
  },
  {
    "objectID": "posts/haciendo-boludeces-en-r/index.html#cargando-los-datos-y-preparándolos",
    "href": "posts/haciendo-boludeces-en-r/index.html#cargando-los-datos-y-preparándolos",
    "title": "Haciendo pavadas en R",
    "section": "Cargando los datos y preparándolos",
    "text": "Cargando los datos y preparándolos\nEmpecemos cargando las librerías y los datos directamente desde un repositorio:\n\n# Paquetes\nlibrary(tidyverse) # Cargar, limpiar y preparar datos\nlibrary(ggimage)   # Para usar imágenes en las visualizaciones\n\n# Datos\nclones &lt;- read_delim(\"https://raw.githubusercontent.com/chechoid/silliest-use-of-r/main/source.csv\", delim = \";\")\n\n\ncomentarios &lt;- clones %&gt;% \n  select(comentarios = `Poné lo que quieras... parecidos, chistes, comentarios, etc...`) %&gt;% \n  filter(!is.na(comentarios))\n\n# Exploremos los datos\nhead(clones)\n\n# A tibble: 6 × 24\n  `Marca temporal`    `Facha de Keanu` `Copadez de Keanu` `Facha de Russell`\n  &lt;dttm&gt;                         &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 2021-06-23 12:37:28               10                 10                  7\n2 2021-06-23 12:39:12                4                 10                  5\n3 2021-06-23 12:42:21                8                  9                  8\n4 2021-06-23 12:43:24               10                 10                  1\n5 2021-06-23 12:45:03               10                  8                  4\n6 2021-06-23 12:45:12                5                  9                  1\n# ℹ 20 more variables: `Copadez de Russell` &lt;dbl&gt;, `Facha de Nico` &lt;dbl&gt;,\n#   `Copadez de Nico` &lt;dbl&gt;, `Facha de Roberto` &lt;dbl&gt;,\n#   `Copadez de Roberto` &lt;dbl&gt;, `Facha de Jeff` &lt;dbl&gt;, `Copadez de Jeff` &lt;dbl&gt;,\n#   `Facha de Brad` &lt;dbl&gt;, `Copadez de Brad` &lt;dbl&gt;, `Facha del Mono` &lt;dbl&gt;,\n#   `Copadez del Mono` &lt;dbl&gt;, `Facha de Sergio` &lt;dbl&gt;,\n#   `Copadez de Sergio` &lt;dbl&gt;, `Facha de Ricky` &lt;dbl&gt;,\n#   `Copadez de Ricky` &lt;dbl&gt;, `Facha de Ben` &lt;dbl&gt;, `Copadez de Ben` &lt;dbl&gt;, …\n\n\nAhí podemos ver que para cada personaje tenemos una columna con el puntaje de su facha y su puntaje de copadez.\nEl siguiente paso consiste en eliminar algunas columnas que no son relevantes para el análisis, y agregamos una columna de id. Y luego tenemos que “pivotear” la tabla para que nos queden todas las columnas de puntajes de los personajes en dos columnas:\n\n# Eliminar columnas innecesarias\nclones &lt;- clones %&gt;% \n  select(-`Marca temporal`, -`Poné lo que quieras... parecidos, chistes, comentarios, etc...`)\n\n# Agregar columna de id\nclones &lt;- clones %&gt;% \n  rowid_to_column(var = \"id\")\n\n# Pivotear variables\nclones &lt;- clones %&gt;% \n  pivot_longer(cols = c(\"Facha de Keanu\": \"Copadez de Javier\"),\n               names_to = \"personaje\",\n               values_to = \"puntaje\")\n\n# Veamos como queda el dataset ahora\nhead(clones)\n\n# A tibble: 6 × 3\n     id personaje          puntaje\n  &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;\n1     1 Facha de Keanu          10\n2     1 Copadez de Keanu        10\n3     1 Facha de Russell         7\n4     1 Copadez de Russell      10\n5     1 Facha de Nico            1\n6     1 Copadez de Nico          1\n\n\nHabíamos comenzado con un dataset de 66 filas y 24 columnas. Ahora terminamos con un data frame de 1.452 filas en 3 columnas. Ahora necesitamos eliminar las palabras intermedias de y del de los nombres en la columna personaje así después podemos crear una columna para facha, y otra para copadez.\n\n# Separar variables categóricas\nclones &lt;- clones %&gt;% \n  mutate(personaje = str_remove(personaje, \"de \"),\n         personaje = str_remove(personaje, \"del \"))\n\n# Veamos el puntaje promedio de cada personaje y sus caraceterísticas\nclones %&gt;% \n  group_by(personaje) %&gt;% \n  summarise(valor_promedio = mean(puntaje)) %&gt;% \n  ggplot(aes(x = valor_promedio, y = personaje)) +\n  geom_point(size = 2)\n\n\n\n# Dividimos la columna 'personaje' en dos columnas, una para la métrica y otra para el nombre\nclones &lt;- clones %&gt;% \n  separate(personaje,  into = c(\"metrica\", \"persona\"))\n\n\n# Pivotear ancho \nclones &lt;- clones %&gt;% \n  pivot_wider(id_cols = c(id, persona),\n              names_from = metrica,\n              values_from = puntaje)\n\n# Veamos como queda el data frame ahora\nhead(clones)\n\n# A tibble: 6 × 4\n     id persona Facha Copadez\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Keanu      10      10\n2     1 Russell     7      10\n3     1 Nico        1       1\n4     1 Roberto     1       1\n5     1 Jeff        5       5\n6     1 Brad       10      10\n\n\nLuego de estos pasos quedamos con un data frame de 726 filas, una para cada votación para cada personaje, y con 4 columnas, id, persona, Facha y Copadez. Con estos datos podemos ver los resultados de cada persona:\n\n# Calculamos los resultados promedios para cada persona y graficamos los resultados\nresultados &lt;- clones %&gt;% \n  group_by(persona) %&gt;% \n  summarise(facha_promedio = mean(Facha),\n            copadez_promedio = mean(Copadez))\n\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio, color = persona)) +\n  geom_point(size = 3)\n\n\n\n\nEn esencia, este es el gráfico al que queremos llegar. Así como está es medio aburrido, así que vamos a enchular este gráfico con imágenes."
  },
  {
    "objectID": "posts/haciendo-boludeces-en-r/index.html#trabajando-con-las-imágenes",
    "href": "posts/haciendo-boludeces-en-r/index.html#trabajando-con-las-imágenes",
    "title": "Haciendo pavadas en R",
    "section": "Trabajando con las imágenes",
    "text": "Trabajando con las imágenes\nComo contaba antes, primero armé una presentación en Canva y pegué todas las imágenes de cada personaje para que queden más o menos del mismo tamaño. Luego guardé cada imagen en un archivo separado, y en este caso las guardé en una carpeta que se llama clones.\nPodría haber hecho la carga de las fotos una por una, pero quería hacer este trabajo lo más eficiente posible tratando de repetir pasos. Para eso tenemos que crear un data frame que tenga por un lado el nombre de la persona tal cual lo tenemos en la tabla de las votaciones, y que incluya la dirección a la imagen.\n\n# Creamos un vector con los nombres de las personas\npersona &lt;- resultados %&gt;% \n  select(persona) %&gt;% \n  pull()\n\n# Creo un vector de imágenes\nruta &lt;- \"pics\"        # Ruta de las fotos\nextension &lt;- \"png\"   # Extensión de los archivos de imágenes\n\n# nombres de los archivos\nimagen &lt;- c(\"Ben\", \"Brad\", \"Javier\", \"jeff\", \"keanu\", \"mono\", \"nico\", \n            \"ricky\", \"roberto\", \"russell\", \"sergio\")\n\n# Creo el vector de fotos con dirección y extensión completa\nfoto &lt;- str_c(ruta, imagen, sep = \"/\")\nfoto &lt;- str_c(foto, extension, sep = \".\")\n\n# Creo el dataframe y lo agrego al dataframe resultados\npics &lt;- data.frame(persona, foto)\n\n# Ver el resultado de este proceso\npics\n\n   persona             foto\n1      Ben     pics/Ben.png\n2     Brad    pics/Brad.png\n3   Javier  pics/Javier.png\n4     Jeff    pics/jeff.png\n5    Keanu   pics/keanu.png\n6     Mono    pics/mono.png\n7     Nico    pics/nico.png\n8    Ricky   pics/ricky.png\n9  Roberto pics/roberto.png\n10 Russell pics/russell.png\n11  Sergio  pics/sergio.png\n\n\nAhora tenemos un data frame de 11 filas y dos columnas, con el nombre de cada persona, y la dirección al archivo que contiene las imágenes de cada una. Estos datos lo podemos integrar al data frame que veníamos trabajando con los resultados de Facha y Copadez promedio de cada personaje.\n\n# Unimos los datasets\nresultados &lt;- left_join(resultados, pics)\n\nhead(resultados)\n\n# A tibble: 6 × 4\n  persona facha_promedio copadez_promedio foto           \n  &lt;chr&gt;            &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;          \n1 Ben               8.23             6.47 pics/Ben.png   \n2 Brad              8.52             7.55 pics/Brad.png  \n3 Javier            6.89             6.56 pics/Javier.png\n4 Jeff              5.06             6.45 pics/jeff.png  \n5 Keanu             7.77             8.74 pics/keanu.png \n6 Mono              3.30             6.30 pics/mono.png"
  },
  {
    "objectID": "posts/haciendo-boludeces-en-r/index.html#poniendo-imágenes-al-gráfico",
    "href": "posts/haciendo-boludeces-en-r/index.html#poniendo-imágenes-al-gráfico",
    "title": "Haciendo pavadas en R",
    "section": "Poniendo imágenes al gráfico",
    "text": "Poniendo imágenes al gráfico\nY ahora si, a lo que venimos: incluir las fotos en el gráfico\n\n# El gráfico final\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio)) +\n  geom_image(aes(image=foto), size = 0.08) +\n  theme_minimal() +\n  scale_x_continuous(limits = c(1,10)) +\n  scale_y_continuous(limits = c(1,10)) +\n  labs(title = \"Facha y Copadez Promedio de cada Personaje\",\n       x = \"Copadez Promedio\", \n       y = \"Facha Promedio\",\n       caption = \"n = 66\\nNinguna tía participó del relevamiento\")\n\n\n\n\nComo conclusión del análisis los datos dicen que estoy alejado de las características de Nicolás del Caño y Roberto Baradel por ejemplo y tengo características muy similares que Keanu Reeves. O sea que los datos indican que me parezco a Keanu. Dato, no opinión 😎."
  },
  {
    "objectID": "posts/haciendo-boludeces-en-r/index.html#qué-saqué-de-todo-esto",
    "href": "posts/haciendo-boludeces-en-r/index.html#qué-saqué-de-todo-esto",
    "title": "Haciendo pavadas en R",
    "section": "¿Qué saqué de todo esto?",
    "text": "¿Qué saqué de todo esto?\nEn primer lugar aprender a usar un paquete nuevo, ggimage que permite incluir imágenes en los gráficos. Por otro lado hubo un error en el diseño del formulario (poner “Facha del Mono”) lo que implicó un paso extra en la limpieza de los datos. Ese error en este proyecto me ayudó a prevenir un potencial problema con una encuesta de diversidad para un cliente.\nOtro tema fue la manipulación de los datos, pivotearlos de un formato “ancho” a uno “largo” y después nuevamente a uno “ancho” otra vez. Una vez que logré eso el cálculo de los resultados salió de manera muy simple.\nTodo esto llevó dos días de trabajo, mirar tutoriales y documentación y mucha prueba y error. La verdad es que fue mucho trabajo, pero el hecho de ser un proyecto medio delirante le sacó mucha presión y me dió la motivación para aprender algo nuevo y superar las barreras y errores que me fui encontrando. Creo que el hecho que sea un proyecto divertido me liberó para tratar interpretar los mensajes de error y buscar la solución apropiada.\nEste tipo de proyecto me parece ideal para realizar apenas terminás un tutorial o un curso. Los datos que usamos en un tutorial siempre están bastante limpios, controlados, divinos y cuando trabajás con tus propios datos te encontrás con barreras. Realizar este tipo de análisis sin la presión de “agregar valor” al negocio y pone a prueba las habilidades que tenés.\nAsí que te invito a que hagas un proyecto ridículo y que lo compartas con el mundo.\n\nFinal\nSi querés ver el script final de este post, lo podés encontrar en el repositorio en este link.\nY como regalo final, me reí mucho con los comentarios que hicieron las personas que participaron del relevamiento de datos así que los comparto con ustedes:\n\n\n\n\n\n\n  \n    \n    \n      Comentarios\n    \n  \n  \n    te rompí los patrones a la merd\n    jaja me rei mucho!\n    Caruso a la Final!\n    Johnny Depp, 8/8\n    Hajajja\n    De Brad Pitt te copiaste el peinado, no?\n    ¿es requisito tener pelo largo para parecer fachero?  mostrame indicadores\n    Sergio vos no estas bien haciendo esto!!!  Jajaja\n    Falta Denicolay\n    Jajaj muy bueno\n    Haces todo esto para levantarte minas Mora, lo sabemos!!!\n    ME ENCANTÓ! curiosa, dinámica y original iniciativa como siempre!!\n    Copado el test!!\n    ¿todos hombres?\n    Hajajja\n    WTH??\n    Sos un capo!!! me divertí mucho!!!\n    Falta el test de mujeres.....\n    Bronn, de game of thrones.\n    Muy buen ejercicio!  A algunos personajes el 1 le quedaba grande! habiliten el 0 jaja Éxitos!\n    Un genio Sergio 😂😂😂 Podría ser también a la versión adulta del niño del sexto sentido, el que dice\"veo gente muerta\" ¿? 🤔\n    Puedo decir que la foto que te sacaste, es muy de MA de instagram\n    Jaja me hiciste reír. Cómo no soy de Argentina tuve que googlear algunos, pero todo bien. Super entretenido\n  \n  \n  \n\n\n\n\nMuchas gracias por leer!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mi blog de R y People Analytics",
    "section": "",
    "text": "Cargar Campos de Fecha desde Excel Sin Errores\n\n\n\n\n\n\n\ntipito\n\n\ntip\n\n\nanálisis\n\n\ndate\n\n\nfecha\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2023\n\n\nChecho\n\n\n\n\n\n\n  \n\n\n\n\nExtraer el máximo valor de una fila\n\n\n\n\n\n\n\ntipito\n\n\ntip\n\n\nanálisis\n\n\ndplyr\n\n\ndata wrangling\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2022\n\n\nChecho\n\n\n\n\n\n\n  \n\n\n\n\nMicroaprendizajes de un proyecto\n\n\n\n\n\n\n\nggplot2\n\n\ntipito\n\n\ntip\n\n\nvisualización\n\n\nrmarkdown\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\nChecho\n\n\n\n\n\n\n  \n\n\n\n\nHaciendo pavadas en R\n\n\n\n\n\n\n\nfun\n\n\nggplot2\n\n\nproyectos\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nChecho\n\n\n\n\n\n\n  \n\n\n\n\nIndicadores de Capacitación\n\n\n\n\n\n\n\ncode free\n\n\npeople analytics\n\n\nkpi\n\n\ncapacitación\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2020\n\n\nChecho\n\n\n\n\n\n\n  \n\n\n\n\nScrap Learning: La Capacitación Desaprovechada\n\n\n\n\n\n\n\ncode free\n\n\npeople analytics\n\n\nkpi\n\n\ncapacitación\n\n\n\n\n\n\n\n\n\n\n\nAug 11, 2017\n\n\nChecho\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sergio Garcia Mora aka Checho",
    "section": "",
    "text": "Este blog va a ser un espacio en donde centraré contenido sobre programación en R, mayormente orientado a temas relacionados con Recursos Humanos y People Analytics.\nHonestamente, a esta altura del partido no me interesa hacer algo solemne para “parecer profesional”, lo que busco más que nada es generar contenido que le sirva a principiantes y a los que están permanentemente aprendiendo.\nTodo el contenido de este blog se puede compartir de manera abierta y libre, citando por supuesto la fuente.\nEn este blog te vas a encontrar con contenido relacionado con R y otros más generales y “conceptuales” sobre People Analytics.\nPara contactarme o saber más de mí podés hacerlo a través de mis redes sociales o las redes de R4HR - Club de R para RRHH.\nEsta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.\nEste blog está hecho en R usando Quarto, un sistema de publicación de código abierto desarrollado por el equipo de RStudio. Para más informacion visita este contenido desarrollado por Isabella Velásquez."
  },
  {
    "objectID": "about.html#de-qué-va-este-blog",
    "href": "about.html#de-qué-va-este-blog",
    "title": "Sergio Garcia Mora aka Checho",
    "section": "",
    "text": "Este blog va a ser un espacio en donde centraré contenido sobre programación en R, mayormente orientado a temas relacionados con Recursos Humanos y People Analytics.\nHonestamente, a esta altura del partido no me interesa hacer algo solemne para “parecer profesional”, lo que busco más que nada es generar contenido que le sirva a principiantes y a los que están permanentemente aprendiendo.\nTodo el contenido de este blog se puede compartir de manera abierta y libre, citando por supuesto la fuente.\nEn este blog te vas a encontrar con contenido relacionado con R y otros más generales y “conceptuales” sobre People Analytics.\nPara contactarme o saber más de mí podés hacerlo a través de mis redes sociales o las redes de R4HR - Club de R para RRHH.\nEsta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.\nEste blog está hecho en R usando Quarto, un sistema de publicación de código abierto desarrollado por el equipo de RStudio. Para más informacion visita este contenido desarrollado por Isabella Velásquez."
  },
  {
    "objectID": "posts/cargar_fechas_desde_excel/index.html",
    "href": "posts/cargar_fechas_desde_excel/index.html",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "",
    "text": "¿A quién no le pasó esto alguna vez?\nEsto en R muchas veces también nos trae dolores de cabeza así que en esto post vamos a ver cómo podemos solucionar esto."
  },
  {
    "objectID": "posts/cargar_fechas_desde_excel/index.html#paquetes",
    "href": "posts/cargar_fechas_desde_excel/index.html#paquetes",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Paquetes",
    "text": "Paquetes\nPara este ejemplo vamos a utilizar 3 paquetes, openxlsx que nos permite cargar y guardar archivos de Excel, dplyr para manipular y limpiar datos (podés ver un tutorial acá). También vamos a usar el paquete janitor para limpiar los nombres de las columnas a un formato más fácil de utilizar (elimina tildes, pasa todo a minúscula y reemplaza espacios por guiones, por ejemplo).\nEl primer paso, en caso que no los tengas aún, es instalar los paquetes:\n\n# Instalar paquetes\ninstall.packages(\"openxlsx\") # Cargar y guardar archivos de Excel\ninstall.packages(\"dplyr\")    # Manipular y limpiar datos\ninstall.packages(\"janitor\")  # Entre otras cosas, facilitar manipulación de columnas\n\nUna vez que termina la instalación, hay que cargarlos. No vamos a cargar el paquete janitor porque sólo vamos a usar una función.\nCargar un paquete “deja activas” todas las funciones del paquete, lo cual implica un consumo de memoria, muchas veces ínfimo, pero consumo al fin, así que en este caso mostraremos como usar una función sin cargar todas las funciones del paquete.\n\n# Cargar paquetes\nlibrary(openxlsx)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/cargar_fechas_desde_excel/index.html#los-datos",
    "href": "posts/cargar_fechas_desde_excel/index.html#los-datos",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Los datos",
    "text": "Los datos\nEl caso que usaremos de ejemplo simula ser una base de Postulantes de una búsqueda que llevamos adelante para una vacante de People Analytics. Primero carguemos los datos que están almacenados en una carpeta llamada data.\n\n# Cargar los datos en R\ndatos &lt;- read.xlsx(\"data/Postulantes.xlsx\") %&gt;% \n  janitor::clean_names() # Usamos solo la función clean_names() sin cargar todo el paquete janitor\n\nAhora veamos los datos que tenemos cargados:\n\n# Ver los datos cargados\ndatos\n\n  fecha_sourcing         busqueda   nombre apellido   telefono            mail\n1          44729 People Analytics   Sergio   Garcia 1111111111 sergio@d4hr.com\n2          44729 People Analytics  Daniela   Garcia 2222222222            &lt;NA&gt;\n3          44729 People Analytics    Yanel Paulette 3333333333            &lt;NA&gt;\n4          44729 People Analytics    Carla   Cirone 4444444444            &lt;NA&gt;\n5          44729 People Analytics Santiago  Lardone 5555555555            &lt;NA&gt;\n  empresa            puesto   github          twitter\n1    R4HR Master of Puppets chechoid @sergiogarciamor\n2    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n3    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n4    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n5    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n                                                  linkedin   fuente status\n1            https://www.linkedin.com/in/sergiogarciamora/  Twitter Activo\n2        https://www.linkedin.com/in/claudiadanielagarcia/ Linkedin Activo\n3               https://www.linkedin.com/in/yanelpaulette/ Linkedin Activo\n4       https://www.linkedin.com/in/carla-cirone-0566b095/ Linkedin Activo\n5 https://www.linkedin.com/in/santiagolardonequinodozrrhh/ Linkedin Activo\n  fecha_ultimo_contacto\n1                 44739\n2                 44739\n3                 44739\n4                 44739\n5                 44739\n\n# Hagamos un zoom en los campos que contienen fechas\ndatos %&gt;% \n  select(fecha_sourcing, fecha_ultimo_contacto)\n\n  fecha_sourcing fecha_ultimo_contacto\n1          44729                 44739\n2          44729                 44739\n3          44729                 44739\n4          44729                 44739\n5          44729                 44739\n\n\nEn la tabla anterior vemos que el valor que obtenemos en la primera columna es 44729, el número que representa a la fecha 17/6/22 como podemos apreciar en el archivo original:\n\nAhora veremos cómo podemos resolver este problema."
  },
  {
    "objectID": "posts/cargar_fechas_desde_excel/index.html#solución",
    "href": "posts/cargar_fechas_desde_excel/index.html#solución",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Solución",
    "text": "Solución\nPara empezar, seleccionemos algunas columnas nomás usando la función select(). Vamos a seleccionar los campos de fecha_sourcing que representa cuándo inició la búsqueda, nombre, empresa, y fecha_ultimo_contacto donde anotamos cuándo fue la última vez que nos pusimos en contacto con cada persona.\n\n# Seleccionar los campos con fechas, nombre y empres y sobreescribo el data frame\ndatos &lt;- datos %&gt;% \n  select(fecha_sourcing, nombre, empresa, fecha_ultimo_contacto)\n\n# Ver el nuevo dataframe\ndatos\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1          44729   Sergio    R4HR                 44739\n2          44729  Daniela    R4HR                 44739\n3          44729    Yanel    R4HR                 44739\n4          44729    Carla    R4HR                 44739\n5          44729 Santiago    R4HR                 44739\n\n\nAhora nos quedamos con un data frame de 5 filas y 4 columnas.\nPara transformar el campo fecha_sourcing de un formato numérico a un formato de tipo fecha, vamos a usar la función as.Date() de R base.\n\n# Transformar el campo fecha_sourcing a tipo fecha\ndatos %&gt;% \n  mutate(fecha_sourcing = as.Date(fecha_sourcing,          # Sobrescribimos el campo fecha_sourcing\n                                  origin = \"1899-12-30\",   # Fecha de origen para el conteo\n                                  tz = \"UTC\"))             # Huso horario\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1     2022-06-17   Sergio    R4HR                 44739\n2     2022-06-17  Daniela    R4HR                 44739\n3     2022-06-17    Yanel    R4HR                 44739\n4     2022-06-17    Carla    R4HR                 44739\n5     2022-06-17 Santiago    R4HR                 44739\n\n\nEl trabajo con fechas siempre fue complejo desde el punto de vista del análisis de datos. Especialmente con los distintos formatos que se usan en el mundo, por ejemplo dd/mm/aaaa en Sudamérica, o mm/dd/aaaa en Estados Unidos por ejemplo. R, cuando un campo fecha carga correctamente, lo transforma a un formato ISO 8601 aaaa-mm-dd.\n\nEl primer número que obtuvimos cuando cargamos la tabla en R (el 44729) significa que desde el 30 de diciembre de 1899 hasta el 17 de Junio de 2022 pasaron 44.729 días. De ahí el número que obtuvimos en la carga.\nEl parámetro tz, nos permite especificar el huso horario del registro. Para algunos casos puede ser relevante, pero para la mayoría de los casos de uso que le daríamos en RRHH, es un parámetro que podemos incluir o no.\n\nCambiar varios campos a la vez\nCon la tabla que estamos usando de ejemplo, no hay mucho problema en repetir el paso ya que únicamente tenemos dos campos de fechas. ¿Pero qué pasa si tenemos 6, 7, o más campos de fechas en un archivo? Repetir estos pasos manualmente va a hacer confuso nuestro código y más complejo de mantener.\nVeamos una forma de cambiar todos los campos de fecha usando algunas funciones auxiliares del paquete dplyr.\n\n# Cambios los dos campos de fecha a la vez\ndatos %&gt;% \n  mutate(across(starts_with(\"fecha\"),\n                ~as.Date(.x,\n                         tz = \"UTC\",\n                         origin = \"1899-12-30\")))\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1     2022-06-17   Sergio    R4HR            2022-06-27\n2     2022-06-17  Daniela    R4HR            2022-06-27\n3     2022-06-17    Yanel    R4HR            2022-06-27\n4     2022-06-17    Carla    R4HR            2022-06-27\n5     2022-06-17 Santiago    R4HR            2022-06-27\n\n\nEn este caso usamos la función across() para indicarle a R que ejecute la función (en este ejemplo, as.Date()) en todas las variables que cumplan con algún criterio. En este ejemplo, nos valemos de otra función auxiliar, starts_with(), que como su nombre en inglés lo indica, va a ejecutar la función en todas las columnas que empiecen con el término \"fecha\".\nEste ejemplo funciona porque los campos que contienen una fecha comienzan con el nombre fecha. Por eso es importante al momento de diseñar una base de datos, un formulario, o cualquier registro que utilicemos para que haya una consistencia entre los nombres de los campos para facilitarnos posteriormente el proceso y análisis de datos, independiemente del software que utilicemos.\nPresten atención a que delante de la función as.Date() usamos este símbolo (~ ) llamado virgulilla (en Neuquén, Argentina, le dríamos ñuflo). Con ese símbolo le indicamos a R que esa va a ser la función que vamos a replicar en todos los campos.\nEl argumento .x, representa a todas las columnas que habíamos seleccionado con las funciones across() y starts_with(). Es decir que es la forma que tiene R de simplificar cuáles son los campos que tiene que transformar sin que le tengamos que indicar uno por uno cuales son."
  },
  {
    "objectID": "posts/indicadores_capacitacion/index.html",
    "href": "posts/indicadores_capacitacion/index.html",
    "title": "Indicadores de Capacitación",
    "section": "",
    "text": "Con la Capacitación en las empresas pasa algo curioso: hace unos años atrás, entre mis compañeros de la Maestría de Data Mining hice una encuesta sobre beneficios, y una de las preguntas que hacía era “¿Qué beneficio que no tenés hoy te gustaría tener?”. Y 1 de cada 4 respuestas estaba relacionada con Capacitación (capacitación in company, desde cuotas en posgrados, certificaciones, etc.). Y yo pensaba por dentro “Pero… la capacitación no es un beneficio”. Sin embargo las personas perciben a la capacitación como un beneficio.\nLos cambios que impone la tecnología, y la rapidez con la que avanza, hacen que, como dijo Diego Bekerman, las empresas dejen de buscar “graduados de” para buscar “personas que saben de”. Esto plantea una nueva necesidad de Planificación Estratégica de Capital Humano en donde se plantean las capacidades que hoy tienen las personas y se las contrasta con las capacidades futuras que requiere la empresa. Y acá surge una de las primeras cuestiones: Estas capacidades, ¿las desarrollamos internamente o las salimos a buscar al mercado?\nDespués tenemos variables de contexto. No debe haber ni un sólo CEO, Gerente General o Dueño de una empresa que desconozca el valor y la importancia de la capacitación de sus empleados. Sin embargo, es uno de los primeros presupuestos que se corta en épocas de vacas flacas. Y uno de los principales factores que determinan estas decisiones seguramente se relaciona con que no cuentan con suficiente información sobre el impacto de la capacitación en los resultados de la empresa.\nNótese que escribí impacto en los resultados, no ROI. Ampliaremos.\nEntonces tenemos empleados que demandan capacitación, negocios que necesitan nuevas capacidades, y una constante tensión presupuestaria. Sin mencionar el contexto económico recesivo. ¿Cómo podemos usar indicadores para administrar, planificar y conseguir presupuesto para gestionar la capacitación en este contexto?\nEn primer lugar conociendo las necesidades del negocio.Y para esto es necesario entender qué es lo que demandan las personas que dirigen las empresas.\nEn Learning Analytics, John R Mattox II, Mark Van Buren y Jean Martin, plantean que los CEO’s pretenden que midamos:\n\nAplicación: ¿Cómo Podemos aumentar la aplicación de nuevas habilidades en el trabajo\nResultados: ¿En qué grado un programa de capacitación mejorará un resultado de negocio específico?\nValor: ¿Cuál será el Retorno de Inversión?\n\n¿Qué es lo que usualmente medimos en gestión de capacitación?\n\nCosto de capacitación por empleado\nSatisfacción con la capacitación.\nHoras de Capacitación por Empleado\nGastos de Capacitación Externa.\n\nEvidentemente hay un mismatch entre la información que demandan las personas que dirigen las empresas y la información que proveemos desde Recursos Humanos.\nAlec Levenson, uno de los autores más “hardcore evidence” de People Analytics que sigo, de formación en Economía, plantea en una podcast que el ROI no siempre es medible, por ejemplo,de una capacitación en empatía para líderes. Alec explica que el ROI se mide fundamentalmente en cashflow, y que no todo es traducible en términos económicos.\nUn punto interesante que plantea Levenson es dice que si encontramos vínculos entre cómo las personas operan en el negocio, en cómo se comunican, se hacen cargo y se comprometen, y en cómo enfocan su tiempo y energía en alcanzar la estrategia del negocio, y haciendo lo que es necesario hacer para crear ventajas competitivas, es todo lo que necesitamos mostrar. Si logramos establecer una relación consistente entre los comportamientos de las personas y las ventajas competitivas, generamos información más valiosa y expresiva (agrego yo) que el ROI.\n\n\nSi buscamos en nuestros apuntes y libros de la universidad como medir la gestión de capacitación, seguramente nos vamos a encontrar con los modelos de Donald Kirkpatrick y de Jack Phillips.\nEl Modelo de 4 Niveles de Evaluación de Kirkpatrick propone un enfoque para medir el impacto de la capacitación en los siguientes niveles:\nEl primer nivel apunta a medir la satisfacción de los colaboradores con el curso y con el facilitador. Muchas empresas sólo están midiendo este nivel. El aprendizaje busca medir si las personas adquirieron nuevos conocimientos y habilidades.\nRespecto al nivel 3, de medir conductas, Kirkpatrick plantea analizar si hubo un cambio de comportamiento luego de la capacitación. Volvamos a la entrevista de Alec Levenson, ¿cuáles son los comportamientos que crean ventajas competitivas?\nFinalmente el 4° nivel es el de resultados, que ahí buscaremos ver el impacto de las acciones de capacitación en resultados tanto operativos como de clima laboral por ejemplo.\nJack Phillips desarrolló la Metodología ROI que en gran parte se sustenta en el modelo de Kirkpatrick, cambiando ligeramente los primeros 4 niveles, y añadiendo el del ROI.\n\nReacción y acción planificada.\nAprendizaje.\nAplicación.\nImpacto.\nRetorno de Inversión.\n\nEstos 5 niveles son parte de la Metodología ROI que incluye además la planificación, la recolección de datos, su análisis y reporte.\nMi postura es que si hoy sólo estamos midiendo horas de capacitación y costos, lograr avanzar al nivel 3 (Conductas o Aplicación), ya es un enorme salto de calidad de las métricas del área. Si logramos eso, será más fácil medir resultados, y ya habrá tiempo para medir el ROI.\nKirkpatrick desarrolló su modelo en la década del ’50, mientras que Phillips lo hizo a principios de los ’80. En 2007 Josh Bersin publicó The Training Measurement Book, en donde se enfoca principalmente en la planificación y en el alineamiento de la capacitación con las necesidades del negocio.\nEl modelo de Bersin propone 9 métricas críticas para su Modelo de Medición de Impacto. Estas métricas son:\n\nSatisfacción.\nAprendizaje.\nAdopción (tasa del público target que completó el proceso de aprendizaje).\nUtilidad.\nEficiencia.\nAlineamiento.\nLogros de objetivos desde la perspectiva de los clientes.\nDesempeño Individual.\nDesempeño del Negocio.\n\nSi logramos incorporar métricas que incluyan los aspectos de cualquiera de estos modelos, más nuevas tendencias como el Scrap Learning (incluyendo la perspectiva de los jefes) podemos construir un set de información muy valiosa para los stakeholders de la organización. Correr el foco del ROI y enfocarlo en las ventajas competitivas (eso que la empresa hace bien y que la distingue de otras empresas) también nos permite canalizar los esfuerzos de gestión y de análisis en donde más valor aportamos a la rentabilidad del negocio."
  },
  {
    "objectID": "posts/indicadores_capacitacion/index.html#de-vuelta-a-la-universidad",
    "href": "posts/indicadores_capacitacion/index.html#de-vuelta-a-la-universidad",
    "title": "Indicadores de Capacitación",
    "section": "",
    "text": "Si buscamos en nuestros apuntes y libros de la universidad como medir la gestión de capacitación, seguramente nos vamos a encontrar con los modelos de Donald Kirkpatrick y de Jack Phillips.\nEl Modelo de 4 Niveles de Evaluación de Kirkpatrick propone un enfoque para medir el impacto de la capacitación en los siguientes niveles:\nEl primer nivel apunta a medir la satisfacción de los colaboradores con el curso y con el facilitador. Muchas empresas sólo están midiendo este nivel. El aprendizaje busca medir si las personas adquirieron nuevos conocimientos y habilidades.\nRespecto al nivel 3, de medir conductas, Kirkpatrick plantea analizar si hubo un cambio de comportamiento luego de la capacitación. Volvamos a la entrevista de Alec Levenson, ¿cuáles son los comportamientos que crean ventajas competitivas?\nFinalmente el 4° nivel es el de resultados, que ahí buscaremos ver el impacto de las acciones de capacitación en resultados tanto operativos como de clima laboral por ejemplo.\nJack Phillips desarrolló la Metodología ROI que en gran parte se sustenta en el modelo de Kirkpatrick, cambiando ligeramente los primeros 4 niveles, y añadiendo el del ROI.\n\nReacción y acción planificada.\nAprendizaje.\nAplicación.\nImpacto.\nRetorno de Inversión.\n\nEstos 5 niveles son parte de la Metodología ROI que incluye además la planificación, la recolección de datos, su análisis y reporte.\nMi postura es que si hoy sólo estamos midiendo horas de capacitación y costos, lograr avanzar al nivel 3 (Conductas o Aplicación), ya es un enorme salto de calidad de las métricas del área. Si logramos eso, será más fácil medir resultados, y ya habrá tiempo para medir el ROI.\nKirkpatrick desarrolló su modelo en la década del ’50, mientras que Phillips lo hizo a principios de los ’80. En 2007 Josh Bersin publicó The Training Measurement Book, en donde se enfoca principalmente en la planificación y en el alineamiento de la capacitación con las necesidades del negocio.\nEl modelo de Bersin propone 9 métricas críticas para su Modelo de Medición de Impacto. Estas métricas son:\n\nSatisfacción.\nAprendizaje.\nAdopción (tasa del público target que completó el proceso de aprendizaje).\nUtilidad.\nEficiencia.\nAlineamiento.\nLogros de objetivos desde la perspectiva de los clientes.\nDesempeño Individual.\nDesempeño del Negocio.\n\nSi logramos incorporar métricas que incluyan los aspectos de cualquiera de estos modelos, más nuevas tendencias como el Scrap Learning (incluyendo la perspectiva de los jefes) podemos construir un set de información muy valiosa para los stakeholders de la organización. Correr el foco del ROI y enfocarlo en las ventajas competitivas (eso que la empresa hace bien y que la distingue de otras empresas) también nos permite canalizar los esfuerzos de gestión y de análisis en donde más valor aportamos a la rentabilidad del negocio."
  },
  {
    "objectID": "posts/microaprendizajes/index.html",
    "href": "posts/microaprendizajes/index.html",
    "title": "Microaprendizajes de un proyecto",
    "section": "",
    "text": "Esta presentación se centra en algunos microaprendizajes de un proyecto de análisis de resultados de una encuesta de diversidad e inclusión.\nLo razón por la que lo llamo “microaprendizajes” es porque no tuve que aprender muchas cosas desde cero, pero si aprendí varios truquitos que me sirvieron mucho.\nVoy a usar una encuesta simulada para no violar la confidencialidad de los datos, pero va a ser algo análogo a lo que estuve usando en el proyecto.\nPara explotar al máximo esta sesión conviene saber un poco de hacer informes con RMarkdown. Si necesitás un tutorial sobre ese tema te comparto el video que hicimos el año pasado.\n\n\n\n\n\nEste material se puede utilizar y compartir sin fines comerciales y citando la fuente.\n\n\n\nLicencia"
  },
  {
    "objectID": "posts/microaprendizajes/index.html#el-chunk-de-setup",
    "href": "posts/microaprendizajes/index.html#el-chunk-de-setup",
    "title": "Microaprendizajes de un proyecto",
    "section": "El chunk de ‘setup’",
    "text": "El chunk de ‘setup’\nEl bloque de código de setup es muy útil para controlar cómo se van a comportar todos los bloques de código.\nMi archivo original tiene +150 bloques de código, imaginen si modificara uno por uno las características de cada bloque.\n\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.retina = 3,\n                      out.width = \"80%\")"
  },
  {
    "objectID": "posts/microaprendizajes/index.html#ordenar-el-código",
    "href": "posts/microaprendizajes/index.html#ordenar-el-código",
    "title": "Microaprendizajes de un proyecto",
    "section": "Ordenar el código",
    "text": "Ordenar el código\nTener un orden en el código es muy importante para poder ir y venir rápido y encontrar rápidamente las cosas, modificar algo, y demás.\nDentro de los bloques de código también es importante poner títulos o marcadores que nos ayuden a encontrar rápido las cosas. El orden que definí fue:\n\nLibrerías.\nConfiguraciones generales\nCarga de datos\nPreprocesamiento y limpieza de datos\nFunciones\n\n\n# Librerías -----\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(scales)\nlibrary(extrafont)\nlibrary(readxl)\n\n\n# Configuraciones generales ----------\n\n# Colores\nverde &lt;- \"#01B3B6\"\nnegro &lt;- \"#333132\"\ngris &lt;- \"#AEB6BF\"\n\ncolor3 &lt;- c(verde, gris, negro)\ncolor2 &lt;- c(verde, negro)\n\n# Opciones de visualización --------\noptions(scipen = 999)   # Modifica la visualización de los ejes numérico a valores nominales\n\nloadfonts(quiet = TRUE) # Permite cargar en R otros tipos de fuentes.\n\n# Estilo limpio sin líneas de fondo\nestilo &lt;- theme(panel.grid = element_blank(),\n                plot.background = element_rect(fill = \"#FBFCFC\"),\n                panel.background = element_blank(),\n                text = element_text(family = \"Ubuntu Mono\"))\n\n# Estilo limpio con líneas de referencia verticales en gris claro\nestilov &lt;- theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#FBFCFC\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#ecf0f1\"),\n                 text = element_text(family = \"Ubuntu Mono\"))\n\n# Estilo limpio con líneas de referencia horizontales en gris claro\nestiloh &lt;- theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#FBFCFC\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.y = element_line(color = \"#ecf0f1\"),\n                 text = element_text(family = \"Ubuntu Mono\"))\n\n\n# Creo un objeto con un texto que se va a repetir mucho a lo largo del análisis\nfuente &lt;- \"Club de R para RRHH\\nDatos Ficticios\"\n\n# Creo objetos para formatear las etiquetas numéricas de los ejes x e y\neje_x_per &lt;- scale_x_continuous(labels = scales::percent_format(accuracy = 1))\n\neje_y_per &lt;- scale_y_continuous(labels = scales::percent_format(accuracy = 1))\n\n# Carga de Datos -----\nencuesta &lt;- read_excel(\"data/encuesta.xlsx\")\nplantel  &lt;- read_excel(\"data/plantel.xlsx\")\n\n# Preparación de datos -----------\n\n# Pivotea el dataset a un formato largo\nenc &lt;- encuesta %&gt;% \n  pivot_longer(cols = c(7:11),\n               names_to = \"pregunta\", \n               values_to = \"valor\")\n\n# Cambia nombres y Organiza variables ordinales \n\nenc &lt;- enc %&gt;% \n  rename(id = \"ID\",\n         genero = `¿Cómo definirías tu identidad de género?`,\n         unidad = \"Unidad de Negocio\",\n         pais = \"País\",\n         sector = \"Sector\",\n         cargo = \"Tu cargo/nivel:\") %&gt;% \n  mutate(cargo = factor(cargo,\n                        levels = c(\"Management\", \"Líder\", \"Contribuidor individual\")))\n\n# Crea categorías de resultados\n\nenc &lt;- enc %&gt;% \n  mutate(resultado = if_else(valor == \"Totalmente de acuerdo\", \"Positivo\", \n                             if_else(valor == \"De acuerdo\", \"Positivo\", \n                                     if_else(valor == \"Ni de acuerdo ni en desacuerdo\",\n                                             \"Neutral\", \"Negativo\"\n      )\n    )\n  ),\n         resultado = factor(resultado, \n                            levels = c(\"Positivo\", \"Neutral\", \"Negativo\")))\n\n\nY comenten el código por amor a Jebús!"
  },
  {
    "objectID": "posts/microaprendizajes/index.html#poner-el-nombre-a-los-bloques-de-código",
    "href": "posts/microaprendizajes/index.html#poner-el-nombre-a-los-bloques-de-código",
    "title": "Microaprendizajes de un proyecto",
    "section": "Poner el nombre a los bloques de código",
    "text": "Poner el nombre a los bloques de código\nAlgo muy útil es ponerle nombre a los bloques de código. Por un lado porque es fácil para navegar entre bloques buscándolos en RStudio.\nPor ejemplo, probemos un gráfico simple:\n\nggplot(enc, aes(x = pais, fill = resultado)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(color3)) +\n  estiloh +\n  eje_y_per +\n  labs(title = \"Resultados por país\",\n       fill = \"Resultado\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\nPuede ocurrir que necesitemos reutilizar el gráfico. Hacer la gran stackoverflow (copiar y pegar el código) es una opción, pero puede generar errores y por otro lado implica tiempo de procesamiento.\nEn cambio, con la opción ref.label podemos reutilizar lo que hicimos antes, de una forma más prolija y cómoda pasando el nombre del bloque anterior.\nInternamente, lo que hace R es reutilizar el código creado anteriormente.\n\n{r ref.label=\"grafico1\"}\n\nVoilá!\n\nggplot(enc, aes(x = pais, fill = resultado)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(color3)) +\n  estiloh +\n  eje_y_per +\n  labs(title = \"Resultados por país\",\n       fill = \"Resultado\",\n       x = \"\", y = \"\",\n       caption = fuente)"
  },
  {
    "objectID": "posts/microaprendizajes/index.html#etiquetas-largas",
    "href": "posts/microaprendizajes/index.html#etiquetas-largas",
    "title": "Microaprendizajes de un proyecto",
    "section": "Etiquetas largas",
    "text": "Etiquetas largas\nA veces necesitamos presentar en un gráfico o en una tabla la pregunta original de la encuesta. Por ejemplo, una de las “preguntas” de la encuesta dice:\n\nOtra pregunta que tiene muchísimo texto escrito en la encuesta y quedó tan larga que no entra en un solo renglón y que me hace preguntarme cómo la voy a poner en un gráfico\n\nAhora veamos cómo se ven las preguntas en un gráfico si intentamos hacer un ranking.\n\nenc %&gt;% \n  group_by(pregunta, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = pregunta)) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\nQueda hermoso, no? 😱\nPara sortear este problema podemos crear una columna nueva, y usar la función str_wrap() del paquete stringr.\nLo que hace esto es agregar el símbolo \\n que divide el texto en renglones. Con el parámetro width le indicamos la cantidad de caracteres de largo que tendrá cada renglón.\n\n# Divide el largo de 'función' en varias líneas\nenc$preg2 &lt;- str_wrap(enc$pregunta, width = 40)\n\n# Veamos como queda esto en el df\nhead(enc$preg2,5)\n\n[1] \"Una pregunta con un texto muy pero muy\\npero muy largo, de verdad que es muy muy\\nmuy largo\"                                                                                     \n[2] \"Otra pregunta que tiene muchísimo texto\\nescrito en la encuesta y quedó tan larga\\nque no entra en un solo renglón y que me\\nhace preguntarme cómo la voy a poner en\\nun gráfico\"\n[3] \"Los líderes son unos capos\"                                                                                                                                                      \n[4] \"Que grosso es trabajar acá\"                                                                                                                                                      \n[5] \"Esta encuesta es genial\"                                                                                                                                                         \n\n\nY ahora podemos hacer un gráfico que se vea bien:\n\nenc %&gt;% \n  group_by(preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop))) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\nAhora queda mucho mejor 👍\nTambién se puede jugar con la altura del gráfico usando la opción fig.height en las opciones del bloque para que haya más espacio entre las barras.\n\n{r fig.height=8} # El tamaño es exagerado en este caso\n\n\nranking &lt;- enc %&gt;% \n  group_by(preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop))) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\nranking"
  },
  {
    "objectID": "posts/microaprendizajes/index.html#texto-en-los-gráficos",
    "href": "posts/microaprendizajes/index.html#texto-en-los-gráficos",
    "title": "Microaprendizajes de un proyecto",
    "section": "Texto en los gráficos",
    "text": "Texto en los gráficos\nEs simple agregar las etiquetas de datos a un gráfico:\n\nranking +\n  geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            size = 3,                           # Cambia el tamaño de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\") \n\n\n\n\nMiremos lo que pasa cuando queremos agregar más información al gráfico, por ejemplo, con los resultados por país.\n\nranking &lt;- enc %&gt;% \n  group_by(pais, preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop), fill = pais)) +\n  geom_col(position = \"dodge\") +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       fill = \"País\",\n       caption = fuente) +\n  scale_fill_brewer(palette = 2)\n\nranking +\n   geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            size = 3,                           # Cambia el tamaño de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\")             # Modifica la fuente\n\n\n\n\nEl problema es que todas las etiquetas de cada barra están centradas con la etiqueta del eje y. En la guía de geom_text en la documentación de ggplot2 encontramos como solucionar el problema usando el parámetro position_dodge().\n\nranking &lt;- ranking +\n   geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            position = position_dodge(0.9),     # Acomoda cada etiqueta con las barras\n            size = 3,                           # Cambia el tamaño de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\")             # Modifica la fuente\n\nranking\n\n\n\n\nOtra mejora que podemos hacer al gráfico es acomodar los colores en la leyenda (la referencia de los colores) para que tengan la misma secuencia que tiene en el gráfico, es decir que el verde oscuro aparezca primero al igual que la barra con el verde más oscuro en el gráfico.\nEn esta página hay muchas variantes para trabajar con las etiquetas y leyendas.\n\nranking +\n  guides(fill = guide_legend(reverse=TRUE)) + # Invierte el orden de los colores en la leyenda\n  theme(axis.text.x = element_blank())\n\n\n\n\nCuando estamos mapeando una variable categórica en el eje y, R lo ordena alfabéticamente desde abajo hacia arriba.\n\nenc %&gt;% \n  group_by(sector, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = sector)) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Resultado Positivos por Sector\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\nPodemos usar la función fct_rev del paquete forcats para poner al revés las etiquetas del eje y cuando estamos mapeando las variables dentro de ggplot\n\nenc %&gt;% \n  group_by(sector, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = fct_rev(sector))) + # Invertimos el orden del eje y\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Resultado Positivos por Sector\",\n       x = \"\", y = \"\",\n       caption = fuente)"
  },
  {
    "objectID": "posts/microaprendizajes/index.html#funciones",
    "href": "posts/microaprendizajes/index.html#funciones",
    "title": "Microaprendizajes de un proyecto",
    "section": "Funciones",
    "text": "Funciones\nEsto es un work-in-progress y tengo que agradecer a Mónica Alonso de RLadies Buenos Aires por la ayuda.\nEl problema es que me encontré muchas veces escribiendo esta secuencia de código muchas veces:\n\n# Calcular pocertajes de respuestas\nenc %&gt;% \n  group_by(genero, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant / sum(cant))\n\n# A tibble: 6 × 4\n# Groups:   genero [2]\n  genero    resultado  cant   prop\n  &lt;chr&gt;     &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 Femenino  Positivo   1127 0.764 \n2 Femenino  Neutral     244 0.165 \n3 Femenino  Negativo    104 0.0705\n4 Masculino Positivo   1477 0.823 \n5 Masculino Neutral     222 0.124 \n6 Masculino Negativo     96 0.0535\n\n\nMuchas veces resolví copiando y pegando el código, pero se hace tedioso controlar cada uno de los bloques de código y gráficos. Así que para eso, podemos crear nuestras propias funciones.\n\ncant_prop_gen &lt;- function(df){\n  df %&gt;% \n    group_by(genero,resultado) %&gt;% \n    summarise(cant = n()) %&gt;% \n    mutate(prop = cant / sum(cant)) \n}\n\nY ahora lo podemos incorporar en nuestro flujo de trabajo como cualquier función.\n\nenc %&gt;% \n  cant_prop_gen() %&gt;% \n  ggplot(aes(x = genero, y = prop, fill = resultado)) +\n  geom_col(position = \"dodge\") +\n  eje_y_per +\n  estiloh +\n  scale_fill_manual(values = color3) +\n  labs(title = \"Resultados por Género\",\n       x = \"\", y = \"\",\n       fill = \"Resultado\",\n       caption = fuente)\n\n\n\n\nTodavía estoy resolviendo como crear funciones usando cualquier tipo de variable en la función. Por ahora, lo estoy resolviendo creando una función para cada combinación de variables que agrupo. No es lo ideal, pero es lo que hay. 🤷\nCapaz encuentre lo que necesito en estos libros:\n\nR para Ciencia de Datos\nHands-On Programming with R\nAdvanced R\n\nYa les contaré… stay tuned 📺"
  },
  {
    "objectID": "posts/microaprendizajes/index.html#código-inline",
    "href": "posts/microaprendizajes/index.html#código-inline",
    "title": "Microaprendizajes de un proyecto",
    "section": "Código Inline",
    "text": "Código Inline\nComo sabemos, algo interesante de RMarkdown es la posibilidad de utilizar el código de los bloques dentro del texto.\nAsí que creemos un pequeño objeto primero para almacenar los resultados positivos y negativos por género.\n\nresult_genero &lt;- enc %&gt;% \n  cant_prop_gen()\n\nresult_genero\n\n# A tibble: 6 × 4\n# Groups:   genero [2]\n  genero    resultado  cant   prop\n  &lt;chr&gt;     &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 Femenino  Positivo   1127 0.764 \n2 Femenino  Neutral     244 0.165 \n3 Femenino  Negativo    104 0.0705\n4 Masculino Positivo   1477 0.823 \n5 Masculino Neutral     222 0.124 \n6 Masculino Negativo     96 0.0535\n\n\nUsando la llamada de datos de un dataframe con nombre_df[fila,columna] puedo usar los resultados almacenados para incluirlos dentro del texto por ejemplo para decir:\nLos resultados positivos para las personas de género femenino es 0.7640678.\nLo ideal es poder ver ese resultado como un porcentaje, así que intuitivamente podemos usar la función percent para lograr eso…\n…y no va a funcionar. Obtenemos el siguiente mensaje de error:\n\n# Intento de código inline\n`r percent(result_genero[1,4])`\n\n# Quitting from lines 425-441 (r4hr_microaprendizajes.Rmd) \n# Error in is.finite(x) : default method not implemented for type 'list'\n\nPara que la función percent funcione la tenemos que combinar con la función pull . Y ahora así sí funciona:\nLos resultados positivos para las personas de género femenino es 76% ."
  },
  {
    "objectID": "posts/microaprendizajes/index.html#trust-the-tidyverse",
    "href": "posts/microaprendizajes/index.html#trust-the-tidyverse",
    "title": "Microaprendizajes de un proyecto",
    "section": "Trust the Tidyverse",
    "text": "Trust the Tidyverse\n\nLo barato sale caro\nDicho popular\n\n\nLa encuesta que estábamos analizando era anónima, lo cual hacía imposible poder cruzar datos contra el listado de empleados.\nPero, sí podíamos calcular los resultados según la composición del liderazgo. Para eso teníamos que calcular el porcentaje de líderes hombres y mujeres por sector.\n\n# Cuento la cantidad de líderes por sector y géenero\nplantel &lt;- plantel %&gt;% \n  rename(division = `Unidad de Negocio`, \n         lider = Líder, \n         sexo = Género, \n         sector = Sector, \n         pais = País) %&gt;% \n  filter(lider == \"true\") %&gt;% \n  group_by(pais, division, sector, lider, sexo) %&gt;% \n  tally() %&gt;% \n  ungroup()\n\nplantel\n\n# A tibble: 106 × 6\n   pais  division sector           lider sexo          n\n   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;\n 1 Chad  Unidad 1 Comercial        true  Femenino      4\n 2 Chad  Unidad 1 Comercial        true  Masculino     3\n 3 Chad  Unidad 1 R&D              true  Femenino      5\n 4 Chad  Unidad 1 R&D              true  Masculino     1\n 5 Chad  Unidad 2 Administración   true  Femenino      3\n 6 Chad  Unidad 2 Administración   true  Masculino     6\n 7 Chad  Unidad 2 Calidad          true  Femenino      1\n 8 Chad  Unidad 2 Comercial        true  Femenino      5\n 9 Chad  Unidad 2 Comercial        true  Masculino     1\n10 Chad  Unidad 2 Recursos Humanos true  Femenino      3\n# ℹ 96 more rows\n\n\n\n# Pivoteo el dataset a un dataset ancho\nplantel &lt;- plantel %&gt;% \n  pivot_wider(.,\n              names_from = sexo,\n              values_from = n)\n\n# Reemplaza los NA con un 0\nplantel[is.na(plantel)] &lt;- 0\n\n\n# Calculo porcentaje de líderes hombres\nplantel %&gt;% \n  mutate(prop_lider_hombre = if_else(Femenino == 0, 1, Masculino / (Masculino +Femenino))) %&gt;% \n  select(-lider)\n\n# A tibble: 60 × 6\n   pais  division sector           Femenino Masculino prop_lider_hombre\n   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;               &lt;int&gt;     &lt;int&gt;             &lt;dbl&gt;\n 1 Chad  Unidad 1 Comercial               4         3             0.429\n 2 Chad  Unidad 1 R&D                     5         1             0.167\n 3 Chad  Unidad 2 Administración          3         6             0.667\n 4 Chad  Unidad 2 Calidad                 1         0             0    \n 5 Chad  Unidad 2 Comercial               5         1             0.167\n 6 Chad  Unidad 2 Recursos Humanos        3         0             0    \n 7 Chad  Unidad 3 Administración          2         2             0.5  \n 8 Chad  Unidad 3 Calidad                 2         2             0.5  \n 9 Chad  Unidad 3 Comercial               5        20             0.8  \n10 Chad  Unidad 3 HSE                     1         0             0    \n# ℹ 50 more rows"
  }
]