[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mi blog de R y People Analytics",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "es/tidytuesday-simpsons/index.html",
    "href": "es/tidytuesday-simpsons/index.html",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Vamos a cargar los datos con el paquete tidytuesdayR:\n\n\nVer c√≥digo\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "es/tidytuesday-simpsons/index.html#the-simpsons-data",
    "href": "es/tidytuesday-simpsons/index.html#the-simpsons-data",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Vamos a cargar los datos con el paquete tidytuesdayR:\n\n\nVer c√≥digo\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "es/tidytuesday-simpsons/index.html#calcular-el-rating-promedio-por-duplas",
    "href": "es/tidytuesday-simpsons/index.html#calcular-el-rating-promedio-por-duplas",
    "title": "Tidy Tuesday - Simpsons",
    "section": "Calcular el rating promedio por duplas",
    "text": "Calcular el rating promedio por duplas\nVamos a limpiar un poco m√°s los datos, qued√°ndonos √∫nicamente con las duplas que aparezcan al menos 5 veces\n\n\nVer c√≥digo\ntop_duplas &lt;- duplas_por_episodio %&gt;% \n  count(dupla, name = \"cuenta\") %&gt;% \n  filter(cuenta &gt;= 10)\n\n# Reducimos el dataframe\nduplas_por_episodio &lt;- duplas_por_episodio %&gt;% \n  filter(dupla %in% top_duplas$dupla)\n\n\nAhora podemos unir los datos de duplas_por_episodio y de esa manera calculamos el rating de cada pareja de personajes.\n\n\nVer c√≥digo\nduplas_con_rating &lt;- duplas_por_episodio %&gt;% \n  inner_join(episodes, by = c(\"episode_id\" = \"id\")) %&gt;% \n  group_by(dupla) %&gt;% \n  summarise(imdb_promedio = mean(imdb_rating, na.rm = TRUE),\n            episodios = n())\n\n# Filtrar solo las duplas que aparecen en al menos 10 episodios\nduplas_con_rating &lt;- duplas_con_rating %&gt;%\n  filter(episodios &gt;= 10) %&gt;%\n  arrange(desc(imdb_promedio))\n\n\nY ahora podemos hacer un gr√°fico de las 10 parejas con mejor puntaje promedio en imdb_ranking.\n\n\nVer c√≥digo\n# Seleccionar los mejores d√∫os\ntop_10_duplas &lt;- duplas_con_rating %&gt;% \n  head(10)\n\n\n# Gr√°fico\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_point(size = 3, color = \"#4f76df\") +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodios: \", episodios)),nudge_y = 0.35,\n            size = 3.5, \n            face = \"bold\",\n            color = \"#4f76df\", \n            family = \"Atma Medium\") +\n  labs(\n    title = \"Top 10 duplas de personajes con mejor IMDb rating promedio\",\n    y = \"Dupla de personajes\",\n    x = \"IMDb rating promedio\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer c√≥digo\nggsave(\"top_duplas.png\", dpi = 300)\n\n\nY si agregamos donas en vez de puntos?\n\n\nVer c√≥digo\n# Y si metemos una dona en vez de puntos?\nlibrary(ggimage)\n\n# Agregamos una columna con la imagen de la dona\ntop_10_duplas &lt;- top_10_duplas %&gt;% \n  mutate(imagen = \"dona.png\")\n\n# Gr√°fico\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_image(aes(image = imagen), size = 0.06) +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodios: \", episodios)),\n            nudge_y = 0.15,\n            nudge_x = -2.15,\n            size = 3.7,\n            family = \"Atma Medium\",\n            face = \"bold\",\n            color = \"#4f76df\") +\n  labs(\n    title = \"Top 10 duplas de personajes con mejor IMDb rating promedio\",\n    y = \"Dupla de personajes\",\n    x = \"IMDb rating promedio\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer c√≥digo\nggsave(\"top_duplas_dona.png\", dpi = 300)"
  },
  {
    "objectID": "es/microaprendizajes/index.html",
    "href": "es/microaprendizajes/index.html",
    "title": "Microaprendizajes de un proyecto",
    "section": "",
    "text": "Esta presentaci√≥n se centra en algunos microaprendizajes de un proyecto de an√°lisis de resultados de una encuesta de diversidad e inclusi√≥n.\nLo raz√≥n por la que lo llamo ‚Äúmicroaprendizajes‚Äù es porque no tuve que aprender muchas cosas desde cero, pero si aprend√≠ varios truquitos que me sirvieron mucho.\nVoy a usar una encuesta simulada para no violar la confidencialidad de los datos, pero va a ser algo an√°logo a lo que estuve usando en el proyecto.\nPara explotar al m√°ximo esta sesi√≥n conviene saber un poco de hacer informes con RMarkdown. Si necesit√°s un tutorial sobre ese tema te comparto el video que hicimos el a√±o pasado.\n\n\n\n\n\nEste material se puede utilizar y compartir sin fines comerciales y citando la fuente.\n\n\n\nLicencia"
  },
  {
    "objectID": "es/microaprendizajes/index.html#el-chunk-de-setup",
    "href": "es/microaprendizajes/index.html#el-chunk-de-setup",
    "title": "Microaprendizajes de un proyecto",
    "section": "El chunk de ‚Äòsetup‚Äô",
    "text": "El chunk de ‚Äòsetup‚Äô\nEl bloque de c√≥digo de setup es muy √∫til para controlar c√≥mo se van a comportar todos los bloques de c√≥digo.\nMi archivo original tiene +150 bloques de c√≥digo, imaginen si modificara uno por uno las caracter√≠sticas de cada bloque.\n\n\nVer c√≥digo\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.retina = 3,\n                      out.width = \"80%\")"
  },
  {
    "objectID": "es/microaprendizajes/index.html#ordenar-el-c√≥digo",
    "href": "es/microaprendizajes/index.html#ordenar-el-c√≥digo",
    "title": "Microaprendizajes de un proyecto",
    "section": "Ordenar el c√≥digo",
    "text": "Ordenar el c√≥digo\nTener un orden en el c√≥digo es muy importante para poder ir y venir r√°pido y encontrar r√°pidamente las cosas, modificar algo, y dem√°s.\nDentro de los bloques de c√≥digo tambi√©n es importante poner t√≠tulos o marcadores que nos ayuden a encontrar r√°pido las cosas. El orden que defin√≠ fue:\n\nLibrer√≠as.\nConfiguraciones generales\nCarga de datos\nPreprocesamiento y limpieza de datos\nFunciones\n\n\n\nVer c√≥digo\n# Librer√≠as -----\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(scales)\nlibrary(extrafont)\nlibrary(readxl)\n\n\n# Configuraciones generales ----------\n\n# Colores\nverde &lt;- \"#01B3B6\"\nnegro &lt;- \"#333132\"\ngris &lt;- \"#AEB6BF\"\n\ncolor3 &lt;- c(verde, gris, negro)\ncolor2 &lt;- c(verde, negro)\n\n# Opciones de visualizaci√≥n --------\noptions(scipen = 999)   # Modifica la visualizaci√≥n de los ejes num√©rico a valores nominales\n\nloadfonts(quiet = TRUE) # Permite cargar en R otros tipos de fuentes.\n\n# Estilo limpio sin l√≠neas de fondo\nestilo &lt;- theme(panel.grid = element_blank(),\n                plot.background = element_rect(fill = \"#FBFCFC\"),\n                panel.background = element_blank(),\n                text = element_text(family = \"Ubuntu Mono\"))\n\n# Estilo limpio con l√≠neas de referencia verticales en gris claro\nestilov &lt;- theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#FBFCFC\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#ecf0f1\"),\n                 text = element_text(family = \"Ubuntu Mono\"))\n\n# Estilo limpio con l√≠neas de referencia horizontales en gris claro\nestiloh &lt;- theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#FBFCFC\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.y = element_line(color = \"#ecf0f1\"),\n                 text = element_text(family = \"Ubuntu Mono\"))\n\n\n# Creo un objeto con un texto que se va a repetir mucho a lo largo del an√°lisis\nfuente &lt;- \"Club de R para RRHH\\nDatos Ficticios\"\n\n# Creo objetos para formatear las etiquetas num√©ricas de los ejes x e y\neje_x_per &lt;- scale_x_continuous(labels = scales::percent_format(accuracy = 1))\n\neje_y_per &lt;- scale_y_continuous(labels = scales::percent_format(accuracy = 1))\n\n# Carga de Datos -----\nencuesta &lt;- read_excel(\"data/encuesta.xlsx\")\nplantel  &lt;- read_excel(\"data/plantel.xlsx\")\n\n# Preparaci√≥n de datos -----------\n\n# Pivotea el dataset a un formato largo\nenc &lt;- encuesta %&gt;% \n  pivot_longer(cols = c(7:11),\n               names_to = \"pregunta\", \n               values_to = \"valor\")\n\n# Cambia nombres y Organiza variables ordinales \n\nenc &lt;- enc %&gt;% \n  rename(id = \"ID\",\n         genero = `¬øC√≥mo definir√≠as tu identidad de g√©nero?`,\n         unidad = \"Unidad de Negocio\",\n         pais = \"Pa√≠s\",\n         sector = \"Sector\",\n         cargo = \"Tu cargo/nivel:\") %&gt;% \n  mutate(cargo = factor(cargo,\n                        levels = c(\"Management\", \"L√≠der\", \"Contribuidor individual\")))\n\n# Crea categor√≠as de resultados\n\nenc &lt;- enc %&gt;% \n  mutate(resultado = if_else(valor == \"Totalmente de acuerdo\", \"Positivo\", \n                             if_else(valor == \"De acuerdo\", \"Positivo\", \n                                     if_else(valor == \"Ni de acuerdo ni en desacuerdo\",\n                                             \"Neutral\", \"Negativo\"\n      )\n    )\n  ),\n         resultado = factor(resultado, \n                            levels = c(\"Positivo\", \"Neutral\", \"Negativo\")))\n\n\n\nY comenten el c√≥digo por amor a Jeb√∫s!"
  },
  {
    "objectID": "es/microaprendizajes/index.html#poner-el-nombre-a-los-bloques-de-c√≥digo",
    "href": "es/microaprendizajes/index.html#poner-el-nombre-a-los-bloques-de-c√≥digo",
    "title": "Microaprendizajes de un proyecto",
    "section": "Poner el nombre a los bloques de c√≥digo",
    "text": "Poner el nombre a los bloques de c√≥digo\nAlgo muy √∫til es ponerle nombre a los bloques de c√≥digo. Por un lado porque es f√°cil para navegar entre bloques busc√°ndolos en RStudio.\nPor ejemplo, probemos un gr√°fico simple:\n\n\nVer c√≥digo\nggplot(enc, aes(x = pais, fill = resultado)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(color3)) +\n  estiloh +\n  eje_y_per +\n  labs(title = \"Resultados por pa√≠s\",\n       fill = \"Resultado\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nPuede ocurrir que necesitemos reutilizar el gr√°fico. Hacer la gran stackoverflow (copiar y pegar el c√≥digo) es una opci√≥n, pero puede generar errores y por otro lado implica tiempo de procesamiento.\nEn cambio, con la opci√≥n ref.label podemos reutilizar lo que hicimos antes, de una forma m√°s prolija y c√≥moda pasando el nombre del bloque anterior.\nInternamente, lo que hace R es reutilizar el c√≥digo creado anteriormente.\n\n\nVer c√≥digo\n{r ref.label=\"grafico1\"}\n\n\nVoil√°!\n\n\nVer c√≥digo\nggplot(enc, aes(x = pais, fill = resultado)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(color3)) +\n  estiloh +\n  eje_y_per +\n  labs(title = \"Resultados por pa√≠s\",\n       fill = \"Resultado\",\n       x = \"\", y = \"\",\n       caption = fuente)"
  },
  {
    "objectID": "es/microaprendizajes/index.html#etiquetas-largas",
    "href": "es/microaprendizajes/index.html#etiquetas-largas",
    "title": "Microaprendizajes de un proyecto",
    "section": "Etiquetas largas",
    "text": "Etiquetas largas\nA veces necesitamos presentar en un gr√°fico o en una tabla la pregunta original de la encuesta. Por ejemplo, una de las ‚Äúpreguntas‚Äù de la encuesta dice:\n\nOtra pregunta que tiene much√≠simo texto escrito en la encuesta y qued√≥ tan larga que no entra en un solo rengl√≥n y que me hace preguntarme c√≥mo la voy a poner en un gr√°fico\n\nAhora veamos c√≥mo se ven las preguntas en un gr√°fico si intentamos hacer un ranking.\n\n\nVer c√≥digo\nenc %&gt;% \n  group_by(pregunta, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = pregunta)) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nQueda hermoso, no? üò±\nPara sortear este problema podemos crear una columna nueva, y usar la funci√≥n str_wrap() del paquete stringr.\nLo que hace esto es agregar el s√≠mbolo \\n que divide el texto en renglones. Con el par√°metro width le indicamos la cantidad de caracteres de largo que tendr√° cada rengl√≥n.\n\n\nVer c√≥digo\n# Divide el largo de 'funci√≥n' en varias l√≠neas\nenc$preg2 &lt;- str_wrap(enc$pregunta, width = 40)\n\n# Veamos como queda esto en el df\nhead(enc$preg2,5)\n\n\n[1] \"Una pregunta con un texto muy pero muy\\npero muy largo, de verdad que es muy muy\\nmuy largo\"                                                                                     \n[2] \"Otra pregunta que tiene much√≠simo texto\\nescrito en la encuesta y qued√≥ tan larga\\nque no entra en un solo rengl√≥n y que me\\nhace preguntarme c√≥mo la voy a poner en\\nun gr√°fico\"\n[3] \"Los l√≠deres son unos capos\"                                                                                                                                                      \n[4] \"Que grosso es trabajar ac√°\"                                                                                                                                                      \n[5] \"Esta encuesta es genial\"                                                                                                                                                         \n\n\nY ahora podemos hacer un gr√°fico que se vea bien:\n\n\nVer c√≥digo\nenc %&gt;% \n  group_by(preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop))) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nAhora queda mucho mejor üëç\nTambi√©n se puede jugar con la altura del gr√°fico usando la opci√≥n fig.height en las opciones del bloque para que haya m√°s espacio entre las barras.\n\n\nVer c√≥digo\n{r fig.height=8} # El tama√±o es exagerado en este caso\n\n\n\n\nVer c√≥digo\nranking &lt;- enc %&gt;% \n  group_by(preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop))) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\nranking"
  },
  {
    "objectID": "es/microaprendizajes/index.html#texto-en-los-gr√°ficos",
    "href": "es/microaprendizajes/index.html#texto-en-los-gr√°ficos",
    "title": "Microaprendizajes de un proyecto",
    "section": "Texto en los gr√°ficos",
    "text": "Texto en los gr√°ficos\nEs simple agregar las etiquetas de datos a un gr√°fico:\n\n\nVer c√≥digo\nranking +\n  geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            size = 3,                           # Cambia el tama√±o de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\") \n\n\n\n\n\n\n\n\n\nMiremos lo que pasa cuando queremos agregar m√°s informaci√≥n al gr√°fico, por ejemplo, con los resultados por pa√≠s.\n\n\nVer c√≥digo\nranking &lt;- enc %&gt;% \n  group_by(pais, preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop), fill = pais)) +\n  geom_col(position = \"dodge\") +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       fill = \"Pa√≠s\",\n       caption = fuente) +\n  scale_fill_brewer(palette = 2)\n\nranking +\n   geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            size = 3,                           # Cambia el tama√±o de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\")             # Modifica la fuente\n\n\n\n\n\n\n\n\n\nEl problema es que todas las etiquetas de cada barra est√°n centradas con la etiqueta del eje y. En la gu√≠a de geom_text en la documentaci√≥n de ggplot2 encontramos como solucionar el problema usando el par√°metro position_dodge().\n\n\nVer c√≥digo\nranking &lt;- ranking +\n   geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            position = position_dodge(0.9),     # Acomoda cada etiqueta con las barras\n            size = 3,                           # Cambia el tama√±o de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\")             # Modifica la fuente\n\nranking\n\n\n\n\n\n\n\n\n\nOtra mejora que podemos hacer al gr√°fico es acomodar los colores en la leyenda (la referencia de los colores) para que tengan la misma secuencia que tiene en el gr√°fico, es decir que el verde oscuro aparezca primero al igual que la barra con el verde m√°s oscuro en el gr√°fico.\nEn esta p√°gina hay muchas variantes para trabajar con las etiquetas y leyendas.\n\n\nVer c√≥digo\nranking +\n  guides(fill = guide_legend(reverse=TRUE)) + # Invierte el orden de los colores en la leyenda\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\n\nCuando estamos mapeando una variable categ√≥rica en el eje y, R lo ordena alfab√©ticamente desde abajo hacia arriba.\n\n\nVer c√≥digo\nenc %&gt;% \n  group_by(sector, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = sector)) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Resultado Positivos por Sector\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nPodemos usar la funci√≥n fct_rev del paquete forcats para poner al rev√©s las etiquetas del eje y cuando estamos mapeando las variables dentro de ggplot\n\n\nVer c√≥digo\nenc %&gt;% \n  group_by(sector, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = fct_rev(sector))) + # Invertimos el orden del eje y\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Resultado Positivos por Sector\",\n       x = \"\", y = \"\",\n       caption = fuente)"
  },
  {
    "objectID": "es/microaprendizajes/index.html#funciones",
    "href": "es/microaprendizajes/index.html#funciones",
    "title": "Microaprendizajes de un proyecto",
    "section": "Funciones",
    "text": "Funciones\nEsto es un work-in-progress y tengo que agradecer a M√≥nica Alonso de RLadies Buenos Aires por la ayuda.\nEl problema es que me encontr√© muchas veces escribiendo esta secuencia de c√≥digo muchas veces:\n\n\nVer c√≥digo\n# Calcular pocertajes de respuestas\nenc %&gt;% \n  group_by(genero, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant / sum(cant))\n\n\n# A tibble: 6 √ó 4\n# Groups:   genero [2]\n  genero    resultado  cant   prop\n  &lt;chr&gt;     &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 Femenino  Positivo   1127 0.764 \n2 Femenino  Neutral     244 0.165 \n3 Femenino  Negativo    104 0.0705\n4 Masculino Positivo   1477 0.823 \n5 Masculino Neutral     222 0.124 \n6 Masculino Negativo     96 0.0535\n\n\nMuchas veces resolv√≠ copiando y pegando el c√≥digo, pero se hace tedioso controlar cada uno de los bloques de c√≥digo y gr√°ficos. As√≠ que para eso, podemos crear nuestras propias funciones.\n\n\nVer c√≥digo\ncant_prop_gen &lt;- function(df){\n  df %&gt;% \n    group_by(genero,resultado) %&gt;% \n    summarise(cant = n()) %&gt;% \n    mutate(prop = cant / sum(cant)) \n}\n\n\nY ahora lo podemos incorporar en nuestro flujo de trabajo como cualquier funci√≥n.\n\n\nVer c√≥digo\nenc %&gt;% \n  cant_prop_gen() %&gt;% \n  ggplot(aes(x = genero, y = prop, fill = resultado)) +\n  geom_col(position = \"dodge\") +\n  eje_y_per +\n  estiloh +\n  scale_fill_manual(values = color3) +\n  labs(title = \"Resultados por G√©nero\",\n       x = \"\", y = \"\",\n       fill = \"Resultado\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nTodav√≠a estoy resolviendo como crear funciones usando cualquier tipo de variable en la funci√≥n. Por ahora, lo estoy resolviendo creando una funci√≥n para cada combinaci√≥n de variables que agrupo. No es lo ideal, pero es lo que hay. ü§∑\nCapaz encuentre lo que necesito en estos libros:\n\nR para Ciencia de Datos\nHands-On Programming with R\nAdvanced R\n\nYa les contar√©‚Ä¶ stay tuned üì∫"
  },
  {
    "objectID": "es/microaprendizajes/index.html#c√≥digo-inline",
    "href": "es/microaprendizajes/index.html#c√≥digo-inline",
    "title": "Microaprendizajes de un proyecto",
    "section": "C√≥digo Inline",
    "text": "C√≥digo Inline\nComo sabemos, algo interesante de RMarkdown es la posibilidad de utilizar el c√≥digo de los bloques dentro del texto.\nAs√≠ que creemos un peque√±o objeto primero para almacenar los resultados positivos y negativos por g√©nero.\n\n\nVer c√≥digo\nresult_genero &lt;- enc %&gt;% \n  cant_prop_gen()\n\nresult_genero\n\n\n# A tibble: 6 √ó 4\n# Groups:   genero [2]\n  genero    resultado  cant   prop\n  &lt;chr&gt;     &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 Femenino  Positivo   1127 0.764 \n2 Femenino  Neutral     244 0.165 \n3 Femenino  Negativo    104 0.0705\n4 Masculino Positivo   1477 0.823 \n5 Masculino Neutral     222 0.124 \n6 Masculino Negativo     96 0.0535\n\n\nUsando la llamada de datos de un dataframe con nombre_df[fila,columna] puedo usar los resultados almacenados para incluirlos dentro del texto por ejemplo para decir:\nLos resultados positivos para las personas de g√©nero femenino es 0.7640678.\nLo ideal es poder ver ese resultado como un porcentaje, as√≠ que intuitivamente podemos usar la funci√≥n percent para lograr eso‚Ä¶\n‚Ä¶y no va a funcionar. Obtenemos el siguiente mensaje de error:\n\n\nVer c√≥digo\n# Intento de c√≥digo inline\n`r percent(result_genero[1,4])`\n\n# Quitting from lines 425-441 (r4hr_microaprendizajes.Rmd) \n# Error in is.finite(x) : default method not implemented for type 'list'\n\n\nPara que la funci√≥n percent funcione la tenemos que combinar con la funci√≥n pull . Y ahora as√≠ s√≠ funciona:\nLos resultados positivos para las personas de g√©nero femenino es 76% ."
  },
  {
    "objectID": "es/microaprendizajes/index.html#trust-the-tidyverse",
    "href": "es/microaprendizajes/index.html#trust-the-tidyverse",
    "title": "Microaprendizajes de un proyecto",
    "section": "Trust the Tidyverse",
    "text": "Trust the Tidyverse\n\nLo barato sale caro\nDicho popular\n\n\nLa encuesta que est√°bamos analizando era an√≥nima, lo cual hac√≠a imposible poder cruzar datos contra el listado de empleados.\nPero, s√≠ pod√≠amos calcular los resultados seg√∫n la composici√≥n del liderazgo. Para eso ten√≠amos que calcular el porcentaje de l√≠deres hombres y mujeres por sector.\n\n\nVer c√≥digo\n# Cuento la cantidad de l√≠deres por sector y g√©enero\nplantel &lt;- plantel %&gt;% \n  rename(division = `Unidad de Negocio`, \n         lider = L√≠der, \n         sexo = G√©nero, \n         sector = Sector, \n         pais = Pa√≠s) %&gt;% \n  filter(lider == \"true\") %&gt;% \n  group_by(pais, division, sector, lider, sexo) %&gt;% \n  tally() %&gt;% \n  ungroup()\n\nplantel\n\n\n# A tibble: 106 √ó 6\n   pais  division sector           lider sexo          n\n   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;\n 1 Chad  Unidad 1 Comercial        true  Femenino      4\n 2 Chad  Unidad 1 Comercial        true  Masculino     3\n 3 Chad  Unidad 1 R&D              true  Femenino      5\n 4 Chad  Unidad 1 R&D              true  Masculino     1\n 5 Chad  Unidad 2 Administraci√≥n   true  Femenino      3\n 6 Chad  Unidad 2 Administraci√≥n   true  Masculino     6\n 7 Chad  Unidad 2 Calidad          true  Femenino      1\n 8 Chad  Unidad 2 Comercial        true  Femenino      5\n 9 Chad  Unidad 2 Comercial        true  Masculino     1\n10 Chad  Unidad 2 Recursos Humanos true  Femenino      3\n# ‚Ñπ 96 more rows\n\n\n\n\nVer c√≥digo\n# Pivoteo el dataset a un dataset ancho\nplantel &lt;- plantel %&gt;% \n  pivot_wider(.,\n              names_from = sexo,\n              values_from = n)\n\n# Reemplaza los NA con un 0\nplantel[is.na(plantel)] &lt;- 0\n\n\n# Calculo porcentaje de l√≠deres hombres\nplantel %&gt;% \n  mutate(prop_lider_hombre = if_else(Femenino == 0, 1, Masculino / (Masculino +Femenino))) %&gt;% \n  select(-lider)\n\n\n# A tibble: 60 √ó 6\n   pais  division sector           Femenino Masculino prop_lider_hombre\n   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;               &lt;int&gt;     &lt;int&gt;             &lt;dbl&gt;\n 1 Chad  Unidad 1 Comercial               4         3             0.429\n 2 Chad  Unidad 1 R&D                     5         1             0.167\n 3 Chad  Unidad 2 Administraci√≥n          3         6             0.667\n 4 Chad  Unidad 2 Calidad                 1         0             0    \n 5 Chad  Unidad 2 Comercial               5         1             0.167\n 6 Chad  Unidad 2 Recursos Humanos        3         0             0    \n 7 Chad  Unidad 3 Administraci√≥n          2         2             0.5  \n 8 Chad  Unidad 3 Calidad                 2         2             0.5  \n 9 Chad  Unidad 3 Comercial               5        20             0.8  \n10 Chad  Unidad 3 HSE                     1         0             0    \n# ‚Ñπ 50 more rows"
  },
  {
    "objectID": "es/indicadores_capacitacion/index.html",
    "href": "es/indicadores_capacitacion/index.html",
    "title": "Indicadores de Capacitaci√≥n",
    "section": "",
    "text": "Con la Capacitaci√≥n en las empresas pasa algo curioso: hace unos a√±os atr√°s, entre mis compa√±eros de la Maestr√≠a de Data Mining hice una encuesta sobre beneficios, y una de las preguntas que hac√≠a era¬†‚Äú¬øQu√© beneficio que no ten√©s hoy te gustar√≠a tener?‚Äù. Y 1 de cada 4 respuestas estaba relacionada con Capacitaci√≥n (capacitaci√≥n in company, desde cuotas en posgrados, certificaciones, etc.). Y yo pensaba por dentro ‚ÄúPero‚Ä¶ la capacitaci√≥n no es un beneficio‚Äù. Sin embargo las personas perciben a la capacitaci√≥n como un beneficio.\nLos cambios que impone la tecnolog√≠a, y la rapidez con la que avanza, hacen que, como dijo¬†Diego Bekerman, las empresas dejen de buscar¬†‚Äúgraduados de‚Äù¬†para buscar¬†‚Äúpersonas que saben de‚Äù. Esto plantea una nueva necesidad de Planificaci√≥n Estrat√©gica de Capital Humano en donde se plantean las capacidades que hoy tienen las personas y se las contrasta con las capacidades futuras que requiere la empresa. Y ac√° surge una de las primeras cuestiones: Estas capacidades, ¬ølas desarrollamos internamente o las salimos a buscar al mercado?\nDespu√©s tenemos variables de contexto. No debe haber ni un s√≥lo CEO, Gerente General o Due√±o de una empresa que desconozca el valor y la importancia de la capacitaci√≥n de sus empleados. Sin embargo, es uno de los primeros presupuestos que se corta en √©pocas de vacas flacas. Y uno de los principales factores que determinan estas decisiones seguramente se relaciona con que no cuentan con suficiente informaci√≥n sobre el impacto de la capacitaci√≥n en los resultados de la empresa.\nN√≥tese que escrib√≠ impacto en los resultados, no ROI. Ampliaremos.\nEntonces tenemos empleados que demandan capacitaci√≥n, negocios que necesitan nuevas capacidades, y una constante tensi√≥n presupuestaria. Sin mencionar el contexto econ√≥mico recesivo. ¬øC√≥mo podemos usar indicadores para administrar, planificar y conseguir presupuesto para gestionar la capacitaci√≥n en este contexto?\nEn primer lugar conociendo las necesidades del negocio.Y para esto es necesario entender qu√© es lo que demandan las personas que dirigen las empresas.\nEn¬†Learning Analytics, John R Mattox II, Mark Van Buren y Jean Martin, plantean que los CEO‚Äôs pretenden que midamos:\n\nAplicaci√≥n: ¬øC√≥mo Podemos aumentar la aplicaci√≥n de nuevas habilidades en el trabajo\nResultados: ¬øEn qu√© grado un programa de capacitaci√≥n mejorar√° un resultado de negocio espec√≠fico?\nValor: ¬øCu√°l ser√° el Retorno de Inversi√≥n?\n\n¬øQu√© es lo que usualmente medimos en gesti√≥n de capacitaci√≥n?\n\nCosto de capacitaci√≥n por empleado\nSatisfacci√≥n con la capacitaci√≥n.\nHoras de Capacitaci√≥n por Empleado\nGastos de Capacitaci√≥n Externa.\n\nEvidentemente hay un mismatch entre la informaci√≥n que demandan las personas que dirigen las empresas y la informaci√≥n que proveemos desde Recursos Humanos.\nAlec Levenson, uno de los autores m√°s ‚Äúhardcore evidence‚Äù de People Analytics que sigo, de formaci√≥n en Econom√≠a, plantea en una podcast que el ROI no siempre es medible, por ejemplo,de una capacitaci√≥n en empat√≠a para l√≠deres. Alec explica que el ROI se mide fundamentalmente en cashflow, y que no todo es traducible en t√©rminos econ√≥micos.\nUn punto interesante que plantea Levenson es dice que si encontramos v√≠nculos entre c√≥mo las personas operan en el negocio, en c√≥mo se comunican, se hacen cargo y se comprometen, y en c√≥mo enfocan su tiempo y energ√≠a en alcanzar la estrategia del negocio, y haciendo lo que es necesario hacer para crear ventajas competitivas, es todo lo que necesitamos mostrar. Si logramos establecer una relaci√≥n consistente entre los comportamientos de las personas y las ventajas competitivas, generamos informaci√≥n m√°s valiosa y expresiva (agrego yo) que el ROI.\n\n\nSi buscamos en nuestros apuntes y libros de la universidad como medir la gesti√≥n de capacitaci√≥n, seguramente nos vamos a encontrar con los modelos de¬†Donald Kirkpatrick¬†y de¬†Jack Phillips.\nEl Modelo de 4 Niveles de Evaluaci√≥n de Kirkpatrick propone un enfoque para medir el impacto de la capacitaci√≥n en los siguientes niveles:\nEl primer nivel apunta a medir la satisfacci√≥n de los colaboradores con el curso y con el facilitador. Muchas empresas s√≥lo est√°n midiendo este nivel. El aprendizaje busca medir si las personas adquirieron nuevos conocimientos y habilidades.\nRespecto al nivel 3, de medir conductas, Kirkpatrick plantea analizar si hubo un cambio de comportamiento luego de la capacitaci√≥n. Volvamos a la entrevista de Alec Levenson, ¬øcu√°les son los comportamientos que crean ventajas competitivas?\nFinalmente el 4¬∞ nivel es el de resultados, que ah√≠ buscaremos ver el impacto de las acciones de capacitaci√≥n en resultados tanto operativos como de clima laboral por ejemplo.\nJack Phillips desarroll√≥ la¬†Metodolog√≠a ROI¬†que en gran parte se sustenta en el modelo de Kirkpatrick, cambiando ligeramente los primeros 4 niveles, y a√±adiendo el del ROI.\n\nReacci√≥n y acci√≥n planificada.\nAprendizaje.\nAplicaci√≥n.\nImpacto.\nRetorno de Inversi√≥n.\n\nEstos 5 niveles son parte de la Metodolog√≠a ROI que incluye adem√°s la planificaci√≥n, la recolecci√≥n de datos, su an√°lisis y reporte.\nMi postura es que si hoy s√≥lo estamos midiendo horas de capacitaci√≥n y costos, lograr avanzar al nivel 3 (Conductas o Aplicaci√≥n), ya es un enorme salto de calidad de las m√©tricas del √°rea. Si logramos eso, ser√° m√°s f√°cil medir resultados, y ya habr√° tiempo para medir el ROI.\nKirkpatrick desarroll√≥ su modelo en la d√©cada del ‚Äô50, mientras que Phillips lo hizo a principios de los ‚Äô80. En 2007 Josh Bersin public√≥¬†The Training Measurement Book, en donde se enfoca principalmente en la planificaci√≥n y en el alineamiento de la capacitaci√≥n con las necesidades del negocio.\nEl modelo de Bersin propone 9 m√©tricas cr√≠ticas para su¬†Modelo de Medici√≥n de Impacto. Estas m√©tricas son:\n\nSatisfacci√≥n.\nAprendizaje.\nAdopci√≥n (tasa del p√∫blico target que complet√≥ el proceso de aprendizaje).\nUtilidad.\nEficiencia.\nAlineamiento.\nLogros de objetivos desde la perspectiva de los clientes.\nDesempe√±o Individual.\nDesempe√±o del Negocio.\n\nSi logramos incorporar m√©tricas que incluyan los aspectos de cualquiera de estos modelos, m√°s nuevas tendencias como el¬†Scrap Learning¬†(incluyendo la perspectiva de los jefes) podemos construir un set de informaci√≥n muy valiosa para los stakeholders de la organizaci√≥n. Correr el foco del ROI y enfocarlo en las ventajas competitivas (eso que la empresa hace bien y que la distingue de otras empresas) tambi√©n nos permite canalizar los esfuerzos de gesti√≥n y de an√°lisis en donde m√°s valor aportamos a la rentabilidad del negocio."
  },
  {
    "objectID": "es/indicadores_capacitacion/index.html#de-vuelta-a-la-universidad",
    "href": "es/indicadores_capacitacion/index.html#de-vuelta-a-la-universidad",
    "title": "Indicadores de Capacitaci√≥n",
    "section": "",
    "text": "Si buscamos en nuestros apuntes y libros de la universidad como medir la gesti√≥n de capacitaci√≥n, seguramente nos vamos a encontrar con los modelos de¬†Donald Kirkpatrick¬†y de¬†Jack Phillips.\nEl Modelo de 4 Niveles de Evaluaci√≥n de Kirkpatrick propone un enfoque para medir el impacto de la capacitaci√≥n en los siguientes niveles:\nEl primer nivel apunta a medir la satisfacci√≥n de los colaboradores con el curso y con el facilitador. Muchas empresas s√≥lo est√°n midiendo este nivel. El aprendizaje busca medir si las personas adquirieron nuevos conocimientos y habilidades.\nRespecto al nivel 3, de medir conductas, Kirkpatrick plantea analizar si hubo un cambio de comportamiento luego de la capacitaci√≥n. Volvamos a la entrevista de Alec Levenson, ¬øcu√°les son los comportamientos que crean ventajas competitivas?\nFinalmente el 4¬∞ nivel es el de resultados, que ah√≠ buscaremos ver el impacto de las acciones de capacitaci√≥n en resultados tanto operativos como de clima laboral por ejemplo.\nJack Phillips desarroll√≥ la¬†Metodolog√≠a ROI¬†que en gran parte se sustenta en el modelo de Kirkpatrick, cambiando ligeramente los primeros 4 niveles, y a√±adiendo el del ROI.\n\nReacci√≥n y acci√≥n planificada.\nAprendizaje.\nAplicaci√≥n.\nImpacto.\nRetorno de Inversi√≥n.\n\nEstos 5 niveles son parte de la Metodolog√≠a ROI que incluye adem√°s la planificaci√≥n, la recolecci√≥n de datos, su an√°lisis y reporte.\nMi postura es que si hoy s√≥lo estamos midiendo horas de capacitaci√≥n y costos, lograr avanzar al nivel 3 (Conductas o Aplicaci√≥n), ya es un enorme salto de calidad de las m√©tricas del √°rea. Si logramos eso, ser√° m√°s f√°cil medir resultados, y ya habr√° tiempo para medir el ROI.\nKirkpatrick desarroll√≥ su modelo en la d√©cada del ‚Äô50, mientras que Phillips lo hizo a principios de los ‚Äô80. En 2007 Josh Bersin public√≥¬†The Training Measurement Book, en donde se enfoca principalmente en la planificaci√≥n y en el alineamiento de la capacitaci√≥n con las necesidades del negocio.\nEl modelo de Bersin propone 9 m√©tricas cr√≠ticas para su¬†Modelo de Medici√≥n de Impacto. Estas m√©tricas son:\n\nSatisfacci√≥n.\nAprendizaje.\nAdopci√≥n (tasa del p√∫blico target que complet√≥ el proceso de aprendizaje).\nUtilidad.\nEficiencia.\nAlineamiento.\nLogros de objetivos desde la perspectiva de los clientes.\nDesempe√±o Individual.\nDesempe√±o del Negocio.\n\nSi logramos incorporar m√©tricas que incluyan los aspectos de cualquiera de estos modelos, m√°s nuevas tendencias como el¬†Scrap Learning¬†(incluyendo la perspectiva de los jefes) podemos construir un set de informaci√≥n muy valiosa para los stakeholders de la organizaci√≥n. Correr el foco del ROI y enfocarlo en las ventajas competitivas (eso que la empresa hace bien y que la distingue de otras empresas) tambi√©n nos permite canalizar los esfuerzos de gesti√≥n y de an√°lisis en donde m√°s valor aportamos a la rentabilidad del negocio."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html",
    "href": "es/comparando-visualizaciones/index.html",
    "title": "Comparando Visualizaciones",
    "section": "",
    "text": "Hace unos a√±os atr√°s, el 22/2/22 para ser exactos, hice un art√≠culo en ingl√©s comparando gr√°ficos, luego de que Paul Van Der Laken PhD recomendara en LinkedIn un art√≠culo de Nick Desbarats se√±alando los problemas de los boxplots en su fant√°stico sitio Nightingale Journal of Data Visualization Society.\nLo que pas√≥ fue que en R4HR hab√≠amos hecho un boxplot que nos result√≥ muy √∫til para evidenciar las desigualdades salariales entre hombres y mujeres, entonces me convert√≠ en un palad√≠n de los boxplots. Bueno, estoy exagerando, pero la realidad es que no existen gr√°ficos mejores o peores que otros, sino gr√°ficos que sirven a un prop√≥sito.\nEn fin, hace poco tuve un intercambio con Nick, y entonces pens√© que ser√≠a una buena idea reflotar ese art√≠culo en castellano para mi comunidad. As√≠ que aqu√≠ lo tienen, un nuevo autoplagio üòé."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#preparaci√≥n-de-datos",
    "href": "es/comparando-visualizaciones/index.html#preparaci√≥n-de-datos",
    "title": "Comparando Visualizaciones",
    "section": "Preparaci√≥n de datos",
    "text": "Preparaci√≥n de datos\nEstoy cargando datos desde la fuente original. Por eso, esto requiere algo de limpieza de datos. Los datos est√°n filtrados para mostrar solo los resultados de Argentina, y realic√© algunos c√°lculos para estimar los salarios de medio tiempo como equivalentes a un salario de tiempo completo. Esos son los datos que voy a usar para hacer las visualizaciones. Pod√©s descargar una versi√≥n limpia de estos datos desde este repositorio de GitHub.\n\n\nVer c√≥digo\n# Librarias & Data ----\nlibrary(tidyverse)    # Limpieza y Manipulaci√≥n de Datos\nlibrary(funModeling)  # Exploraci√≥n y limpieza de datos y mucho m√°s\nlibrary(scales)       # Ajustes a c√≥mo ver las escalas de los ejes\nlibrary(googlesheets4) # Leer archivos de Google Sheets\nlibrary(gargle)       # Para lidiar con los caracteres especiales del castellano\n\n# Data\nsalaries &lt;- read_sheet(\"1aeuu9dVfN42EjyvbmhEcsf0ilSz2DiXU-0MpnF896ss\") %&gt;% \n    select(gender = \"G√©nero\",\n           role = \"¬øEn qu√© puesto trabaj√°s?\",\n           gross_salary = \"¬øCu√°l es tu remuneraci√≥n BRUTA MENSUAL en tu moneda local? (antes de impuestos y deducciones)\",\n           country = \"Pa√≠s en el que trabajas\",\n           work_type = \"Trabajo\",\n           work_hours = \"Tipo de contrataci√≥n\") %&gt;% \n  filter(country == \"Argentina\",\n         work_type == \"Relaci√≥n de Dependencia\",\n         gender %in% c(\"Femenino\", \"Masculino\")) %&gt;% \n  select(-country, -work_type)\n\n## Limpieza de datos (no hay escapatoria de esto) ----\nsalaries &lt;- salaries %&gt;% \n  mutate(gross_salary = as.numeric(unlist(gross_salary)))\n\n# A√±ade columna para estimar el salario full time de trabajadores part time\nsalaries &lt;- salaries %&gt;% \n  mutate(multiplier = if_else(work_hours == \"Part time\", 1.5, 1),\n         ft_salary = gross_salary * multiplier) %&gt;% \n  select(-work_hours, -multiplier, -gross_salary)\n\n# Filtro y unificaci√≥n de roles \nsalaries &lt;- salaries %&gt;% \n  filter(role != \"Juzgado Civil y Comercial\",\n         role != \"Programador\",\n         role != \"Cuidado\",\n         role != \"Asesor\",\n         role != \"Jefe de Proyecto\") %&gt;% \n  mutate(role = str_trim(role, side = \"both\"), # Elimina espacios vac√≠os\n         role = fct_collapse(role, \"Gerente\" = \"Superintendente\"),\n         role = fct_collapse(role, \"Director\" = \"Director ( escalaf√≥n municipal)\"),\n         role = fct_collapse(role, \"HRBP\" = c(\"Senior Consultor√≠a\", \"specialist\", \"especialista\",\n                                                  \"Especialista en selecci√≥n IT\", \"Recruiter\")),\n         role = fct_collapse(role, \"Responsable\" = c(\"Coordinaci√≥n\", \"Coordinador de Payroll\",\n                                                         \"Encargado\", \"Supervisor\")),\n         role = fct_collapse(role, \"Administrativo\" = c(\"Asistente\", \"Asistente RRHH\", \"Aux\", \n                                                            \"Capacitador\", \"Consultor Ejecutivo\",\n                                                            \"consultor jr\")),\n         role = fct_collapse(role, \"Analista\" = c(\"Asesoramiento\", \"Consultor\", \"Generalista\", \n                                                      \"Reclutadora\", \"Selectora\", \"Senior\"))) \n\n# Filtra roles para analizar\nsalaries &lt;- salaries %&gt;% \n  filter(role %in% c(\"Analista\", \"HRBP\", \"Responsable\",\n                     \"Jefe\", \"Gerente\"))\n\n# Graba el dataframe en un csv para compartir.\nwrite_delim(salaries, file = \"hr_salaries_arg.csv\",\n            delim = \";\")\n\n\nLa siguiente secci√≥n es para customizar los gr√°ficos.\n\n\nVer c√≥digo\noptions(scipen = 999) # Cambia la notaci√≥n cient√≠fica por valores nominales\n\n# Estilo limpio con l√≠neas horizontales grises\nstyleh &lt;- theme(panel.grid = element_blank(),\n                plot.background = element_rect(fill = \"#FBFCFC\"),\n                panel.background = element_blank(),\n                panel.grid.major.y = element_line(color = \"#EAEDED\"),\n                axis.ticks.y = element_blank(),\n                plot.title.position = \"plot\")\n\n# Estilo limpio con l√≠neas verticales grises\nstylev &lt;- theme(panel.grid = element_blank(),\n                plot.background = element_rect(fill = \"#FBFCFC\"),\n                panel.background = element_blank(),\n                panel.grid.major.x = element_line(color = \"#EAEDED\"),\n                axis.ticks.x = element_blank(),\n                plot.title.position = \"plot\")\n\n\n# Modifica la forma en que se muestran los ejes\naxis_x_n &lt;- scale_x_continuous(labels = comma_format(big.mark = \".\", decimal.mark = \",\"))\naxis_y_n &lt;- scale_y_continuous(labels = comma_format(big.mark = \".\", decimal.mark = \",\"))\n\n\n# Colores\ngender_colors &lt;- genero &lt;- c(\"#8624F5\", \"#1FC3AA\") # Purple and green (sort of :p)\n\n# Fuente de datos\nfuente &lt;- \"Data Source: Encuesta KIWI de Sueldos de RRHH LATAM 2020\\nR4HR Club de R para RRHH\"\n\n\nVeamos un resumen de los datos.\n\n\nVer c√≥digo\n# Ordena los puestos por jerarqu√≠a\nsalaries &lt;- salaries %&gt;% \n  mutate(role = fct_relevel(role, c(\"Analista\", \"HRBP\", \"Responsable\",\n                                   \"Jefe\", \"Gerente\"))) \n\n# Veamos un resumen de los datos\nsummary(salaries)\n\n\n    gender                      role       ft_salary      \n Length:536         Analista      :223   Min.   :      2  \n Class :character   Responsable   :136   1st Qu.:  56000  \n Mode  :character   Jefe          : 72   Median :  75000  \n                    HRBP          : 57   Mean   :  93288  \n                    Gerente       : 48   3rd Qu.: 105250  \n                    Administrativo:  0   Max.   :2140000  \n                    (Other)       :  0                    \n\n\nHay un par de valores inusuales. Primero, el valor m√≠nimo, que claramente es un error (o alguien con malas intenciones), y luego el valor m√°ximo, que podr√≠a ser posible, pero es altamente inusual para el mercado argentino. Si hacemos un histograma, el resultado ser√≠a extra√±o.\n\n\nVer c√≥digo\nggplot(salaries, aes(x = ft_salary)) +\n  geom_histogram() +\n  labs(title = paste0(\"Distribuci√≥n de Salario Bruto en HR \", emo::ji(\"scream\")),\n       subtitle = \"Datos de Argentina | en AR$\",\n       x = NULL, y = NULL,\n       caption = fuente) +\n  axis_x_n +\n  styleh\n\n\n\n\n\n\n\n\n\nAc√° es donde funModeling hace su magia. La funci√≥n profiling_num arroja una tabla con un mont√≥n de informaci√≥n estad√≠stica de resumen.\n\n\nVer c√≥digo\n(numerical &lt;- profiling_num(salaries))\n\n\n   variable     mean  std_dev variation_coef  p_01  p_05  p_25  p_50   p_75\n1 ft_salary 93287.88 104693.9       1.122267 217.5 35000 56000 75000 105250\n    p_95   p_99 skewness kurtosis   iqr        range_98        range_80\n1 195500 290000 14.41845  275.362 49250 [217.5, 290000] [44500, 150000]\n\n\nDado que quiero analizar los valores centrales de los salarios, voy a eliminar todos los valores por fuera de los percentiles 5 y 95.\n\n\nVer c√≥digo\n# Guarda los valores de los percentiles 5 y 95 de la tabla numerical\np05 &lt;- numerical[1,6]\np95 &lt;- numerical[1,10]\n\n# Filtra valores dentro del rango de los percentiles p05 y p95\nsalaries &lt;- salaries %&gt;% \n  filter(between(    # Funci√≥n de soporte\n    ft_salary,       # Variable a filtrar\n    p05,             # Umbral m√≠nimo\n    p95              # Umbral m√°ximo\n  ))\n\n# Elimino objetos que no voy a volver a usar\nrm(numerical, p05, p95)\n\n\nAhora que tenemos una versi√≥n m√°s limpia de los datos podemos empezar a comparar las visualizaciones.\n\n\nVer c√≥digo\nggplot(salaries, aes(x = ft_salary)) +\n  geom_histogram() +\n  labs(title = \"Distribuci√≥n de Salario Bruto en HR | Datos Limpios\",\n       subtitle = \"Data de Argentina | en AR$\",\n       x = NULL, y = NULL,\n       caption = fuente) +\n  axis_x_n +\n  styleh"
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#boxplots",
    "href": "es/comparando-visualizaciones/index.html#boxplots",
    "title": "Comparando Visualizaciones",
    "section": "Boxplots",
    "text": "Boxplots\nEn el debate en LinkedIn, Nick Desbarats dice que tiene problemas para encontrar casos de uso donde los boxplots fueran la mejor opci√≥n, as√≠ que compart√≠ el siguiente gr√°fico:\n\n\nVer c√≥digo\nggplot(salaries, aes(x = role, y = ft_salary, fill = gender)) +\n  geom_boxplot() +\n  scale_fill_manual(values = gender_colors) +\n  axis_y_n +\n  styleh +\n  labs(title = \"Distribuci√≥n Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"G√©nero\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nLo que me gusta de este gr√°fico es que podemos ver la distribuci√≥n de los salarios por el tama√±o de cada mitad de las cajas. Usemos de ejemplo la posici√≥n de Jefe. Las medianas entre hombres y mujeres son similares, pero en el caso de las mujeres la mitad inferior es m√°s grande que la de los varones, indicando que el rango de salarios de las mujeres es m√°s amplio. Eso nos dice que hay mujeres en la posici√≥n de Jefe con sueldos muy por debajo de la mediana.\nLo opuesto ocurre con profesionales masculinos en el puesto de Jefe. La mitad superior de la caja es m√°s amplia, indicando que hay hombres con sueldos muy por encima de la mediana.\nNick tiene un punto a su favor. ¬øCu√°ntos casos tenemos en cada rol? ¬ø3, 15, 300? No lo podemos saber con este tipo de gr√°fico. Entonces √©l sugiri√≥ probar con un gr√°fico de viol√≠n. As√≠ que, veamos qu√© ocurre."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#violin-plot",
    "href": "es/comparando-visualizaciones/index.html#violin-plot",
    "title": "Comparando Visualizaciones",
    "section": "Violin plot",
    "text": "Violin plot\nLos gr√°ficos de viol√≠n son una alternativa a los boxplots. Muestran el rango de valores con su largo, y las distintas concentraciones de datos con su ancho. La secci√≥n m√°s ancha del gr√°fico suele indicar la mediana de los valores num√©ricos.:\n[\nConvirtamos nuestro boxplot original en un gr√°fico de viol√≠n.\n\n\nVer c√≥digo\nggplot(salaries, aes(x = role, y = ft_salary, fill = gender)) +\n  geom_violin() +\n  scale_fill_manual(values = gender_colors) +\n  axis_y_n +\n  styleh +\n  labs(title = \"Distribuci√≥n Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"G√©nero\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nDada la cantidad de roles, no podemos apreciar el valor de este tipo de gr√°fico. As√≠ que repitamos el ejercicio pero s√≥lo con los Analistas y Gerentes\n\n\nVer c√≥digo\nsalaries %&gt;% \n  filter(role %in% c(\"Analista\", \"Gerente\")) %&gt;% \n  ggplot(aes(x = role, y = ft_salary, fill = gender)) +\n  geom_violin() +\n  scale_fill_manual(values = gender_colors) +\n  axis_y_n +\n  styleh +\n  labs(title = \"Distribuci√≥n Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"G√©nero\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nEl ancho de cada gr√°fico indica que esa zona contiene mayor cantidad de casos. Para Gerentes hombres, podemos apreciar que la mayor√≠a de los casos est√°n cerca de la mediana. El largo o altura del gr√°fico indica el rango de valores. Para el caso de las Gerentas ese rango va desde aproximadamente AR$ 50.000 hasta cerca de los AR$ 200.000 y el ancho es bastante parejo a lo largo de las observaciones.\nEn el caso de los analistas, en las mujeres vemos que la secci√≥n m√°s ancha se encuentra en torno a los AR$ 50.000 y se hace m√°s delgada hacia arriba. En el caso de los varones, la parte m√°s ancha del gr√°fico est√° m√°s arriba que el de las mujeres, y el rango se expande hasta valores m√°s altos.\nTal vez para este dataset, el gr√°fico de viol√≠n no sea la mejor opci√≥n para ver todos los roles juntos, as√≠ que probemos el gr√°fico de dispersi√≥n o scatter plot."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#scatter-plot",
    "href": "es/comparando-visualizaciones/index.html#scatter-plot",
    "title": "Comparando Visualizaciones",
    "section": "Scatter plot",
    "text": "Scatter plot\nUna manera de ver la distribuci√≥n de los puntos de datos es mediante el scatter plot o gr√°ficos de dispersi√≥n. Tendemos a usarlos para visualizar las relaciones entre dos variables num√©ricas, pero tambi√©n podemos utilizarlos cuando tenemos una variable nominal.\n\n\nVer c√≥digo\nggplot(salaries, aes(x = role, y = ft_salary, color = gender)) +\n  geom_point(size = 3,\n             alpha = 0.2,\n             position = position_jitter(0.3)) +\n  scale_color_manual(values = gender_colors) +\n  styleh +\n  axis_y_n +\n  labs(title = \"Distribuci√≥n Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"G√©nero\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nNuevamente, con este dataset el scatter plot puede ser m√°s confuso dado que en ciertos roles, como el de Analista o el Responsable tienen muchas observaciones, se dificulta apreciar las diferencias por color. Pero por ejemeplo, en el caso de los Gerentes se puede apreciar el rango de los salarios y d√≥nde se concentran en el caso de los varones.\nProbemos separar los gr√°ficos en gr√°ficos m√°s chicos para ver si ayuda a clarificar la interpretaci√≥n de los datos.\n\n\nVer c√≥digo\n# Calcular mediana de los salarios por g√©nero y rol \nmedian_salaries &lt;- salaries %&gt;%\n  group_by(gender, role) %&gt;%\n  summarise(median_salary = median(ft_salary, na.rm = TRUE), .groups = \"drop\")\n\nmedian_salaries &lt;- median_salaries %&gt;%\n  mutate(x = as.numeric(as.factor(gender)) - 0.4,  # Ajusta el inicio de la l√≠nea\n         xend = as.numeric(as.factor(gender)) + 0.4) # Ajusta el final de la l√≠nea\n\n# Gr√°fico\n## Scatter plot\nggplot(salaries, aes(x = gender, y = ft_salary, color = gender)) +\n  geom_point(size = 2,\n             alpha = 0.3,\n             position = position_jitter(0.22)) +\n  ## Customiza colores\n  scale_color_manual(values = gender_colors) +\n  ## A√±ade l√≠neas de medianas\n  geom_segment(data = median_salaries, \n               aes(x = x, xend = xend, \n                   y = median_salary, \n                   yend = median_salary, \n                   color = gender), \n               size = 1,\n               show.legend = FALSE) +\n  ## Customiza el estilo del gr√°fico\n  styleh +\n  ## Customiza las etiquetas del eje y\n  axis_y_n +\n  ## Modifica t√≠tulos y ejes\n  labs(title = \"Distribuci√≥n Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"G√©nero\",\n       caption = paste0(fuente,\"\\nSugerencias por Nick Desbarats\")) +\n  ## Divide el gr√°fico en subgr√°ficos por rol\n  facet_wrap(~role, nrow = 1) +\n  # Modificaciones est√©ticas adicionales al gr√°fico sugeridas por Nick Desbarats\n  theme(axis.title.y = element_text(color = \"grey30\", family = \"Poppins\"),\n        axis.text.x = element_blank(),\n        legend.position = \"top\",            # Mueve la leyenda arriba del gr√°fico\n        legend.justification = \"left\",      # Centra la leyenda horizontalmente\n        legend.box.just = \"left\",           # Alinea el contenido de la caja de la leyenda \n        legend.margin = margin(l = -50, t = 3),\n        panel.spacing = unit(25, \"pt\"),\n        strip.background = element_blank(),\n        stripp.text.x = element_text(face = \"bold\"),\n        axis.ticks.x = element_blank())\n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Guarda el gr√°fico en un archivo png\nggsave(\"jittered_strip.png\", dpi = 300)\n\n\nAhora podemos apreciar de mejor manera todas las posiciones de los puntos de datos, donde los datos est√°n m√°s concentrados y tambi√©n los diferentes rangos de los salarios tanto para hombres como para mujeres en los diferentes roles. Por lo tanto, es m√°s f√°cil comparar y analizar los resultados y ver el n√∫mero de observaciones.\nDado que estoy dise√±ando todas estas visualizaciones, podr√≠a estar sesgado, pero en mi opini√≥n, al ver todos los roles juntos en una visualizaci√≥n, la carga cognitiva aumenta para interpretar la situaci√≥n salarial tanto para el g√©nero como para todos los roles a la vez."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#paquetes-de-r-utilizados",
    "href": "es/comparando-visualizaciones/index.html#paquetes-de-r-utilizados",
    "title": "Comparando Visualizaciones",
    "section": "Paquetes de R Utilizados",
    "text": "Paquetes de R Utilizados\nEstos son los paquetes de R usados para hacer este post:\n\nfunModeling: Pablo Casas (2020). funModeling: Exploratory Data Analysis and Data Preparation Tool-Box. R package, version 1.9.4. https://CRAN.R-project.org/package=funModeling\ntidyverse: Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686\nscales: Hadley Wickham and Dana Seidel (2020). scales: Scale Functions for Visualization. R package version 1.1.1. https://CRAN.R-project.org/package=scales\ngooglesheets4: Jennifer Bryan (2021). googlesheets4: Access Google Sheets using the Sheets API V4. R package version 1.0.0. https://CRAN.R-project.org/package=googlesheets4\ngargle: Jennifer Bryan, Craig Citro and Hadley Wickham (2021). gargle: Utilities for Working with Google APIs. R package version 1.2.0. https://CRAN.R-project.org/package=gargle\nemo: Hadley Wickham, Romain Fran√ßois and Lucy D‚ÄôAgostino McGowan (2021). emo: Easily Insert ‚ÄòEmoji‚Äô. R package version 0.0.0.9000. https://github.com/hadley/emo"
  },
  {
    "objectID": "es/animando_graficos/index.html",
    "href": "es/animando_graficos/index.html",
    "title": "Animando gr√°ficos con gganimate",
    "section": "",
    "text": "Hace rato que no hac√≠a boludeces, as√≠ que mientras pensaba un fin de semana qu√© pod√≠a hacer, Boca jugaba un nuevo partido en el cual empez√≥ perdiendo y termin√≥ ganando, y me d√≠ cuenta que nunca hab√≠a usado el paquete gganimate para animar una visualizaci√≥n, as√≠ que qu√© mejor que usar un partido de Boca para transmitir las sensaciones del partido a trav√©s de un gr√°fico animado."
  },
  {
    "objectID": "es/animando_graficos/index.html#bocaaa-bocaaaa-bocaaaaaa",
    "href": "es/animando_graficos/index.html#bocaaa-bocaaaa-bocaaaaaa",
    "title": "Animando gr√°ficos con gganimate",
    "section": "Bocaaa, Bocaaaa, Bocaaaaaa‚Ä¶ üíôüíõüíô",
    "text": "Bocaaa, Bocaaaa, Bocaaaaaa‚Ä¶ üíôüíõüíô\nDesde que Diego Martinez, el actual DT de Boca, asumi√≥ su cargo en Diciembre de 2023, una de las caracter√≠sticas que tiene su gesti√≥n (adem√°s de jugar mejor), es que varios partidos los comenz√≥ perdiendo, y termin√≥ ganando. Al d√≠a de hoy, (22 de mayo de 2024), gan√≥ 12 partidos, de los cuales en 5 el primer gol lo hizo el rival.\nAs√≠ que qu√© mejor ejemplo para graficar este caso de uso que aprovechando el vendaval de sensaciones que es mirar un partido de Boca Jrs. en la era Martinez.\nEn la fecha 2 del torneo local, Boca enfrent√≥ como visitante a Central C√≥rdoba de Santiago del Estero, que convirtieron el primer gol a los 3‚Äô de comenzado el partido, y luego hicieron el 2-0 en el tiempo a√±adido al final del primer tiempo.\nApenas comenz√≥ el 2¬∞ tiempo, Equi Fernandez hizo el 2-1, la Bestia Merentiel lo empat√≥ y lo di√≥ vuelta a los 52‚Äô y 80‚Äô respectivamente. Cuando el partido estaba en tiempo a√±adido, Equi Fernandez puso el 2-4 final.\nAcomp√°√±enme a experimentar el vendaval de sensaciones que es vivir un partido de Boca en un gr√°fico.\nVamos a usar el siguiente dataset:\n\n\nVer c√≥digo\n# Carga de datos\nboca &lt;- read_excel(\"boca_vibes.xlsx\")\n\n# Explora las primeras 6 filas\nhead(boca)\n\n\n# A tibble: 6 √ó 5\n  minuto central_cordoba  boca diferencia resultado  \n   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;      \n1      1               0     0          0 Empata Boca\n2      2               0     0          0 Empata Boca\n3      3               1     0         -1 Pierde Boca\n4      4               1     0         -1 Pierde Boca\n5      5               1     0         -1 Pierde Boca\n6      6               1     0         -1 Pierde Boca\n\n\nEl dataset contiene un detalle de los resultados minuto a minuto, podemos observar el primer gol de Central C√≥rdoba convertido por Rodrigo Uriel Atencio a los 3 minutos que deja a Boca abajo en el marcador.\nPara hacer el primer gr√°fico necesitamos transformar un poco los datos para que los goles de central_cordoba y de boca nos queden en una misma columna.\n\n\nVer c√≥digo\npartido &lt;- boca |&gt; \n  pivot_longer(cols = c(central_cordoba, boca), \n               names_to = \"equipo\", \n               values_to = \"goles\") |&gt; \n  mutate(equipo = str_replace(equipo, \"central_cordoba\", \"Central C√≥rdoba\"),\n         equipo = str_replace(equipo, \"boca\", \"Boca Jrs.\"))\n\n# Ver c√≥mo qued√≥ el dataset\nhead(partido)\n\n\n# A tibble: 6 √ó 5\n  minuto diferencia resultado   equipo          goles\n   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt;\n1      1          0 Empata Boca Central C√≥rdoba     0\n2      1          0 Empata Boca Boca Jrs.           0\n3      2          0 Empata Boca Central C√≥rdoba     0\n4      2          0 Empata Boca Boca Jrs.           0\n5      3         -1 Pierde Boca Central C√≥rdoba     1\n6      3         -1 Pierde Boca Boca Jrs.           0\n\n\nUsemos un gr√°fico de l√≠neas para visualizar el partido.\n\n\nVer c√≥digo\n ggplot(partido) +                                           # Datos\n  geom_line(aes(x = minuto, y = goles, color = equipo),      # Tipo de gr√°fico y variables\n            linewidth = 1.1) +                               # Ancho de la l√≠nea\n  scale_color_manual(values = c(\"#103f79\", \"#EA0838\")) +     # Colores custom\n  theme_minimal() +                                          # Estilo del gr√°fico\n  labs(title = \"Central C√≥rdoba vs. Boca\",\n       x = \"Goles\", y = \"Minuto\",\n       color = \"Equipo\")\n\n\n\n\n\n\n\n\n\nLe podemos incorporar una l√≠nea adicional para visualizar c√≥mo iba el partido para Boca, en el cual podemos apreciar c√≥mo arranca perdiendo, cerca del minuto ‚Äô50 lo empata, y en el final lo da vuelta.\n\n\nVer c√≥digo\n# Guardamos el gr√°fico en un objeto llamado 'p'\np &lt;-  ggplot(partido) +                                           # Datos\n  geom_line(aes(x = minuto, y = goles, color = equipo),      # Tipo de gr√°fico y variables\n            linewidth = 1.1) +                               # Ancho de la l√≠nea\n  scale_color_manual(values = c(\"#103f79\", \"#EA0838\")) +         # Colores custom\n  theme_minimal() +                                          # Estilo del gr√°fico\n  labs(title = \"Central C√≥rdoba vs. Boca\",\n       x = \"Minuto\", y = \"Goles\",\n       color = \"Equipo\") +\n  geom_line(data = boca, aes(x = minuto, y = diferencia), linewidth = 1.3,\n            linetype = 2)\n\n# Veamos el gr√°fico\np\n\n\n\n\n\n\n\n\n\nPero venimos a ver un gr√°fico animado, as√≠ que demosle movimiento al gr√°fico.\n\n\nVer c√≥digo\n# Animemos el gr√°fico\n# transition_reveal funciona con gr√°ficos de l√≠neas\np + \n  transition_reveal(along = minuto) # MAGIA!!!!\n\n\n\n\n\n\n\n\n\nY manipulando un poco los datos podemos hacer cosas gloriosas‚Ä¶\n\n\nVer c√≥digo\n# A√±adir una columna para agregar un emoji en funci√≥n de la diferencia y los goles\nboca &lt;- boca |&gt; \n  # Arranca el partido\n  mutate(estado = if_else(diferencia == 0 , \"meh\", if_else( \n  # Primer gol de Central C√≥rdoba\n    diferencia &lt; 0 & central_cordoba == 1, \"cry\",  if_else(\n  # Segundo gol de Central C√≥rdoba\n      diferencia &lt; 0 & central_cordoba == 2, \"angry\", if_else(\n  # Primer gol de Boca\n        diferencia &lt; 0 & boca == 1, \"fear\", if_else(\n  # Segundo gol de Boca\n          diferencia == 1 & boca == 2, \"biceps\", if_else(\n  # Tercer gol de Boca y cuarto gol\n            diferencia == 1, \"smile\", \"lol\")\n          )\n        )\n      ))))\n\n\n# Mapear cada nombre de emoji a un emoji\n# Link al paquete de emoji: https://github.com/hadley/emo\nboca &lt;- boca |&gt; \n  mutate(emoji = map_chr(estado, emo::ji))\n\n# Veamos como quedan los datos\nhead(boca)\n\n\n# A tibble: 6 √ó 7\n  minuto central_cordoba  boca diferencia resultado   estado emoji       \n   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;       \n1      1               0     0          0 Empata Boca meh    \"\\U0001f612\"\n2      2               0     0          0 Empata Boca meh    \"\\U0001f612\"\n3      3               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n4      4               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n5      5               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n6      6               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n\n\nVer c√≥digo\n# Hagamos el gr√°fico final con anotaciones\np + \n  # A√±adimos anotaciones en funci√≥n de los goles\n  geom_text(data = boca, aes(x = 15, y = 3.5, \n                             label = paste0(\"Central C√≥rdoba: \", central_cordoba,\n                                            \"\\nBoca: \", boca)),\n            size = 4,        # Tama√±o de la letra\n            hjust = 0) +     # Alinea a la izquierda\n# A√±adimos anotaciones usando emojis\n  geom_text(data = boca, aes(x = 15, y = 2.5, label = emoji), \n            size = 15) +\n# A√±adimos un \"subt√≠tulo\"\n  geom_text(data = boca, aes(x = 0, y = 4.5, label = paste0(\"Resultado: \", resultado)), hjust = 0) +\n# Animemos el gr√°fico\n   transition_reveal(along = minuto)\n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Ya que estamos, guardemos el gr√°fico en un gif\nanim_save(\"boca_gganimate.gif\", animation = last_animation())\n\n\nSi quieren ver c√≥mo fue el partido, pueden ver el siguiente resumen. Despu√©s me cuentan qu√© transmite m√°s emoci√≥n, si mi gr√°fico o el video üßê"
  },
  {
    "objectID": "en/doing-silly-things-r/index.html",
    "href": "en/doing-silly-things-r/index.html",
    "title": "Doing silly things in R",
    "section": "",
    "text": "I once watched Ryan Timpe, the Lead Data Scientist at Lego, where he shared how he sometimes took on fun projects to learn new data analysis skills. In his talk at the RStudio Conference, he mentioned analyzing the dialogues from The Golden Girls using text mining techniques to find the most frequent words. Every time one of the characters said the magic words, they‚Äôd take a ‚Äúwhite shot‚Äù of whatever they were drinking.\nThis post is about something similar. I wanted to learn how to use images in my visualizations, and that‚Äôs how this project was born‚Äîusing images of people with ‚Äúsimilar‚Äù features to mine and incorporating those photos into a scatter plot.\nWhat might seem like a silly project involved:\n\nCreating a Google Form.\nCollecting data from responses.\nProcessing the results.\nIncluding visualizations with people‚Äôs images.\n\nProjects like this make learning feel less heavy and give you extra motivation to find solutions and get results."
  },
  {
    "objectID": "en/doing-silly-things-r/index.html#loading-and-preparing-data",
    "href": "en/doing-silly-things-r/index.html#loading-and-preparing-data",
    "title": "Doing silly things in R",
    "section": "Loading and Preparing Data",
    "text": "Loading and Preparing Data\nLet‚Äôs start by loading the libraries and importing data from a repository.\n\n\nView code\n# Libraries\nlibrary(tidyverse) # Load, cleand and wrangle data\nlibrary(ggimage)   # To use images withing chart\n\n# Data\nclones &lt;- read_delim(\"https://raw.githubusercontent.com/chechoid/silliest-use-of-r/main/source.csv\", delim = \";\")\n\n\ncomentarios &lt;- clones %&gt;% \n  select(comentarios = `Pon√© lo que quieras... parecidos, chistes, comentarios, etc...`) %&gt;% \n  filter(!is.na(comentarios))\n\n# Explore the data\nhead(clones)\n\n\n# A tibble: 6 √ó 24\n  `Marca temporal`    `Facha de Keanu` `Copadez de Keanu` `Facha de Russell`\n  &lt;dttm&gt;                         &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 2021-06-23 12:37:28               10                 10                  7\n2 2021-06-23 12:39:12                4                 10                  5\n3 2021-06-23 12:42:21                8                  9                  8\n4 2021-06-23 12:43:24               10                 10                  1\n5 2021-06-23 12:45:03               10                  8                  4\n6 2021-06-23 12:45:12                5                  9                  1\n# ‚Ñπ 20 more variables: `Copadez de Russell` &lt;dbl&gt;, `Facha de Nico` &lt;dbl&gt;,\n#   `Copadez de Nico` &lt;dbl&gt;, `Facha de Roberto` &lt;dbl&gt;,\n#   `Copadez de Roberto` &lt;dbl&gt;, `Facha de Jeff` &lt;dbl&gt;, `Copadez de Jeff` &lt;dbl&gt;,\n#   `Facha de Brad` &lt;dbl&gt;, `Copadez de Brad` &lt;dbl&gt;, `Facha del Mono` &lt;dbl&gt;,\n#   `Copadez del Mono` &lt;dbl&gt;, `Facha de Sergio` &lt;dbl&gt;,\n#   `Copadez de Sergio` &lt;dbl&gt;, `Facha de Ricky` &lt;dbl&gt;,\n#   `Copadez de Ricky` &lt;dbl&gt;, `Facha de Ben` &lt;dbl&gt;, `Copadez de Ben` &lt;dbl&gt;, ‚Ä¶\n\n\nThe dataset included columns for each character‚Äôs ‚Äúfacha‚Äù (gorgeousness) and ‚Äúcopadez‚Äù (awesomeness) scores. The next steps were:\n\nRemoving irrelevant columns and adding an ID column.\nPivoting the table so that all the score columns ended up in two columns (one for ‚Äúfacha‚Äù and one for ‚Äúcopadez‚Äù).\n\n\n\nView code\n# Remove unnecesary columns\nclones &lt;- clones %&gt;% \n  select(-`Marca temporal`, -`Pon√© lo que quieras... parecidos, chistes, comentarios, etc...`)\n\n# Add id column\nclones &lt;- clones %&gt;% \n  rowid_to_column(var = \"id\")\n\n# Pivot to a lonf format\nclones &lt;- clones %&gt;% \n  pivot_longer(cols = c(\"Facha de Keanu\": \"Copadez de Javier\"),\n               names_to = \"personaje\",\n               values_to = \"puntaje\")\n\n# Explore the dataset again\nhead(clones)\n\n\n# A tibble: 6 √ó 3\n     id personaje          puntaje\n  &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;\n1     1 Facha de Keanu          10\n2     1 Copadez de Keanu        10\n3     1 Facha de Russell         7\n4     1 Copadez de Russell      10\n5     1 Facha de Nico            1\n6     1 Copadez de Nico          1\n\n\nWe started with 66 rows and 24 columns and ended up with a data frame of 1,452 rows and 3 columns. After removing intermediary words like \"de\" and \"del\" from names, we created separate columns for ‚Äúfacha‚Äù and ‚Äúcopadez.‚Äù\n\n\nView code\n# Split nominal variables\nclones &lt;- clones %&gt;% \n  mutate(personaje = str_remove(personaje, \"de \"),\n         personaje = str_remove(personaje, \"del \"))\n\n# Explore average score of each character\nclones %&gt;% \n  group_by(personaje) %&gt;% \n  summarise(valor_promedio = mean(puntaje)) %&gt;% \n  ggplot(aes(x = valor_promedio, y = personaje)) +\n  geom_point(size = 2)\n\n\n\n\n\n\n\n\n\nView code\n# Split the column 'personaje' (character) into two columns, one for the metric, the other for the name\nclones &lt;- clones %&gt;% \n  separate(personaje,  into = c(\"metrica\", \"persona\"))\n\n\n# Pivot to wide format \nclones &lt;- clones %&gt;% \n  pivot_wider(id_cols = c(id, persona),\n              names_from = metrica,\n              values_from = puntaje)\n\n# Explore the new data frame\nhead(clones)\n\n\n# A tibble: 6 √ó 4\n     id persona Facha Copadez\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Keanu      10      10\n2     1 Russell     7      10\n3     1 Nico        1       1\n4     1 Roberto     1       1\n5     1 Jeff        5       5\n6     1 Brad       10      10\n\n\nFinally, we had a dataset with 726 rows‚Äîone for each vote per character‚Äîand four columns: ID, character (personaje), ‚Äúfacha,‚Äù and ‚Äúcopadez.‚Äù\n\n\nView code\n# Calculate the average scores for each character and plot results\nresultados &lt;- clones %&gt;% \n  group_by(persona) %&gt;% \n  summarise(facha_promedio = mean(Facha),\n            copadez_promedio = mean(Copadez))\n\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio, color = persona)) +\n  geom_point(size = 3) +\n  labs(title = \"Average Awesomeness and Gorgeousness\",\n       x = \"Avg Awesomeness\",\n       y = \"Avg Gourgeness\",\n       color = \"Person\")\n\n\n\n\n\n\n\n\n\nThis gave us the foundation for our results. To make the chart less boring, let‚Äôs spice it up with images."
  },
  {
    "objectID": "en/doing-silly-things-r/index.html#adding-images-to-the-chart",
    "href": "en/doing-silly-things-r/index.html#adding-images-to-the-chart",
    "title": "Doing silly things in R",
    "section": "Adding Images to the Chart",
    "text": "Adding Images to the Chart\nAs mentioned earlier, I used Canva to resize all the images and saved them in a folder called ‚Äúclones.‚Äù Instead of uploading each photo individually, I created a data frame linking the names of the characters to their corresponding image files.\n\n\nView code\n# Create a vector with the name of the people\npersona &lt;- resultados %&gt;% \n  select(persona) %&gt;% \n  pull()\n\n# Create a vector of images\nruta &lt;- \"pics\"       # Picture path\nextension &lt;- \"png\"   # Extension of the image files\n\n# Name of the files\nimagen &lt;- c(\"Ben\", \"Brad\", \"Javier\", \"jeff\", \"keanu\", \"mono\", \"nico\", \n            \"ricky\", \"roberto\", \"russell\", \"sergio\")\n\n# Create the vector of photos with the path and file extension\nfoto &lt;- str_c(ruta, imagen, sep = \"/\")\nfoto &lt;- str_c(foto, extension, sep = \".\")\n\n# Create the data frame and add the scores to it\npics &lt;- data.frame(persona, foto)\n\n# See the results of this process\npics\n\n\n   persona             foto\n1      Ben     pics/Ben.png\n2     Brad    pics/Brad.png\n3   Javier  pics/Javier.png\n4     Jeff    pics/jeff.png\n5    Keanu   pics/keanu.png\n6     Mono    pics/mono.png\n7     Nico    pics/nico.png\n8    Ricky   pics/ricky.png\n9  Roberto pics/roberto.png\n10 Russell pics/russell.png\n11  Sergio  pics/sergio.png\n\n\nWe now had a data frame with 11 rows and 2 columns (name and image path), which we integrated into the dataset with average ‚Äúfacha‚Äù (gorgeousness) and ‚Äúcopadez‚Äù (awesomeness) scores.\nFinally, it was time to add the images to the chart:\n\n\nView code\n# Join datasets\nresultados &lt;- left_join(resultados, pics)\n\nhead(resultados)\n\n\n# A tibble: 6 √ó 4\n  persona facha_promedio copadez_promedio foto           \n  &lt;chr&gt;            &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;          \n1 Ben               8.23             6.47 pics/Ben.png   \n2 Brad              8.52             7.55 pics/Brad.png  \n3 Javier            6.89             6.56 pics/Javier.png\n4 Jeff              5.06             6.45 pics/jeff.png  \n5 Keanu             7.77             8.74 pics/keanu.png \n6 Mono              3.30             6.30 pics/mono.png  \n\n\nFinally, it was time to add the images to the chart:\n\n\nView code\n# Final Result\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio)) +\n  geom_image(aes(image=foto), size = 0.08) +\n  theme_minimal() +\n  scale_x_continuous(limits = c(1,10)) +\n  scale_y_continuous(limits = c(1,10)) +\n  labs(title = \"Average Awesomeness and Gorgeousness\",\n       subtitle = \"n = 66\",\n       x = \"Avg Awesomeness\",\n       y = \"Avg Gourgeness\",\n       caption = \"No aunt was part of this analysis\")\n\n\n\n\n\n\n\n\n\nAccording to the data, I‚Äôm farther from Nicol√°s del Ca√±o and Roberto Baradel and closer to Keanu Reeves. So, the data says I look like Keanu. Facts, not opinions üòé."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sergio Garcia Mora aka Checho",
    "section": "",
    "text": "Este blog va a ser un espacio en donde centrar√© contenido sobre programaci√≥n en R, mayormente orientado a temas relacionados con Recursos Humanos y People Analytics (actualizaci√≥n 2025: tambi√©n incluir√© contenido en Python).\nHonestamente, a esta altura del partido no me interesa hacer algo solemne para ‚Äúparecer profesional‚Äù, lo que busco m√°s que nada es generar contenido que le sirva a todos los que est√©n arrancando sus carreras en People Analytics y a quienes est√°n permanentemente aprendiendo.\nTodo el contenido de este blog se puede compartir de manera abierta y libre, citando por supuesto la fuente.\nEn este blog te vas a encontrar con contenido relacionado con R y otros m√°s generales y ‚Äúconceptuales‚Äù sobre People Analytics.\nPara contactarme o saber m√°s de m√≠ pod√©s hacerlo a trav√©s de mis redes sociales o las redes de R4HR - Club de R para RRHH.\nEsta obra est√° bajo una Licencia Creative Commons Atribuci√≥n 4.0 Internacional.\nEste blog est√° hecho en R usando Quarto, un sistema de publicaci√≥n de c√≥digo abierto desarrollado por el equipo de RStudio. Para m√°s informacion visita este contenido desarrollado por Isabella Vel√°squez."
  },
  {
    "objectID": "about.html#de-qu√©-va-este-blog",
    "href": "about.html#de-qu√©-va-este-blog",
    "title": "Sergio Garcia Mora aka Checho",
    "section": "",
    "text": "Este blog va a ser un espacio en donde centrar√© contenido sobre programaci√≥n en R, mayormente orientado a temas relacionados con Recursos Humanos y People Analytics (actualizaci√≥n 2025: tambi√©n incluir√© contenido en Python).\nHonestamente, a esta altura del partido no me interesa hacer algo solemne para ‚Äúparecer profesional‚Äù, lo que busco m√°s que nada es generar contenido que le sirva a todos los que est√©n arrancando sus carreras en People Analytics y a quienes est√°n permanentemente aprendiendo.\nTodo el contenido de este blog se puede compartir de manera abierta y libre, citando por supuesto la fuente.\nEn este blog te vas a encontrar con contenido relacionado con R y otros m√°s generales y ‚Äúconceptuales‚Äù sobre People Analytics.\nPara contactarme o saber m√°s de m√≠ pod√©s hacerlo a trav√©s de mis redes sociales o las redes de R4HR - Club de R para RRHH.\nEsta obra est√° bajo una Licencia Creative Commons Atribuci√≥n 4.0 Internacional.\nEste blog est√° hecho en R usando Quarto, un sistema de publicaci√≥n de c√≥digo abierto desarrollado por el equipo de RStudio. Para m√°s informacion visita este contenido desarrollado por Isabella Vel√°squez."
  },
  {
    "objectID": "en/tidytuesday-simpsons/index.html",
    "href": "en/tidytuesday-simpsons/index.html",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Let‚Äôs load the data with the tidytuesdayR package (or directly with the raw files if it doesn‚Äôt work.\n\n\nVer c√≥digo\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "en/tidytuesday-simpsons/index.html#the-simpsons-data",
    "href": "en/tidytuesday-simpsons/index.html#the-simpsons-data",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Let‚Äôs load the data with the tidytuesdayR package (or directly with the raw files if it doesn‚Äôt work.\n\n\nVer c√≥digo\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "en/tidytuesday-simpsons/index.html#calculate-the-average-rating-by-pairs",
    "href": "en/tidytuesday-simpsons/index.html#calculate-the-average-rating-by-pairs",
    "title": "Tidy Tuesday - Simpsons",
    "section": "Calculate the Average Rating by Pairs",
    "text": "Calculate the Average Rating by Pairs\nWe‚Äôll clean the data a bit more, keeping only the pairs that appear at least 10 times.\n\n\nVer c√≥digo\ntop_duplas &lt;- duplas_por_episodio %&gt;% \n  count(dupla, name = \"cuenta\") %&gt;% \n  filter(cuenta &gt;= 10)\n\n# Reducimos el dataframe\nduplas_por_episodio &lt;- duplas_por_episodio %&gt;% \n  filter(dupla %in% top_duplas$dupla)\n\n\nNow we can join the data from duplas_por_episodio and in that way, calculate the average rating for echar character duo.\n\n\nVer c√≥digo\nduplas_con_rating &lt;- duplas_por_episodio %&gt;% \n  inner_join(episodes, by = c(\"episode_id\" = \"id\")) %&gt;% \n  group_by(dupla) %&gt;% \n  summarise(imdb_promedio = mean(imdb_rating, na.rm = TRUE),\n            episodios = n())\n\n# Filter couples with at least 10 episode appearances\nduplas_con_rating &lt;- duplas_con_rating %&gt;%\n  filter(episodios &gt;= 10) %&gt;%\n  arrange(desc(imdb_promedio))\n\n\nAnd now we can make a plot of the 10 couples with the best average score of imdb_ranking.\n\n\nVer c√≥digo\n# Select the best 10 duos\ntop_10_duplas &lt;- duplas_con_rating %&gt;% \n  head(10)\n\n\n# Chart\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_point(size = 3, color = \"#4f76df\") +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodes: \", episodios)),nudge_y = 0.35,\n            size = 3.5, \n            face = \"bold\",\n            color = \"#4f76df\", \n            family = \"Atma Medium\") +\n  labs(\n    title = \"Top 10 Character Pairs with the Highest Average IMDb Rating\",\n    y = \"Character Pair\",\n    x = \"Average IMDb Rating\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer c√≥digo\nggsave(\"en_top_duplas.png\", dpi = 300)\n\n\nWhat if we use donuts instead of points?\n\n\nVer c√≥digo\n# Library\nlibrary(ggimage)\n\n# Add a column with the name of the picture\ntop_10_duplas &lt;- top_10_duplas %&gt;% \n  mutate(imagen = \"dona.png\")\n\n# Chart\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_image(aes(image = imagen), size = 0.06) +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodes: \", episodios)),\n            nudge_y = 0.15,\n            nudge_x = -2.15,\n            size = 3.7,\n            family = \"Atma Medium\",\n            face = \"bold\",\n            color = \"#4f76df\") +\n  labs(\n    title = \"Top 10 Character Pairs with the Highest Average IMDb Rating\",\n    y = \"Character Pair\",\n    x = \"Average IMDb Rating\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer c√≥digo\nggsave(\"top_duplas_dona.png\", dpi = 300)"
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html",
    "href": "es/cargar_fechas_desde_excel/index.html",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "",
    "text": "¬øA qui√©n no le pas√≥ esto alguna vez?\nEsto en R muchas veces tambi√©n nos trae dolores de cabeza as√≠ que en esto post vamos a ver c√≥mo podemos solucionar esto."
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html#paquetes",
    "href": "es/cargar_fechas_desde_excel/index.html#paquetes",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Paquetes",
    "text": "Paquetes\nPara este ejemplo vamos a utilizar 3 paquetes, openxlsx que nos permite cargar y guardar archivos de Excel, dplyr para manipular y limpiar datos (pod√©s ver un tutorial ac√°). Tambi√©n vamos a usar el paquete janitor para limpiar los nombres de las columnas a un formato m√°s f√°cil de utilizar (elimina tildes, pasa todo a min√∫scula y reemplaza espacios por guiones, por ejemplo).\nEl primer paso, en caso que no los tengas a√∫n, es instalar los paquetes:\n\n\nVer c√≥digo\n# Instalar paquetes\ninstall.packages(\"openxlsx\") # Cargar y guardar archivos de Excel\ninstall.packages(\"dplyr\")    # Manipular y limpiar datos\ninstall.packages(\"janitor\")  # Entre otras cosas, facilitar manipulaci√≥n de columnas\n\n\nUna vez que termina la instalaci√≥n, hay que cargarlos. No vamos a cargar el paquete janitor porque s√≥lo vamos a usar una funci√≥n.\nCargar un paquete ‚Äúdeja activas‚Äù todas las funciones del paquete, lo cual implica un consumo de memoria, muchas veces √≠nfimo, pero consumo al fin, as√≠ que en este caso mostraremos como usar una funci√≥n sin cargar todas las funciones del paquete.\n\n\nVer c√≥digo\n# Cargar paquetes\nlibrary(openxlsx)\nlibrary(dplyr)"
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html#los-datos",
    "href": "es/cargar_fechas_desde_excel/index.html#los-datos",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Los datos",
    "text": "Los datos\nEl caso que usaremos de ejemplo simula ser una base de Postulantes de una b√∫squeda que llevamos adelante para una vacante de People Analytics. Primero carguemos los datos que est√°n almacenados en una carpeta llamada data.\n\n\nVer c√≥digo\n# Cargar los datos en R\ndatos &lt;- read.xlsx(\"data/Postulantes.xlsx\") %&gt;% \n  janitor::clean_names() # Usamos solo la funci√≥n clean_names() sin cargar todo el paquete janitor\n\n\nAhora veamos los datos que tenemos cargados:\n\n\nVer c√≥digo\n# Ver los datos cargados\ndatos\n\n\n  fecha_sourcing         busqueda   nombre apellido   telefono            mail\n1          44729 People Analytics   Sergio   Garcia 1111111111 sergio@d4hr.com\n2          44729 People Analytics  Daniela   Garcia 2222222222            &lt;NA&gt;\n3          44729 People Analytics    Yanel Paulette 3333333333            &lt;NA&gt;\n4          44729 People Analytics    Carla   Cirone 4444444444            &lt;NA&gt;\n5          44729 People Analytics Santiago  Lardone 5555555555            &lt;NA&gt;\n  empresa            puesto   github          twitter\n1    R4HR Master of Puppets chechoid @sergiogarciamor\n2    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n3    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n4    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n5    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n                                                  linkedin   fuente status\n1            https://www.linkedin.com/in/sergiogarciamora/  Twitter Activo\n2        https://www.linkedin.com/in/claudiadanielagarcia/ Linkedin Activo\n3               https://www.linkedin.com/in/yanelpaulette/ Linkedin Activo\n4       https://www.linkedin.com/in/carla-cirone-0566b095/ Linkedin Activo\n5 https://www.linkedin.com/in/santiagolardonequinodozrrhh/ Linkedin Activo\n  fecha_ultimo_contacto\n1                 44739\n2                 44739\n3                 44739\n4                 44739\n5                 44739\n\n\nVer c√≥digo\n# Hagamos un zoom en los campos que contienen fechas\ndatos %&gt;% \n  select(fecha_sourcing, fecha_ultimo_contacto)\n\n\n  fecha_sourcing fecha_ultimo_contacto\n1          44729                 44739\n2          44729                 44739\n3          44729                 44739\n4          44729                 44739\n5          44729                 44739\n\n\nEn la tabla anterior vemos que el valor que obtenemos en la primera columna es 44729, el n√∫mero que representa a la fecha 17/6/22 como podemos apreciar en el archivo original:\n\nAhora veremos c√≥mo podemos resolver este problema."
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html#soluci√≥n",
    "href": "es/cargar_fechas_desde_excel/index.html#soluci√≥n",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Soluci√≥n",
    "text": "Soluci√≥n\nPara empezar, seleccionemos algunas columnas nom√°s usando la funci√≥n select(). Vamos a seleccionar los campos de fecha_sourcing que representa cu√°ndo inici√≥ la b√∫squeda, nombre, empresa, y fecha_ultimo_contacto donde anotamos cu√°ndo fue la √∫ltima vez que nos pusimos en contacto con cada persona.\n\n\nVer c√≥digo\n# Seleccionar los campos con fechas, nombre y empres y sobreescribo el data frame\ndatos &lt;- datos %&gt;% \n  select(fecha_sourcing, nombre, empresa, fecha_ultimo_contacto)\n\n# Ver el nuevo dataframe\ndatos\n\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1          44729   Sergio    R4HR                 44739\n2          44729  Daniela    R4HR                 44739\n3          44729    Yanel    R4HR                 44739\n4          44729    Carla    R4HR                 44739\n5          44729 Santiago    R4HR                 44739\n\n\nAhora nos quedamos con un data frame de 5 filas y 4 columnas.\nPara transformar el campo fecha_sourcing de un formato num√©rico a un formato de tipo fecha, vamos a usar la funci√≥n as.Date() de R base.\n\n\nVer c√≥digo\n# Transformar el campo fecha_sourcing a tipo fecha\ndatos %&gt;% \n  mutate(fecha_sourcing = as.Date(fecha_sourcing,          # Sobrescribimos el campo fecha_sourcing\n                                  origin = \"1899-12-30\",   # Fecha de origen para el conteo\n                                  tz = \"UTC\"))             # Huso horario\n\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1     2022-06-17   Sergio    R4HR                 44739\n2     2022-06-17  Daniela    R4HR                 44739\n3     2022-06-17    Yanel    R4HR                 44739\n4     2022-06-17    Carla    R4HR                 44739\n5     2022-06-17 Santiago    R4HR                 44739\n\n\nEl trabajo con fechas siempre fue complejo desde el punto de vista del an√°lisis de datos. Especialmente con los distintos formatos que se usan en el mundo, por ejemplo dd/mm/aaaa en Sudam√©rica, o mm/dd/aaaa en Estados Unidos por ejemplo. R, cuando un campo fecha carga correctamente, lo transforma a un formato ISO 8601 aaaa-mm-dd.\n\nEl primer n√∫mero que obtuvimos cuando cargamos la tabla en R (el 44729) significa que desde el 30 de diciembre de 1899 hasta el 17 de Junio de 2022 pasaron 44.729 d√≠as. De ah√≠ el n√∫mero que obtuvimos en la carga.\nEl par√°metro tz, nos permite especificar el huso horario del registro. Para algunos casos puede ser relevante, pero para la mayor√≠a de los casos de uso que le dar√≠amos en RRHH, es un par√°metro que podemos incluir o no.\n\nCambiar varios campos a la vez\nCon la tabla que estamos usando de ejemplo, no hay mucho problema en repetir el paso ya que √∫nicamente tenemos dos campos de fechas. ¬øPero qu√© pasa si tenemos 6, 7, o m√°s campos de fechas en un archivo? Repetir estos pasos manualmente va a hacer confuso nuestro c√≥digo y m√°s complejo de mantener.\nVeamos una forma de cambiar todos los campos de fecha usando algunas funciones auxiliares del paquete dplyr.\n\n\nVer c√≥digo\n# Cambios los dos campos de fecha a la vez\ndatos %&gt;% \n  mutate(across(starts_with(\"fecha\"),\n                ~as.Date(.x,\n                         tz = \"UTC\",\n                         origin = \"1899-12-30\")))\n\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1     2022-06-17   Sergio    R4HR            2022-06-27\n2     2022-06-17  Daniela    R4HR            2022-06-27\n3     2022-06-17    Yanel    R4HR            2022-06-27\n4     2022-06-17    Carla    R4HR            2022-06-27\n5     2022-06-17 Santiago    R4HR            2022-06-27\n\n\nEn este caso usamos la funci√≥n across() para indicarle a R que ejecute la funci√≥n (en este ejemplo, as.Date()) en todas las variables que cumplan con alg√∫n criterio. En este ejemplo, nos valemos de otra funci√≥n auxiliar, starts_with(), que como su nombre en ingl√©s lo indica, va a ejecutar la funci√≥n en todas las columnas que empiecen con el t√©rmino \"fecha\".\nEste ejemplo funciona porque los campos que contienen una fecha comienzan con el nombre fecha. Por eso es importante al momento de dise√±ar una base de datos, un formulario, o cualquier registro que utilicemos para que haya una consistencia entre los nombres de los campos para facilitarnos posteriormente el proceso y an√°lisis de datos, independiemente del software que utilicemos.\nPresten atenci√≥n a que delante de la funci√≥n as.Date() usamos este s√≠mbolo (~ ) llamado virgulilla (en Neuqu√©n, Argentina, le dr√≠amos √±uflo). Con ese s√≠mbolo le indicamos a R que esa va a ser la funci√≥n que vamos a replicar en todos los campos.\nEl argumento .x, representa a todas las columnas que hab√≠amos seleccionado con las funciones across() y starts_with(). Es decir que es la forma que tiene R de simplificar cu√°les son los campos que tiene que transformar sin que le tengamos que indicar uno por uno cuales son."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html",
    "href": "es/haciendo-boludeces-en-r/index.html",
    "title": "Haciendo pavadas en R",
    "section": "",
    "text": "Una vez vi una charla de Ryan Timpe, un Data Scientist de Lego, que en una charla en la RStudio Conference contaba c√≥mo a veces hac√≠a proyectos que fueran divertidos para aprender nuevos skills de an√°lisis de datos. En su charla cuenta por ejemplo, que hizo un an√°lisis de los di√°logos de la serie The Golden Girls usando t√©cnicas de text mining para detectar cu√°les eran las palabras m√°s frecuentes, entonces cada vez que una protagonista dec√≠a esa palabra ellos hac√≠an un fondo blanco de lo que estuvieran tomando.\nEste post va de lo mismo. Yo quer√≠a aprender a usar im√°genes en mis visualizaciones, as√≠ naci√≥ este proyecto en el que us√© im√°genes de personas con rasgos ‚Äúsimilares‚Äù a los m√≠os e incluir las fotos en un gr√°fico de dispersi√≥n.\nEsto que es una boludez implic√≥:\n\nCrear un formulario en Google Forms\nLevantar los datos de las respuestas\nProcesar los resultados\nE incluir visualizaciones usando las im√°genes de las personas.\n\nEste tipo de proyectos lo que permite es que el esfuerzo que dedic√°s a aprender no se sienta pesado, y que te da una motivaci√≥n extra para buscar la soluci√≥n para lograr el resultado."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#g√©nesis-de-la-idea-k-nn",
    "href": "es/haciendo-boludeces-en-r/index.html#g√©nesis-de-la-idea-k-nn",
    "title": "Haciendo pavadas en R",
    "section": "G√©nesis de la idea: k-nn",
    "text": "G√©nesis de la idea: k-nn\nLa idea de este an√°lisis surgi√≥ un d√≠a despu√©s de hacer una explicaci√≥n sobre un m√©todo de clustering llamado k-nn. Los m√©todos de clustering son t√©cnicas de ciencia de datos que permiten hallar grupos entre los datos (llamados clusters en la jerga).\nEl m√©todo k-nn, k nearest neighbors o de vecinos m√°s cercanos lo que hace es asignar a cada individuo a un cluster en funci√≥n de las caracter√≠sticas de sus ‚Äúvecinos‚Äù. Es decir que determina a qu√© grupo pertenece cada caso en funci√≥n a qu√© casos se parece m√°s.\nLa forma que se me ocurri√≥ para explicar esto de manera visual fue con este dibujo que hice en Paint:\n\nLa explicaci√≥n es que yo, dentro de ese conjunto de datos, estoy m√°s cerca de pertenecer al cluster del Mono Burgos y de Nicol√°s del Ca√±o, m√°s que del cluster de Keanu Reeves, Jeff Bridges y Brad Pitt.\nY despu√©s tuve una idea. ¬øY si hago esto con datos?"
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#cargando-los-datos-y-prepar√°ndolos",
    "href": "es/haciendo-boludeces-en-r/index.html#cargando-los-datos-y-prepar√°ndolos",
    "title": "Haciendo pavadas en R",
    "section": "Cargando los datos y prepar√°ndolos",
    "text": "Cargando los datos y prepar√°ndolos\nEmpecemos cargando las librer√≠as y los datos directamente desde un repositorio:\n\n\nVer c√≥digo\n# Paquetes\nlibrary(tidyverse) # Cargar, limpiar y preparar datos\nlibrary(ggimage)   # Para usar im√°genes en las visualizaciones\n\n# Datos\nclones &lt;- read_delim(\"https://raw.githubusercontent.com/chechoid/silliest-use-of-r/main/source.csv\", delim = \";\")\n\n\ncomentarios &lt;- clones %&gt;% \n  select(comentarios = `Pon√© lo que quieras... parecidos, chistes, comentarios, etc...`) %&gt;% \n  filter(!is.na(comentarios))\n\n# Exploremos los datos\nhead(clones)\n\n\n# A tibble: 6 √ó 24\n  `Marca temporal`    `Facha de Keanu` `Copadez de Keanu` `Facha de Russell`\n  &lt;dttm&gt;                         &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 2021-06-23 12:37:28               10                 10                  7\n2 2021-06-23 12:39:12                4                 10                  5\n3 2021-06-23 12:42:21                8                  9                  8\n4 2021-06-23 12:43:24               10                 10                  1\n5 2021-06-23 12:45:03               10                  8                  4\n6 2021-06-23 12:45:12                5                  9                  1\n# ‚Ñπ 20 more variables: `Copadez de Russell` &lt;dbl&gt;, `Facha de Nico` &lt;dbl&gt;,\n#   `Copadez de Nico` &lt;dbl&gt;, `Facha de Roberto` &lt;dbl&gt;,\n#   `Copadez de Roberto` &lt;dbl&gt;, `Facha de Jeff` &lt;dbl&gt;, `Copadez de Jeff` &lt;dbl&gt;,\n#   `Facha de Brad` &lt;dbl&gt;, `Copadez de Brad` &lt;dbl&gt;, `Facha del Mono` &lt;dbl&gt;,\n#   `Copadez del Mono` &lt;dbl&gt;, `Facha de Sergio` &lt;dbl&gt;,\n#   `Copadez de Sergio` &lt;dbl&gt;, `Facha de Ricky` &lt;dbl&gt;,\n#   `Copadez de Ricky` &lt;dbl&gt;, `Facha de Ben` &lt;dbl&gt;, `Copadez de Ben` &lt;dbl&gt;, ‚Ä¶\n\n\nAh√≠ podemos ver que para cada personaje tenemos una columna con el puntaje de su facha y su puntaje de copadez.\nEl siguiente paso consiste en eliminar algunas columnas que no son relevantes para el an√°lisis, y agregamos una columna de id. Y luego tenemos que ‚Äúpivotear‚Äù la tabla para que nos queden todas las columnas de puntajes de los personajes en dos columnas:\n\n\nVer c√≥digo\n# Eliminar columnas innecesarias\nclones &lt;- clones %&gt;% \n  select(-`Marca temporal`, -`Pon√© lo que quieras... parecidos, chistes, comentarios, etc...`)\n\n# Agregar columna de id\nclones &lt;- clones %&gt;% \n  rowid_to_column(var = \"id\")\n\n# Pivotear variables\nclones &lt;- clones %&gt;% \n  pivot_longer(cols = c(\"Facha de Keanu\": \"Copadez de Javier\"),\n               names_to = \"personaje\",\n               values_to = \"puntaje\")\n\n# Veamos como queda el dataset ahora\nhead(clones)\n\n\n# A tibble: 6 √ó 3\n     id personaje          puntaje\n  &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;\n1     1 Facha de Keanu          10\n2     1 Copadez de Keanu        10\n3     1 Facha de Russell         7\n4     1 Copadez de Russell      10\n5     1 Facha de Nico            1\n6     1 Copadez de Nico          1\n\n\nHab√≠amos comenzado con un dataset de 66 filas y 24 columnas. Ahora terminamos con un data frame de 1.452 filas en 3 columnas. Ahora necesitamos eliminar las palabras intermedias de y del de los nombres en la columna personaje as√≠ despu√©s podemos crear una columna para facha, y otra para copadez.\n\n\nVer c√≥digo\n# Separar variables categ√≥ricas\nclones &lt;- clones %&gt;% \n  mutate(personaje = str_remove(personaje, \"de \"),\n         personaje = str_remove(personaje, \"del \"))\n\n# Veamos el puntaje promedio de cada personaje y sus caraceter√≠sticas\nclones %&gt;% \n  group_by(personaje) %&gt;% \n  summarise(valor_promedio = mean(puntaje)) %&gt;% \n  ggplot(aes(x = valor_promedio, y = personaje)) +\n  geom_point(size = 2)\n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Dividimos la columna 'personaje' en dos columnas, una para la m√©trica y otra para el nombre\nclones &lt;- clones %&gt;% \n  separate(personaje,  into = c(\"metrica\", \"persona\"))\n\n\n# Pivotear ancho \nclones &lt;- clones %&gt;% \n  pivot_wider(id_cols = c(id, persona),\n              names_from = metrica,\n              values_from = puntaje)\n\n# Veamos como queda el data frame ahora\nhead(clones)\n\n\n# A tibble: 6 √ó 4\n     id persona Facha Copadez\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Keanu      10      10\n2     1 Russell     7      10\n3     1 Nico        1       1\n4     1 Roberto     1       1\n5     1 Jeff        5       5\n6     1 Brad       10      10\n\n\nLuego de estos pasos quedamos con un data frame de 726 filas, una para cada votaci√≥n para cada personaje, y con 4 columnas, id, persona, Facha y Copadez. Con estos datos podemos ver los resultados de cada persona:\n\n\nVer c√≥digo\n# Calculamos los resultados promedios para cada persona y graficamos los resultados\nresultados &lt;- clones %&gt;% \n  group_by(persona) %&gt;% \n  summarise(facha_promedio = mean(Facha),\n            copadez_promedio = mean(Copadez))\n\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio, color = persona)) +\n  geom_point(size = 3)\n\n\n\n\n\n\n\n\n\nEn esencia, este es el gr√°fico al que queremos llegar. As√≠ como est√° es medio aburrido, as√≠ que vamos a enchular este gr√°fico con im√°genes."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#trabajando-con-las-im√°genes",
    "href": "es/haciendo-boludeces-en-r/index.html#trabajando-con-las-im√°genes",
    "title": "Haciendo pavadas en R",
    "section": "Trabajando con las im√°genes",
    "text": "Trabajando con las im√°genes\nComo contaba antes, primero arm√© una presentaci√≥n en Canva y pegu√© todas las im√°genes de cada personaje para que queden m√°s o menos del mismo tama√±o. Luego guard√© cada imagen en un archivo separado, y en este caso las guard√© en una carpeta que se llama clones.\nPodr√≠a haber hecho la carga de las fotos una por una, pero quer√≠a hacer este trabajo lo m√°s eficiente posible tratando de repetir pasos. Para eso tenemos que crear un data frame que tenga por un lado el nombre de la persona tal cual lo tenemos en la tabla de las votaciones, y que incluya la direcci√≥n a la imagen.\n\n\nVer c√≥digo\n# Creamos un vector con los nombres de las personas\npersona &lt;- resultados %&gt;% \n  select(persona) %&gt;% \n  pull()\n\n# Creo un vector de im√°genes\nruta &lt;- \"pics\"        # Ruta de las fotos\nextension &lt;- \"png\"   # Extensi√≥n de los archivos de im√°genes\n\n# nombres de los archivos\nimagen &lt;- c(\"Ben\", \"Brad\", \"Javier\", \"jeff\", \"keanu\", \"mono\", \"nico\", \n            \"ricky\", \"roberto\", \"russell\", \"sergio\")\n\n# Creo el vector de fotos con direcci√≥n y extensi√≥n completa\nfoto &lt;- str_c(ruta, imagen, sep = \"/\")\nfoto &lt;- str_c(foto, extension, sep = \".\")\n\n# Creo el dataframe y lo agrego al dataframe resultados\npics &lt;- data.frame(persona, foto)\n\n# Ver el resultado de este proceso\npics\n\n\n   persona             foto\n1      Ben     pics/Ben.png\n2     Brad    pics/Brad.png\n3   Javier  pics/Javier.png\n4     Jeff    pics/jeff.png\n5    Keanu   pics/keanu.png\n6     Mono    pics/mono.png\n7     Nico    pics/nico.png\n8    Ricky   pics/ricky.png\n9  Roberto pics/roberto.png\n10 Russell pics/russell.png\n11  Sergio  pics/sergio.png\n\n\nAhora tenemos un data frame de 11 filas y dos columnas, con el nombre de cada persona, y la direcci√≥n al archivo que contiene las im√°genes de cada una. Estos datos lo podemos integrar al data frame que ven√≠amos trabajando con los resultados de Facha y Copadez promedio de cada personaje.\n\n\nVer c√≥digo\n# Unimos los datasets\nresultados &lt;- left_join(resultados, pics)\n\nhead(resultados)\n\n\n# A tibble: 6 √ó 4\n  persona facha_promedio copadez_promedio foto           \n  &lt;chr&gt;            &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;          \n1 Ben               8.23             6.47 pics/Ben.png   \n2 Brad              8.52             7.55 pics/Brad.png  \n3 Javier            6.89             6.56 pics/Javier.png\n4 Jeff              5.06             6.45 pics/jeff.png  \n5 Keanu             7.77             8.74 pics/keanu.png \n6 Mono              3.30             6.30 pics/mono.png"
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#poniendo-im√°genes-al-gr√°fico",
    "href": "es/haciendo-boludeces-en-r/index.html#poniendo-im√°genes-al-gr√°fico",
    "title": "Haciendo pavadas en R",
    "section": "Poniendo im√°genes al gr√°fico",
    "text": "Poniendo im√°genes al gr√°fico\nY ahora si, a lo que venimos: incluir las fotos en el gr√°fico\n\n\nVer c√≥digo\n# El gr√°fico final\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio)) +\n  geom_image(aes(image=foto), size = 0.08) +\n  theme_minimal() +\n  scale_x_continuous(limits = c(1,10)) +\n  scale_y_continuous(limits = c(1,10)) +\n  labs(title = \"Facha y Copadez Promedio de cada Personaje\",\n       x = \"Copadez Promedio\", \n       y = \"Facha Promedio\",\n       caption = \"n = 66\\nNinguna t√≠a particip√≥ del relevamiento\")\n\n\n\n\n\n\n\n\n\nComo conclusi√≥n del an√°lisis los datos dicen que estoy alejado de las caracter√≠sticas de Nicol√°s del Ca√±o y Roberto Baradel por ejemplo y tengo caracter√≠sticas muy similares que Keanu Reeves. O sea que los datos indican que me parezco a Keanu. Dato, no opini√≥n üòé."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#qu√©-saqu√©-de-todo-esto",
    "href": "es/haciendo-boludeces-en-r/index.html#qu√©-saqu√©-de-todo-esto",
    "title": "Haciendo pavadas en R",
    "section": "¬øQu√© saqu√© de todo esto?",
    "text": "¬øQu√© saqu√© de todo esto?\nEn primer lugar aprender a usar un paquete nuevo, ggimage que permite incluir im√°genes en los gr√°ficos. Por otro lado hubo un error en el dise√±o del formulario (poner ‚ÄúFacha del Mono‚Äù) lo que implic√≥ un paso extra en la limpieza de los datos. Ese error en este proyecto me ayud√≥ a prevenir un potencial problema con una encuesta de diversidad para un cliente.\nOtro tema fue la manipulaci√≥n de los datos, pivotearlos de un formato ‚Äúancho‚Äù a uno ‚Äúlargo‚Äù y despu√©s nuevamente a uno ‚Äúancho‚Äù otra vez. Una vez que logr√© eso el c√°lculo de los resultados sali√≥ de manera muy simple.\nTodo esto llev√≥ dos d√≠as de trabajo, mirar tutoriales y documentaci√≥n y mucha prueba y error. La verdad es que fue mucho trabajo, pero el hecho de ser un proyecto medio delirante le sac√≥ mucha presi√≥n y me di√≥ la motivaci√≥n para aprender algo nuevo y superar las barreras y errores que me fui encontrando. Creo que el hecho que sea un proyecto divertido me liber√≥ para tratar interpretar los mensajes de error y buscar la soluci√≥n apropiada.\nEste tipo de proyecto me parece ideal para realizar apenas termin√°s un tutorial o un curso. Los datos que usamos en un tutorial siempre est√°n bastante limpios, controlados, divinos y cuando trabaj√°s con tus propios datos te encontr√°s con barreras. Realizar este tipo de an√°lisis sin la presi√≥n de ‚Äúagregar valor‚Äù al negocio y pone a prueba las habilidades que ten√©s.\nAs√≠ que te invito a que hagas un proyecto rid√≠culo y que lo compartas con el mundo.\n\nFinal\nSi quer√©s ver el script final de este post, lo pod√©s encontrar en el repositorio en este link.\nY como regalo final, me re√≠ mucho con los comentarios que hicieron las personas que participaron del relevamiento de datos as√≠ que los comparto con ustedes:\n\n\n\n\n\n\n\n\nComentarios\n\n\n\n\nte romp√≠ los patrones a la merd\n\n\njaja me rei mucho!\n\n\nCaruso a la Final!\n\n\nJohnny Depp, 8/8\n\n\nHajajja\n\n\nDe Brad Pitt te copiaste el peinado, no?\n\n\n¬øes requisito tener pelo largo para parecer fachero? mostrame indicadores\n\n\nSergio vos no estas bien haciendo esto!!! Jajaja\n\n\nFalta Denicolay\n\n\nJajaj muy bueno\n\n\nHaces todo esto para levantarte minas Mora, lo sabemos!!!\n\n\nME ENCANT√ì! curiosa, din√°mica y original iniciativa como siempre!!\n\n\nCopado el test!!\n\n\n¬øtodos hombres?\n\n\nHajajja\n\n\nWTH??\n\n\nSos un capo!!! me divert√≠ mucho!!!\n\n\nFalta el test de mujeres.....\n\n\nBronn, de game of thrones.\n\n\nMuy buen ejercicio! A algunos personajes el 1 le quedaba grande! habiliten el 0 jaja √âxitos!\n\n\nUn genio Sergio üòÇüòÇüòÇ Podr√≠a ser tambi√©n a la versi√≥n adulta del ni√±o del sexto sentido, el que dice\"veo gente muerta\" ¬ø? ü§î\n\n\nPuedo decir que la foto que te sacaste, es muy de MA de instagram\n\n\nJaja me hiciste re√≠r. C√≥mo no soy de Argentina tuve que googlear algunos, pero todo bien. Super entretenido\n\n\n\n\n\n\n\nMuchas gracias por leer!"
  },
  {
    "objectID": "es/maximo-valor-fila/index.html",
    "href": "es/maximo-valor-fila/index.html",
    "title": "Extraer el m√°ximo valor de una fila",
    "section": "",
    "text": "En este peque√±o tutorial (por eso el tag de tipito, o sea un tip chiquito), voy a contar c√≥mo resolv√≠ un problema que me encontr√© en el trabajo y me trajo m√°s de un dolor de cabeza.\nEstaba trabajando con una tabla en la que ten√≠a varios cursos, con sus fechas de finalizaci√≥n, y para el an√°lisis que estaba haciendo necesitaba extraer la fecha del √∫ltimo curso completado por cada persona (el valor m√°s alto).\nEl problema es que cuando estaba ejecutando la funci√≥n max() en vez de obtener el valor m√°s alto de la fila, obten√≠a el valor m√°s alto de la columna. As√≠ que en este post vamos a ver la funci√≥n rowwise() que permite resolver este inconveniente.\nEn este ejemplo vamos a reemplazar las fechas por un n√∫mero, que a los fines pr√°cticos plantea el mismo problema.\n\n\nPrimero carguemos la librer√≠a dplyr que adem√°s de contener la funci√≥n rowwise() nos permite trabajar con el pipe %&gt;% para simplificar la lectura del c√≥digo. Luego crearemos un data frame de ejemplo con datos inventados\n\n\nVer c√≥digo\n# En caso que no est√© instalado 'dplyr' primero ejecutar install.package(\"dplyr\")\nlibrary(dplyr)\n\n# Creaci√≥n de datos\nejemplo &lt;- data.frame(\"Nombre\" = c(\"Carla\", \"Daniela\", \"Sergio\", \"Yanel\"),\n                    \"Valor A\" = c(12, 8, 300, 17),\n                    \"Valor B\" = c(5, 21, 18, 400),\n                    \"Valor C\" = c(39, 200, 26, 64), \n                    \"Valor D\" = c(100, 43, 86, 12))\n\n\nAhora veamos c√≥mo quedan los datos\n\n\nVer c√≥digo\n# Ejecutar para ver el contenido del data frame\nejemplo\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D\n1   Carla      12       5      39     100\n2 Daniela       8      21     200      43\n3  Sergio     300      18      26      86\n4   Yanel      17     400      64      12\n\n\nLo que necesitaba lograr (en un archivo con muchas m√°s columnas que en este ejemplo) es poner en una columna nueva el valor m√°s alto para cada persona. Entonces para Carla esperaba que el resultado fuera 100, para Daniela 200 y as√≠ sucesivamente.\nInstintivamente lo que hice para intentar obtener el valor m√°s alto de cada caso, fue usar dentro de una funci√≥n mutate() (para crear una columna nueva) la funci√≥n max() a un vector con los nombres de las 4 columnas.\n\n\nVer c√≥digo\nejemplo %&gt;% \n  mutate(\"Valor M√°ximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D Valor M√°ximo\n1   Carla      12       5      39     100          400\n2 Daniela       8      21     200      43          400\n3  Sergio     300      18      26      86          400\n4   Yanel      17     400      64      12          400\n\n\nClaramente no es es el resultado que esperaba, as√≠ que mi reacci√≥n fue la siguiente:\n\n\n\n\nEl problema del enfoque anterior es que la funci√≥n max() busca entre todos los datos que le pasamos, las 4 columnas con los valores num√©ricos, y lo que nos devuelve el valor m√°ximo de entre todas las celdas. Este es un claro ejemplo de que R est√° haciendo lo que le dijimos que haga, no lo que est√°bamos queriendo que haga.\nPara resolver esto, antes de crear una columna nueva con mutate(), usamos la funci√≥n rowwise().\n\n\nVer c√≥digo\nejemplo %&gt;% \n  rowwise() %&gt;%   # Con esta funci√≥n indicamos que queremos los c√°lculos sobre las filas\n  mutate(\"Valor M√°ximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n# A tibble: 4 √ó 6\n# Rowwise: \n  Nombre  Valor.A Valor.B Valor.C Valor.D `Valor M√°ximo`\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1 Carla        12       5      39     100            100\n2 Daniela       8      21     200      43            200\n3 Sergio      300      18      26      86            300\n4 Yanel        17     400      64      12            400\n\n\nLa funci√≥n rowwise() lo que nos permite hacer es c√°lculos sobre las filas. Dependiendo el caso de uso se puede usar esta alternativa, o ‚Äúpivotear‚Äù o transponer la tabla para que las columnas queden dentro de las filas y luego combinar group_by() y summarise() para calcular el valor m√°ximo para cada persona.\nEste enfoque ser√≠a as√≠:\n\n\nVer c√≥digo\nlibrary(tidyr)\n\nejemplo_largo &lt;- ejemplo %&gt;% \n  # Pivoteamos los datos a un formato 'largo'\n  pivot_longer(cols = c(\"Valor.A\", \"Valor.B\", \"Valor.C\", \"Valor.D\"), \n               names_to = \"Variable\",\n               values_to = \"Valor\")\n\n# Veamos el dataset transformado\nejemplo_largo\n\n\n# A tibble: 16 √ó 3\n   Nombre  Variable Valor\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n 1 Carla   Valor.A     12\n 2 Carla   Valor.B      5\n 3 Carla   Valor.C     39\n 4 Carla   Valor.D    100\n 5 Daniela Valor.A      8\n 6 Daniela Valor.B     21\n 7 Daniela Valor.C    200\n 8 Daniela Valor.D     43\n 9 Sergio  Valor.A    300\n10 Sergio  Valor.B     18\n11 Sergio  Valor.C     26\n12 Sergio  Valor.D     86\n13 Yanel   Valor.A     17\n14 Yanel   Valor.B    400\n15 Yanel   Valor.C     64\n16 Yanel   Valor.D     12\n\n\nVer c√≥digo\n# Ahora hacemos el c√°lculo combinando 'group_by' y 'summarise'\nejemplo_largo %&gt;% \n  group_by(Nombre) %&gt;% \n  summarise(\"Valor M√°ximo\" = max(Valor))\n\n\n# A tibble: 4 √ó 2\n  Nombre  `Valor M√°ximo`\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Carla              100\n2 Daniela            200\n3 Sergio             300\n4 Yanel              400\n\n\nClaramente este es otro enfoque, y depende de la necesidad es una opci√≥n v√°lida. Pero en este caso particular necesitaba mantener una fila para cada persona porque despu√©s iba a exportar esta tabla a un archivo que luego es cargado en un tablero en Power BI.\nAs√≠ que, una vez logrado mi objetivo, me dispuse a celebrar como corresponde."
  },
  {
    "objectID": "es/maximo-valor-fila/index.html#datos-de-ejemplo",
    "href": "es/maximo-valor-fila/index.html#datos-de-ejemplo",
    "title": "Extraer el m√°ximo valor de una fila",
    "section": "",
    "text": "Primero carguemos la librer√≠a dplyr que adem√°s de contener la funci√≥n rowwise() nos permite trabajar con el pipe %&gt;% para simplificar la lectura del c√≥digo. Luego crearemos un data frame de ejemplo con datos inventados\n\n\nVer c√≥digo\n# En caso que no est√© instalado 'dplyr' primero ejecutar install.package(\"dplyr\")\nlibrary(dplyr)\n\n# Creaci√≥n de datos\nejemplo &lt;- data.frame(\"Nombre\" = c(\"Carla\", \"Daniela\", \"Sergio\", \"Yanel\"),\n                    \"Valor A\" = c(12, 8, 300, 17),\n                    \"Valor B\" = c(5, 21, 18, 400),\n                    \"Valor C\" = c(39, 200, 26, 64), \n                    \"Valor D\" = c(100, 43, 86, 12))\n\n\nAhora veamos c√≥mo quedan los datos\n\n\nVer c√≥digo\n# Ejecutar para ver el contenido del data frame\nejemplo\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D\n1   Carla      12       5      39     100\n2 Daniela       8      21     200      43\n3  Sergio     300      18      26      86\n4   Yanel      17     400      64      12\n\n\nLo que necesitaba lograr (en un archivo con muchas m√°s columnas que en este ejemplo) es poner en una columna nueva el valor m√°s alto para cada persona. Entonces para Carla esperaba que el resultado fuera 100, para Daniela 200 y as√≠ sucesivamente.\nInstintivamente lo que hice para intentar obtener el valor m√°s alto de cada caso, fue usar dentro de una funci√≥n mutate() (para crear una columna nueva) la funci√≥n max() a un vector con los nombres de las 4 columnas.\n\n\nVer c√≥digo\nejemplo %&gt;% \n  mutate(\"Valor M√°ximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D Valor M√°ximo\n1   Carla      12       5      39     100          400\n2 Daniela       8      21     200      43          400\n3  Sergio     300      18      26      86          400\n4   Yanel      17     400      64      12          400\n\n\nClaramente no es es el resultado que esperaba, as√≠ que mi reacci√≥n fue la siguiente:"
  },
  {
    "objectID": "es/maximo-valor-fila/index.html#la-soluci√≥n",
    "href": "es/maximo-valor-fila/index.html#la-soluci√≥n",
    "title": "Extraer el m√°ximo valor de una fila",
    "section": "",
    "text": "El problema del enfoque anterior es que la funci√≥n max() busca entre todos los datos que le pasamos, las 4 columnas con los valores num√©ricos, y lo que nos devuelve el valor m√°ximo de entre todas las celdas. Este es un claro ejemplo de que R est√° haciendo lo que le dijimos que haga, no lo que est√°bamos queriendo que haga.\nPara resolver esto, antes de crear una columna nueva con mutate(), usamos la funci√≥n rowwise().\n\n\nVer c√≥digo\nejemplo %&gt;% \n  rowwise() %&gt;%   # Con esta funci√≥n indicamos que queremos los c√°lculos sobre las filas\n  mutate(\"Valor M√°ximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n# A tibble: 4 √ó 6\n# Rowwise: \n  Nombre  Valor.A Valor.B Valor.C Valor.D `Valor M√°ximo`\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1 Carla        12       5      39     100            100\n2 Daniela       8      21     200      43            200\n3 Sergio      300      18      26      86            300\n4 Yanel        17     400      64      12            400\n\n\nLa funci√≥n rowwise() lo que nos permite hacer es c√°lculos sobre las filas. Dependiendo el caso de uso se puede usar esta alternativa, o ‚Äúpivotear‚Äù o transponer la tabla para que las columnas queden dentro de las filas y luego combinar group_by() y summarise() para calcular el valor m√°ximo para cada persona.\nEste enfoque ser√≠a as√≠:\n\n\nVer c√≥digo\nlibrary(tidyr)\n\nejemplo_largo &lt;- ejemplo %&gt;% \n  # Pivoteamos los datos a un formato 'largo'\n  pivot_longer(cols = c(\"Valor.A\", \"Valor.B\", \"Valor.C\", \"Valor.D\"), \n               names_to = \"Variable\",\n               values_to = \"Valor\")\n\n# Veamos el dataset transformado\nejemplo_largo\n\n\n# A tibble: 16 √ó 3\n   Nombre  Variable Valor\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n 1 Carla   Valor.A     12\n 2 Carla   Valor.B      5\n 3 Carla   Valor.C     39\n 4 Carla   Valor.D    100\n 5 Daniela Valor.A      8\n 6 Daniela Valor.B     21\n 7 Daniela Valor.C    200\n 8 Daniela Valor.D     43\n 9 Sergio  Valor.A    300\n10 Sergio  Valor.B     18\n11 Sergio  Valor.C     26\n12 Sergio  Valor.D     86\n13 Yanel   Valor.A     17\n14 Yanel   Valor.B    400\n15 Yanel   Valor.C     64\n16 Yanel   Valor.D     12\n\n\nVer c√≥digo\n# Ahora hacemos el c√°lculo combinando 'group_by' y 'summarise'\nejemplo_largo %&gt;% \n  group_by(Nombre) %&gt;% \n  summarise(\"Valor M√°ximo\" = max(Valor))\n\n\n# A tibble: 4 √ó 2\n  Nombre  `Valor M√°ximo`\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Carla              100\n2 Daniela            200\n3 Sergio             300\n4 Yanel              400\n\n\nClaramente este es otro enfoque, y depende de la necesidad es una opci√≥n v√°lida. Pero en este caso particular necesitaba mantener una fila para cada persona porque despu√©s iba a exportar esta tabla a un archivo que luego es cargado en un tablero en Power BI.\nAs√≠ que, una vez logrado mi objetivo, me dispuse a celebrar como corresponde."
  },
  {
    "objectID": "es/scrap_learning/index.html",
    "href": "es/scrap_learning/index.html",
    "title": "Scrap Learning: La Capacitaci√≥n Desaprovechada",
    "section": "",
    "text": "En Recursos Humanos una de las obsesiones principales es medir el Retorno de la Inversi√≥n (ROI) de la capacitaci√≥n, lo cual, si bien es posible de medir, requiere un esfuerzo enorme. En cambio, poder medir cu√°nta plata se desperdicia por la no aplicaci√≥n del conocimiento adquirido en las capacitaciones es mucho m√°s sencillo, y tambi√©n es una m√©trica muy valiosa para utilizar.\nEl Scrap Learning es una forma de medir cu√°ntos de los conocimientos adquiridos en las capacitaciones no se trasladan al trabajo, lo cual es mucho m√°s sencillo y tan valioso de medir como el ROI.\nLa investigaci√≥n indica el promedio de mercado de Scrap Learning entre las empresas que no lo miden es del 45%. Es decir que si tenemos un presupuesto anual de $ 500.000 para las capacitaciones, $ 225.000 es dinero mal invertido y por ende, la capacitaci√≥n deja de ser una inversi√≥n para convertirse en un costo.\n\n\n\nUna forma sencilla de medir el Scrap Learning es preguntando a los participantes de un curso cu√°nto del conocimiento adquirido se aplicar√° al trabajo. El porcentaje de contenido que NO aplicar√°n al trabajo forma parte del Scrap Learning.\nEjemplo: Le preguntamos a un participante cu√°ntos de los conocimientos adquiridos en una capacitaci√≥n estima aplicar en sus tareas cotidianas. Si dice que piensa aplicar el 60% del contenido a su trabajo, el scrap learning es del 40%.\n\n\n\n\n\n\n\n\nUna de las primeras cosas que debemos hacer los Responsables de Capacitaci√≥n y Desarrollo es aclarar para qu√© sirve una capacitaci√≥n. ¬øCu√°ntas veces hemos escuchado ‚ÄúFulano est√° desmotivado‚Ä¶ m√°ndalo a hacer un curso‚Äù? ¬øO cu√°ntas veces acordamos con un empleado conflictivo o de bajo desempe√±o pagarle un posgrado? ¬øHemos enviado alguna vez a una persona a una capacitaci√≥n sobre una tecnolog√≠a que no usamos en nuestras empresas?\nIncluso de parte de los colaboradores hay una percepci√≥n imprecisa sobre la capacitaci√≥n. Una encuesta que hicimos a empleados de nuestros clientes, frente a la pregunta ‚Äú¬øQu√© beneficio que no ten√©s hoy, te gustar√≠a tener?‚Äù, pr√°cticamente 1 de cada 4 respuestas estaba relacionada con capacitaci√≥n o beneficios en posgrados.\nEsto deja entrever, que lo primero que necesitamos hacer desde Capacitaci√≥n y Desarrollo es ‚Äúre-educar‚Äù a la empresa sobre cu√°l es la utilidad y finalidad de las capacitaciones y en qu√© casos usarlas.\n\n\n\n‚ÄúUna capacitaci√≥n efectiva mejorar√° el desempe√±o del participante y del √°rea donde trabaja.‚Äù\nPor el contrario, cuando las capacitaciones no son efectivas y el scrap learning es alto, la performance del colaborador y del sector no mejorar√°n a√∫n cuando asistan al mejor curso del mundo.¬†Una actividad de formaci√≥n debe aportar valor al participante y a su √°rea. Para ello, hay 3 preguntas claves para hacer:\n\n¬øCu√°nto espera que su performance mejore relacionado con el contexto del curso relacionado con todos los factores, incluido el programa de desarrollo?\n¬øCu√°nto de esa mejora se la atribuir√≠a exclusivamente a la capacitaci√≥n?\n¬øCu√°nto tiempo dedica realmente a tareas relacionadas con el programa de desarrollo?\n\n\n\n\nEn nuestra experiencia, existen varias causas que provocan el scrap learning. La tabla a continuaci√≥n resume algunos de los principales factores que inciden en esta m√©trica.\nEn la primera columna hay causas que est√°n bajo el control del √°rea de Capacitaci√≥n y Desarrollo, como ser la calidad del instructor, del material, la alineaci√≥n con las necesidades del negocio, entre otras. Pero sin dudas uno de los factores m√°s importantes e influyentes es la involucraci√≥n de los Jefes y Gerencias en el proceso de Capacitaci√≥n.\n\n\n\n\n\nComo en muchas cosas de Recursos Humanos, la clave son los l√≠deres. ¬øDe qu√© manera pueden influir en la reducci√≥n del scrap learning? B√°sicamente hay 5 factores preponderantes:\n\nElegir a la persona id√≥nea para asistir a un curso y que sea el indicado para adquirir y aplicar nuevos conocimientos a sus tareas.\nDefinir las expectativas con el participante¬†antes¬†del inicio de la capacitaci√≥n.\nInvolucrarse con la aplicaci√≥n de los conocimientos nuevos una vez terminada la actividad de formaci√≥n.\nRealizar un seguimiento de las expectativas fijadas antes de la capacitaci√≥n.\nProveer recursos necesarios para dar soporte al rendimiento.\n\nOtro dato clave es que, si el conocimiento adquirido durante una capacitaci√≥n no se aplica dentro de las¬†6 semanas¬†posteriores a la capacitaci√≥n, ning√∫n conocimiento adquirido en esa actividad se trasladar√° al trabajo.\n\n\n\n\nMedir la informaci√≥n de todos los cursos planificados de la misma manera, usando las mismas herramientas y preguntas. Esto nos brindar√° consistencia para comparar los resultados y realizar estimaciones m√°s sofisticadas.\nCrear una hoja de c√°lculo en Excel, o un tablero con m√©tricas con algunas m√©tricas clave: scrap learning, desempe√±o, e inversi√≥n por ejemplo para cada curso.\nCrear una serie de reglas que brinden un marco para el proceso de mejora continuo, por ejemplo:\n\nPara el top 5 de los cursos, no realizar cambios, reinvertir en ellos, continuar desarroll√°ndolos, y si ocurrieran cambios que sean en pos de conseguir una reducci√≥n de costos siempre y cuando la calidad no se vea afectada, y de esa manera mejorar el ROI.\nPara el 10% m√°s bajo de los cursos, eliminar cualquier curso que no est√© alineado con los objetivos de la empresa. Para aquellos que est√°n alineados con las necesidades de negocio, reinvertir para revisarlos.\nPara el 85% de los cursos que est√°n en el medio, continuar realiz√°ndolos, pero buscando opciones que permitan reducir el scrap y maximizar los beneficios.\n\n\n\n\n\nEl Retorno de Inversi√≥n (ROI) de una capacitaci√≥n es una medida compleja de estimar, en cambio, el Scrap Learning es m√°s sencillo de medir y de solucionar.\nMantener un bajo nivel de Scrap Learning, no s√≥lo se materializa en resultados en la organizaci√≥n, sino que adem√°s aumenta la confianza sobre el proceso de capacitaci√≥n generando un ‚Äúc√≠rculo virtuoso‚Äù que contribuye a mantenerlo en ese estado.\n√âsta es una m√©trica poderosa para evaluar la efectividad de las capacitaciones que realizamos dentro de una organizaci√≥n. Como Responsables de Capacitaci√≥n y Desarrollo, es nuestro deber asegurar la calidad de la capacitaci√≥n (del instructor, del contenido, y la alineaci√≥n con necesidades de negocio), pero los jefes juegan un rol clave a la hora de trasladar los conocimientos de la formaci√≥n al trabajo cotidiano. De esto surge la necesidad de trabajar codo a codo con las √°reas para involucrar a sus jefaturas y gerencias, d√°ndoles el soporte necesario para mejorar el impacto de las capacitaciones, mejorar el rendimiento de sus equipos e incrementar sus propios resultados e imagen."
  },
  {
    "objectID": "es/scrap_learning/index.html#para-muestra-basta-con-un-bot√≥n",
    "href": "es/scrap_learning/index.html#para-muestra-basta-con-un-bot√≥n",
    "title": "Scrap Learning: La Capacitaci√≥n Desaprovechada",
    "section": "",
    "text": "Una forma sencilla de medir el Scrap Learning es preguntando a los participantes de un curso cu√°nto del conocimiento adquirido se aplicar√° al trabajo. El porcentaje de contenido que NO aplicar√°n al trabajo forma parte del Scrap Learning.\nEjemplo: Le preguntamos a un participante cu√°ntos de los conocimientos adquiridos en una capacitaci√≥n estima aplicar en sus tareas cotidianas. Si dice que piensa aplicar el 60% del contenido a su trabajo, el scrap learning es del 40%."
  },
  {
    "objectID": "es/scrap_learning/index.html#capacitar-sobre-capacitar",
    "href": "es/scrap_learning/index.html#capacitar-sobre-capacitar",
    "title": "Scrap Learning: La Capacitaci√≥n Desaprovechada",
    "section": "",
    "text": "Una de las primeras cosas que debemos hacer los Responsables de Capacitaci√≥n y Desarrollo es aclarar para qu√© sirve una capacitaci√≥n. ¬øCu√°ntas veces hemos escuchado ‚ÄúFulano est√° desmotivado‚Ä¶ m√°ndalo a hacer un curso‚Äù? ¬øO cu√°ntas veces acordamos con un empleado conflictivo o de bajo desempe√±o pagarle un posgrado? ¬øHemos enviado alguna vez a una persona a una capacitaci√≥n sobre una tecnolog√≠a que no usamos en nuestras empresas?\nIncluso de parte de los colaboradores hay una percepci√≥n imprecisa sobre la capacitaci√≥n. Una encuesta que hicimos a empleados de nuestros clientes, frente a la pregunta ‚Äú¬øQu√© beneficio que no ten√©s hoy, te gustar√≠a tener?‚Äù, pr√°cticamente 1 de cada 4 respuestas estaba relacionada con capacitaci√≥n o beneficios en posgrados.\nEsto deja entrever, que lo primero que necesitamos hacer desde Capacitaci√≥n y Desarrollo es ‚Äúre-educar‚Äù a la empresa sobre cu√°l es la utilidad y finalidad de las capacitaciones y en qu√© casos usarlas."
  },
  {
    "objectID": "es/scrap_learning/index.html#las-preguntas-clave",
    "href": "es/scrap_learning/index.html#las-preguntas-clave",
    "title": "Scrap Learning: La Capacitaci√≥n Desaprovechada",
    "section": "",
    "text": "‚ÄúUna capacitaci√≥n efectiva mejorar√° el desempe√±o del participante y del √°rea donde trabaja.‚Äù\nPor el contrario, cuando las capacitaciones no son efectivas y el scrap learning es alto, la performance del colaborador y del sector no mejorar√°n a√∫n cuando asistan al mejor curso del mundo.¬†Una actividad de formaci√≥n debe aportar valor al participante y a su √°rea. Para ello, hay 3 preguntas claves para hacer:\n\n¬øCu√°nto espera que su performance mejore relacionado con el contexto del curso relacionado con todos los factores, incluido el programa de desarrollo?\n¬øCu√°nto de esa mejora se la atribuir√≠a exclusivamente a la capacitaci√≥n?\n¬øCu√°nto tiempo dedica realmente a tareas relacionadas con el programa de desarrollo?"
  },
  {
    "objectID": "es/scrap_learning/index.html#factores-a-tener-en-cuenta",
    "href": "es/scrap_learning/index.html#factores-a-tener-en-cuenta",
    "title": "Scrap Learning: La Capacitaci√≥n Desaprovechada",
    "section": "",
    "text": "En nuestra experiencia, existen varias causas que provocan el scrap learning. La tabla a continuaci√≥n resume algunos de los principales factores que inciden en esta m√©trica.\nEn la primera columna hay causas que est√°n bajo el control del √°rea de Capacitaci√≥n y Desarrollo, como ser la calidad del instructor, del material, la alineaci√≥n con las necesidades del negocio, entre otras. Pero sin dudas uno de los factores m√°s importantes e influyentes es la involucraci√≥n de los Jefes y Gerencias en el proceso de Capacitaci√≥n.\n\n\n\n\n\nComo en muchas cosas de Recursos Humanos, la clave son los l√≠deres. ¬øDe qu√© manera pueden influir en la reducci√≥n del scrap learning? B√°sicamente hay 5 factores preponderantes:\n\nElegir a la persona id√≥nea para asistir a un curso y que sea el indicado para adquirir y aplicar nuevos conocimientos a sus tareas.\nDefinir las expectativas con el participante¬†antes¬†del inicio de la capacitaci√≥n.\nInvolucrarse con la aplicaci√≥n de los conocimientos nuevos una vez terminada la actividad de formaci√≥n.\nRealizar un seguimiento de las expectativas fijadas antes de la capacitaci√≥n.\nProveer recursos necesarios para dar soporte al rendimiento.\n\nOtro dato clave es que, si el conocimiento adquirido durante una capacitaci√≥n no se aplica dentro de las¬†6 semanas¬†posteriores a la capacitaci√≥n, ning√∫n conocimiento adquirido en esa actividad se trasladar√° al trabajo."
  },
  {
    "objectID": "es/scrap_learning/index.html#recomendaciones",
    "href": "es/scrap_learning/index.html#recomendaciones",
    "title": "Scrap Learning: La Capacitaci√≥n Desaprovechada",
    "section": "",
    "text": "Medir la informaci√≥n de todos los cursos planificados de la misma manera, usando las mismas herramientas y preguntas. Esto nos brindar√° consistencia para comparar los resultados y realizar estimaciones m√°s sofisticadas.\nCrear una hoja de c√°lculo en Excel, o un tablero con m√©tricas con algunas m√©tricas clave: scrap learning, desempe√±o, e inversi√≥n por ejemplo para cada curso.\nCrear una serie de reglas que brinden un marco para el proceso de mejora continuo, por ejemplo:\n\nPara el top 5 de los cursos, no realizar cambios, reinvertir en ellos, continuar desarroll√°ndolos, y si ocurrieran cambios que sean en pos de conseguir una reducci√≥n de costos siempre y cuando la calidad no se vea afectada, y de esa manera mejorar el ROI.\nPara el 10% m√°s bajo de los cursos, eliminar cualquier curso que no est√© alineado con los objetivos de la empresa. Para aquellos que est√°n alineados con las necesidades de negocio, reinvertir para revisarlos.\nPara el 85% de los cursos que est√°n en el medio, continuar realiz√°ndolos, pero buscando opciones que permitan reducir el scrap y maximizar los beneficios."
  },
  {
    "objectID": "es/scrap_learning/index.html#conclusi√≥n",
    "href": "es/scrap_learning/index.html#conclusi√≥n",
    "title": "Scrap Learning: La Capacitaci√≥n Desaprovechada",
    "section": "",
    "text": "El Retorno de Inversi√≥n (ROI) de una capacitaci√≥n es una medida compleja de estimar, en cambio, el Scrap Learning es m√°s sencillo de medir y de solucionar.\nMantener un bajo nivel de Scrap Learning, no s√≥lo se materializa en resultados en la organizaci√≥n, sino que adem√°s aumenta la confianza sobre el proceso de capacitaci√≥n generando un ‚Äúc√≠rculo virtuoso‚Äù que contribuye a mantenerlo en ese estado.\n√âsta es una m√©trica poderosa para evaluar la efectividad de las capacitaciones que realizamos dentro de una organizaci√≥n. Como Responsables de Capacitaci√≥n y Desarrollo, es nuestro deber asegurar la calidad de la capacitaci√≥n (del instructor, del contenido, y la alineaci√≥n con necesidades de negocio), pero los jefes juegan un rol clave a la hora de trasladar los conocimientos de la formaci√≥n al trabajo cotidiano. De esto surge la necesidad de trabajar codo a codo con las √°reas para involucrar a sus jefaturas y gerencias, d√°ndoles el soporte necesario para mejorar el impacto de las capacitaciones, mejorar el rendimiento de sus equipos e incrementar sus propios resultados e imagen."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html",
    "href": "es/vino-y-capacitacion/index.html",
    "title": "Gestionar capacitaci√≥n buscando el mejor vino",
    "section": "",
    "text": "Yo durante mi luna de miel en Finca Adelma.\n\n\nEl objetivo de este post es mostrar c√≥mo se puede aplicar un an√°lisis de un tema cualquiera, a un problema de RRHH.\nLa raz√≥n detr√°s de esta idea es que cuando estamos aprendiendo a usar cualquier programa de an√°lisis de datos, ll√°mese R, Python, Power BI o Excel, encontramos mucho contenido sobre muchos tipos de an√°lisis, pero muy poco contenido relacionado con RRHH. Y eso es algo que podemos hacer por nuestra cuenta.\nCon esto en mente, lo que vamos a hacer es ver c√≥mo podemos aprovechar un an√°lisis en el cual buscamos en qu√© regi√≥n de Mendoza podemos hallar los mejores malbecs1, haciendo un r√°nking de las mejores regiones. Luego veremos c√≥mo ese mismo tipo de an√°lisis lo podemos usar para detectar cu√°les son los mejores proveedores de capacitaci√≥n de una empresa."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#librer√≠as-y-datos",
    "href": "es/vino-y-capacitacion/index.html#librer√≠as-y-datos",
    "title": "Gestionar capacitaci√≥n buscando el mejor vino",
    "section": "Librer√≠as y datos",
    "text": "Librer√≠as y datos\nVamos a usar varios paquetes dentro de tidyverse y cargamos los datos directamente desde el repositorio de GitHub del proyecto TidyTuesday.\n\n\nVer c√≥digo\nlibrary(tidyverse)\n\n# Carga de datos\nwine_ratings &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv\")\n\n# Filtramos los datos de la provincia de Mendoza\nwine_ar &lt;- wine_ratings %&gt;% \n  filter(province == \"Mendoza Province\") \n\n\nEl dataset original contiene 129971 filas y 14. Despu√©s de filtrar los datos s√≥lo por Mendoza Province nos quedamos con 3264 filas que representan los puntajes que personas expertas le han dado a los vinos. De ahora en m√°s seguiremos trabajando con el dataset wine_ar.\n\n\nVer c√≥digo\n# Exploremos el contenido del dataset\nglimpse(wine_ar)\n\n\nRows: 3,264\nColumns: 14\n$ ...1                  &lt;dbl&gt; 17, 224, 231, 253, 261, 266, 273, 275, 284, 294,‚Ä¶\n$ country               &lt;chr&gt; \"Argentina\", \"Argentina\", \"Argentina\", \"Argentin‚Ä¶\n$ description           &lt;chr&gt; \"Raw black-cherry aromas are direct and simple b‚Ä¶\n$ designation           &lt;chr&gt; \"Winemaker Selection\", \"Lunta\", NA, \"Reserve\", \"‚Ä¶\n$ points                &lt;dbl&gt; 87, 90, 85, 85, 89, 89, 89, 89, 92, 92, 93, 93, ‚Ä¶\n$ price                 &lt;dbl&gt; 13, 22, 10, 15, 37, 14, 19, 30, 215, 30, 42, 55,‚Ä¶\n$ province              &lt;chr&gt; \"Mendoza Province\", \"Mendoza Province\", \"Mendoza‚Ä¶\n$ region_1              &lt;chr&gt; \"Mendoza\", \"Luj√°n de Cuyo\", \"Mendoza\", \"Luj√°n de‚Ä¶\n$ region_2              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ taster_name           &lt;chr&gt; \"Michael Schachner\", \"Michael Schachner\", \"Micha‚Ä¶\n$ taster_twitter_handle &lt;chr&gt; \"@wineschach\", \"@wineschach\", \"@wineschach\", \"@w‚Ä¶\n$ title                 &lt;chr&gt; \"Gaucho Andino 2011 Winemaker Selection Malbec (‚Ä¶\n$ variety               &lt;chr&gt; \"Malbec\", \"Malbec\", \"Bonarda\", \"Malbec\", \"Red Bl‚Ä¶\n$ winery                &lt;chr&gt; \"Gaucho Andino\", \"Mendel\", \"Andean Sky\", \"Cueva ‚Ä¶\n\n\nSolo de explorar el dataset se me hace agua la boca. En fin, sigamos‚Ä¶"
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#calcular-puntaje-promedio-de-vinos-por-regiones",
    "href": "es/vino-y-capacitacion/index.html#calcular-puntaje-promedio-de-vinos-por-regiones",
    "title": "Gestionar capacitaci√≥n buscando el mejor vino",
    "section": "Calcular puntaje promedio de vinos por regiones",
    "text": "Calcular puntaje promedio de vinos por regiones\nEl paso siguiente es filtrar por la cepa Malbec y luego podemos calcular un promedio de los puntajes de la columna points agrupados por la columna region_1 as√≠ podemos establecer un ranking de las regiones que tienen los mejores Malbecs de Mendoza.\n\n\nVer c√≥digo\n# Filtramos por Malbec\nmalbec &lt;- wine_ar %&gt;% \n  filter(variety == \"Malbec\")\n\n# Creamos un ranking de las mejores regiones productoras de Malbec\npromedio_regiones &lt;- malbec %&gt;% \n  filter(!is.na(region_1)) %&gt;%  # Eliminamos filas sin datos\n  group_by(region_1) %&gt;%        # Agrupamos por region\n  summarise(puntaje_promedio = mean(points)) %&gt;% # Calculamos el promedio\n  arrange(desc(puntaje_promedio)) # Ordenamos de mayor a menor\n\n# Ver el resultado\npromedio_regiones\n\n\n# A tibble: 13 √ó 2\n   region_1         puntaje_promedio\n   &lt;chr&gt;                       &lt;dbl&gt;\n 1 Perdriel                     90.5\n 2 La Consulta                  90.1\n 3 Valle de Uco                 89.5\n 4 Agrelo                       89.3\n 5 Luj√°n de Cuyo                88.8\n 6 Uco Valley                   88.4\n 7 San Carlos                   88.3\n 8 Tupungato                    88.2\n 9 Medrano                      88  \n10 Vista Flores                 87.8\n11 Mendoza                      87.1\n12 Maip√∫                        87  \n13 Altos de Mendoza             86  \n\n\nDe esta manera descubrimos, para mi sorpresa incluso, que en Perdriel (una localidad dentro de Luj√°n de Cuyo) podemos encontrar los mejores malbecs de la provincia.\nY ahora esto lo podemos visualizar en un gr√°fico.\n\n\nVer c√≥digo\nggplot(promedio_regiones, aes(x = puntaje_promedio, \n                              y = reorder(region_1, puntaje_promedio))) + # Ordenamos las regiones por puntaje_promedio\n  geom_col(fill = \"#82163D\") + # Color malbec ;p\n  theme_minimal()  + # Modificamos el estilo del gr√°fico\n  # A√±adimos el t√≠tulo al gr√°fico y a los ejes\n  labs(title = \"Ranking de regiones de Mendoza con los mejores Malbec\", \n       x = \"Puntaje Promedio\",\n       y = \"Regi√≥n de Mendoza\") +\n  theme(title = element_text(color = \"#82163D\"),\n        plot.title.position = \"plot\") +\n  # A√±adimos el puntaje a cada barra\n  geom_text(aes(label = round(puntaje_promedio,1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) \n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Guardamos el gr√°fico en un archivo png\nggsave(\"output/ranking_regiones.png\", dpi = 300, create.dir = TRUE)\n\n\nAs√≠ podemos ver f√°cilmente las localidades con los mejores vinos malbec, y podr√≠amos planificar el viaje asegur√°ndonos de visitar las mejores bodegas.\nDespu√©s me agradecen."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#los-datos",
    "href": "es/vino-y-capacitacion/index.html#los-datos",
    "title": "Gestionar capacitaci√≥n buscando el mejor vino",
    "section": "Los datos",
    "text": "Los datos\nPara realizar este ejercicio, vamos a usar un dataset ficticio, que simula compilar resultados de encuestas de capacitaci√≥n, e incluye m√©tricas como:\n\nsatisfaction: eval√∫a en qu√© medida el curso gust√≥ o no.\nfacilitator_score: punt√∫a la calidad del facilitador/a de la actividad.\nmaterials_satisfaction: mide la satisfacci√≥n con los materiales provistos por el proveedor del curso.\nwilling_recommend: eval√∫a si recomendar√≠a el curso o no.\narea_goals_alignment: mide en qu√© porcentaje el curso est√° alineado con los objetivos del √°rea.\nwork_aplication: en qu√© medida el contenido del curso se puede trasladar al trabajo.\nscrap_learning: mide cu√°nto del contenido de la actividad no tiene aplicaci√≥n en el trabajo (leer m√°s en este art√≠culo).\n\n\n\nVer c√≥digo\n# Carga de datos\ntraining &lt;- read_delim(\"data/training_ratings.csv\",\n                       delim = \";\")\n\n# Explorar dataset\nglimpse(training)\n\n\nRows: 101\nColumns: 11\n$ id_training            &lt;dbl&gt; 129, 129, 129, 129, 145, 41, 41, 41, 41, 41, 41‚Ä¶\n$ program                &lt;chr&gt; \"5 por qu√©/ Problem Solving\", \"5 por qu√©/ Probl‚Ä¶\n$ id_emp                 &lt;dbl&gt; 892, 898, 1499, 1695, 967, 804, 879, 1454, 1455‚Ä¶\n$ satisfaction           &lt;dbl&gt; 8, 7, 2, 5, 6, 10, 5, 9, 8, 4, 2, 8, 6, 10, 8, ‚Ä¶\n$ facilitator_score      &lt;dbl&gt; 4, 2, 8, 10, 10, 6, 6, 7, 4, 7, 1, 10, 6, 8, 4,‚Ä¶\n$ materials_satisfaction &lt;dbl&gt; 8, 9, 5, 9, 9, 7, 4, 1, 1, 8, 5, 1, 9, 7, 1, 9,‚Ä¶\n$ willing_reccomend      &lt;dbl&gt; 8, 7, 8, 1, 4, 5, 1, 2, 10, 8, 7, 8, 5, 5, 5, 9‚Ä¶\n$ area_goals_alignment   &lt;dbl&gt; 0.4, 0.5, 0.9, 0.6, 0.4, 0.1, 0.6, 0.5, 0.6, 0.‚Ä¶\n$ work_aplication        &lt;dbl&gt; 1.0, 0.6, 0.4, 0.9, 0.9, 0.1, 0.8, 0.1, 0.3, 0.‚Ä¶\n$ scrap_learning         &lt;dbl&gt; 0.0, 0.4, 0.6, 0.1, 0.1, 0.9, 0.2, 0.9, 0.7, 0.‚Ä¶\n$ supplier               &lt;chr&gt; \"INTERNO\", \"INTERNO\", \"INTERNO\", \"INTERNO\", \"IN‚Ä¶\n\n\nComo podemos apreciar, hay muchas dimensiones en las que nos podemos enfocar para medir la calidad de nuestros proveedores de capacitaci√≥n. Para este ejercicio vamos a analizar a los proveedores seg√∫n qu√© tan alineados est√°n con los objetivos del √°rea.\n¬øPor qu√© vamos a analizar a los proveedores seg√∫n su alineaci√≥n con los objetivos?\n\n\n\n\n\n\nPar√©ntesis: Nombres de los proveedores de capacitaci√≥n\nCasi todos los datos de este dataset son inventados por m√≠, los puntajes fueron generados aleatoriamente, pero los nombres de los proveedores y de los cursos los saqu√© de los proveedores y cursos que ten√≠amos en Pilkington de la √©poca que trabaj√© ah√≠ (2010-2016).\nAs√≠ que para no herir susceptibilidades, ni que se malinterprete la informaci√≥n que vamos a generar, vamos a usar el paquete noah que lo que hace es generar nombres aleatorios para enmascarar los nombres reales, y mostrar un nombre simp√°tico en vez del real.\n\n\n\n\n\n\n\nVer c√≥digo\n# Cargar la librer√≠a\n# install.packages(\"noah\")\nlibrary(noah)\n\n# Crear columna con nombres random\ntraining &lt;- training %&gt;% \n    mutate(pseudo_supplier = pseudonymize(supplier)) \n\n# Guardamos el archivo nuevo\nwrite_delim(training, \"output/training_data_fake_names.csv\", delim = \";\")\n\n# Veamos los nombres nuevos que tienen los proveedores con este cambio\nfake_names &lt;- unique(training$pseudo_supplier)\n\nfake_names\n\n\n [1] \"Overt Asp\"           \"Waggish Cow\"         \"Hulking Vaquita\"    \n [4] \"Familiar Wildcat\"    \"Famous Xerinae\"      \"Half Newt\"          \n [7] \"Fantastic Jacana\"    \"Jaded Dhole\"         \"Lonely Woodpecker\"  \n[10] \"Known Swordtail\"     \"Placid Guppy\"        \"Mammoth Heron\"      \n[13] \"Scarce Koi\"          \"Bad Flyingfish\"      \"Inquisitive Octopus\"\n[16] \"Furtive Jaguar\"     \n\n\n¬øQui√©n no querr√≠a hacer un curso en Overt Asp? üòÅ\nCierro par√©ntesis."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#calcular-proveedores-mejor-alineados-con-los-objetivos-del-√°rea",
    "href": "es/vino-y-capacitacion/index.html#calcular-proveedores-mejor-alineados-con-los-objetivos-del-√°rea",
    "title": "Gestionar capacitaci√≥n buscando el mejor vino",
    "section": "Calcular proveedores mejor alineados con los objetivos del √°rea",
    "text": "Calcular proveedores mejor alineados con los objetivos del √°rea\nEl siguiente paso es calcular el promedio de alineaci√≥n con objetivos por cada proveedor. De nuevo, podr√≠a ser por cualquier m√©trica, pero para este art√≠culo elejimos esa.\nComo la idea del an√°lisis es analizar proveedores externos. Vamos a filtrar los cursos dictados internamente, y luego vamos a calcular el promedio de alineaci√≥n con objetivos para cada proveedor.\n\n\nVer c√≥digo\n# Crear un dataset de proveedores externos\nexternal_vendors &lt;- training %&gt;% \n  filter(supplier != \"INTERNO\") # Elimina las filas de cursos internos\n\n# Calculamos el puntaje promedio de alineaci√≥n para cada proveedor\nvendor_alignment_score &lt;-  external_vendors %&gt;% \n  group_by(pseudo_supplier) %&gt;% \n  summarise(puntaje_promedio = mean(area_goals_alignment)) %&gt;%\n  arrange(desc(puntaje_promedio))\n\n# Veamos el ranking\nvendor_alignment_score\n\n\n# A tibble: 15 √ó 2\n   pseudo_supplier     puntaje_promedio\n   &lt;chr&gt;                          &lt;dbl&gt;\n 1 Waggish Cow                    0.833\n 2 Placid Guppy                   0.7  \n 3 Scarce Koi                     0.7  \n 4 Hulking Vaquita                0.633\n 5 Furtive Jaguar                 0.614\n 6 Familiar Wildcat               0.6  \n 7 Fantastic Jacana               0.6  \n 8 Famous Xerinae                 0.583\n 9 Inquisitive Octopus            0.575\n10 Lonely Woodpecker              0.562\n11 Bad Flyingfish                 0.5  \n12 Half Newt                      0.433\n13 Mammoth Heron                  0.4  \n14 Jaded Dhole                    0.375\n15 Known Swordtail                0.3  \n\n\nDe esta manera podemos ver que Waggish Cow es el mejor proveedor con un puntaje de 83.3% y que el peor proveedor es Known Swordtail.\nCon estos datos podemos hacer un gr√°fico de la misma manera que lo hicimos con el gr√°fico de vinos.\n\n\nVer c√≥digo\nggplot(vendor_alignment_score, aes(x = puntaje_promedio, \n                              y = reorder(pseudo_supplier, puntaje_promedio))) + # Ordenamos los vendors por puntaje_promedio\n  geom_col(fill = \"#103F79\") +\n  theme_minimal()  + # Modificamos el estilo del gr√°fico\n  # A√±adimos el t√≠tulo al gr√°fico y a los ejes\n  labs(title = \"Ranking de proveedores de capacitaci√≥n\",\n       subtitle = \"Ordenados por Alineaci√≥n con Objetivos del √Årea\",\n       x = \"Puntaje Promedio\",\n       y = \"Vendor\",\n       caption = \"Datos generados aleatoriamente\") +\n  theme(title = element_text(color = \"#103F79\"),\n        plot.title.position = \"plot\") +\n  # A√±adimos el puntaje a cada barra\n  geom_text(aes(label = scales::percent(puntaje_promedio,\n                                        accuracy = 0.1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1))\n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Guardamos el gr√°fico en un archivo png\nggsave(\"output/ranking_proveedores_basico.png\", dpi = 300, create.dir = TRUE)\n\n\nIncluso podemos ir un paso m√°s all√° y agregar una l√≠nea que nos indique el target de alineaci√≥n m√≠nimo. De esta manera podremos saber qu√© proveedores debemos mantener s√≠ o s√≠ independiemente del costo, y cu√°les son los vendors que tenemos que reemplazar.\n\n\nVer c√≥digo\nggplot(vendor_alignment_score, aes(x = puntaje_promedio, \n                              y = reorder(pseudo_supplier, puntaje_promedio))) + # Ordenamos los vendors por puntaje_promedio\n  geom_col(fill = \"#103F79\") +\n  theme_minimal()  + # Modificamos el estilo del gr√°fico\n  # A√±adimos el t√≠tulo al gr√°fico y a los ejes\n  labs(title = \"Ranking de proveedores de capacitaci√≥n\",\n       subtitle = \"Ordenados por Alineaci√≥n con Objetivos del √Årea\",\n       x = \"Puntaje Promedio\",\n       y = \"Vendor\",\n       caption = \"Datos generados aleatoriamente\") +\n  theme(title = element_text(color = \"#103F79\"),\n        plot.title.position = \"plot\") +\n  # A√±adimos el puntaje a cada barra\n  geom_text(aes(label = scales::percent(puntaje_promedio,\n                                        accuracy = 0.1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  # Definimos un umbral de 60% con una l√≠nea punteada amarilla\n  geom_vline(xintercept = 0.6,\n             color = \"#F3B229\",\n             linetype = 2,\n             linewidth = 1)\n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Guardamos el gr√°fico en un archivo png\nggsave(\"output/ranking_proveedores.png\", dpi = 300, create.dir = TRUE)\n\n\nIncluso podr√≠amos asignar colores distintos a los proveedores cuyo puntaje sea inferior al 40% para indicar de esa manera qu√© proveedores deber√≠an ser reemplazados.\n\n\nVer c√≥digo\n# Guardemos el gr√°fico en un objeto para simplificar la lectura\np &lt;- ggplot(vendor_alignment_score, aes(x = puntaje_promedio, \n                              y = reorder(pseudo_supplier, puntaje_promedio))) + \n  # Definimos los cortes en funci√≥n del puntaje promedio\n  geom_col(aes(fill = cut(puntaje_promedio,\n                           c(-Inf,0.4, Inf)))) \n# Los valores van de menos infinito, a 0.4, y luego hasta el infinito\n\n# Veamos este paso\np\n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Ahora asignemos el color en funci√≥n de los valores de puntaje_promedio\n# Si el valor es mayor a 0.4 (40%) entonces el color es azul.\n# Si el valor es menor a 0.4, entonces el color de la barra ser√° naranja.\np &lt;- p +\n  scale_fill_manual(values = c(\"(-Inf,0.4]\" = \"#F7B234\",\n                               \"(0.4, Inf]\" = \"#103F79\"),\n                    labels = c(\"Reemplazar\", \"Mantener\")\n                    )\n# Veamos como queda hasta ahora\np\n\n\n\n\n\n\n\n\n\nVer c√≥digo\n# Gr√°fico final con todos los lujos\np +\n  # A√±adimos el t√≠tulo al gr√°fico y a los ejes\n  labs(title = \"Ranking de proveedores de capacitaci√≥n\",\n       subtitle = \"Ordenados por Alineaci√≥n con Objetivos del √Årea\",\n       x = \"Puntaje Promedio\",\n       y = \"Vendor\",\n       caption = \"Datos generados aleatoriamente\",\n       fill = \"Acci√≥n\") +\n  # A√±adimos el puntaje a cada barra\n  geom_text(aes(label = scales::percent(puntaje_promedio,\n                                        accuracy = 0.1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  # Definimos un umbral de 60% con una l√≠nea punteada amarilla\n  geom_vline(xintercept = 0.6,\n             color = \"#F3B229\",\n             linetype = 2,\n             linewidth = 1) +\n  theme_minimal() +  # Modificamos el estilo del gr√°fico\n  guides(fill = guide_legend(reverse=TRUE)) +\n  theme(title = element_text(color = \"#103F79\"),\n        plot.title.position = \"plot\",\n        legend.position = \"top\") \n\n\n\n\n\n\n\n\n\nVer c√≥digo\nggsave(\"output/ranking_proveedores_final.png\")"
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#footnotes",
    "href": "es/vino-y-capacitacion/index.html#footnotes",
    "title": "Gestionar capacitaci√≥n buscando el mejor vino",
    "section": "Notas",
    "text": "Notas\n\n\nMendoza es la provincia m√°s importante en producci√≥n de vinos de Argentina, y la cepa m√°s representativa del pa√≠s es el malbec.‚Ü©Ô∏é"
  }
]