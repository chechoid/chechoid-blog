[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mi blog de R y People Analytics",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "es/tidytuesday-simpsons/index.html",
    "href": "es/tidytuesday-simpsons/index.html",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Vamos a cargar los datos con el paquete tidytuesdayR:\n\n\nVer código\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "es/tidytuesday-simpsons/index.html#the-simpsons-data",
    "href": "es/tidytuesday-simpsons/index.html#the-simpsons-data",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Vamos a cargar los datos con el paquete tidytuesdayR:\n\n\nVer código\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "es/tidytuesday-simpsons/index.html#calcular-el-rating-promedio-por-duplas",
    "href": "es/tidytuesday-simpsons/index.html#calcular-el-rating-promedio-por-duplas",
    "title": "Tidy Tuesday - Simpsons",
    "section": "Calcular el rating promedio por duplas",
    "text": "Calcular el rating promedio por duplas\nVamos a limpiar un poco más los datos, quedándonos únicamente con las duplas que aparezcan al menos 5 veces\n\n\nVer código\ntop_duplas &lt;- duplas_por_episodio %&gt;% \n  count(dupla, name = \"cuenta\") %&gt;% \n  filter(cuenta &gt;= 10)\n\n# Reducimos el dataframe\nduplas_por_episodio &lt;- duplas_por_episodio %&gt;% \n  filter(dupla %in% top_duplas$dupla)\n\n\nAhora podemos unir los datos de duplas_por_episodio y de esa manera calculamos el rating de cada pareja de personajes.\n\n\nVer código\nduplas_con_rating &lt;- duplas_por_episodio %&gt;% \n  inner_join(episodes, by = c(\"episode_id\" = \"id\")) %&gt;% \n  group_by(dupla) %&gt;% \n  summarise(imdb_promedio = mean(imdb_rating, na.rm = TRUE),\n            episodios = n())\n\n# Filtrar solo las duplas que aparecen en al menos 10 episodios\nduplas_con_rating &lt;- duplas_con_rating %&gt;%\n  filter(episodios &gt;= 10) %&gt;%\n  arrange(desc(imdb_promedio))\n\n\nY ahora podemos hacer un gráfico de las 10 parejas con mejor puntaje promedio en imdb_ranking.\n\n\nVer código\n# Seleccionar los mejores dúos\ntop_10_duplas &lt;- duplas_con_rating %&gt;% \n  head(10)\n\n\n# Gráfico\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_point(size = 3, color = \"#4f76df\") +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodios: \", episodios)),nudge_y = 0.35,\n            size = 3.5, \n            face = \"bold\",\n            color = \"#4f76df\", \n            family = \"Atma Medium\") +\n  labs(\n    title = \"Top 10 duplas de personajes con mejor IMDb rating promedio\",\n    y = \"Dupla de personajes\",\n    x = \"IMDb rating promedio\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer código\nggsave(\"top_duplas.png\", dpi = 300)\n\n\nY si agregamos donas en vez de puntos?\n\n\nVer código\n# Y si metemos una dona en vez de puntos?\nlibrary(ggimage)\n\n# Agregamos una columna con la imagen de la dona\ntop_10_duplas &lt;- top_10_duplas %&gt;% \n  mutate(imagen = \"dona.png\")\n\n# Gráfico\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_image(aes(image = imagen), size = 0.06) +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodios: \", episodios)),\n            nudge_y = 0.15,\n            nudge_x = -2.15,\n            size = 3.7,\n            family = \"Atma Medium\",\n            face = \"bold\",\n            color = \"#4f76df\") +\n  labs(\n    title = \"Top 10 duplas de personajes con mejor IMDb rating promedio\",\n    y = \"Dupla de personajes\",\n    x = \"IMDb rating promedio\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer código\nggsave(\"top_duplas_dona.png\", dpi = 300)"
  },
  {
    "objectID": "es/microaprendizajes/index.html",
    "href": "es/microaprendizajes/index.html",
    "title": "Microaprendizajes de un proyecto",
    "section": "",
    "text": "Esta presentación se centra en algunos microaprendizajes de un proyecto de análisis de resultados de una encuesta de diversidad e inclusión.\nLo razón por la que lo llamo “microaprendizajes” es porque no tuve que aprender muchas cosas desde cero, pero si aprendí varios truquitos que me sirvieron mucho.\nVoy a usar una encuesta simulada para no violar la confidencialidad de los datos, pero va a ser algo análogo a lo que estuve usando en el proyecto.\nPara explotar al máximo esta sesión conviene saber un poco de hacer informes con RMarkdown. Si necesitás un tutorial sobre ese tema te comparto el video que hicimos el año pasado.\n\n\n\n\n\nEste material se puede utilizar y compartir sin fines comerciales y citando la fuente.\n\n\n\nLicencia"
  },
  {
    "objectID": "es/microaprendizajes/index.html#el-chunk-de-setup",
    "href": "es/microaprendizajes/index.html#el-chunk-de-setup",
    "title": "Microaprendizajes de un proyecto",
    "section": "El chunk de ‘setup’",
    "text": "El chunk de ‘setup’\nEl bloque de código de setup es muy útil para controlar cómo se van a comportar todos los bloques de código.\nMi archivo original tiene +150 bloques de código, imaginen si modificara uno por uno las características de cada bloque.\n\n\nVer código\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.retina = 3,\n                      out.width = \"80%\")"
  },
  {
    "objectID": "es/microaprendizajes/index.html#ordenar-el-código",
    "href": "es/microaprendizajes/index.html#ordenar-el-código",
    "title": "Microaprendizajes de un proyecto",
    "section": "Ordenar el código",
    "text": "Ordenar el código\nTener un orden en el código es muy importante para poder ir y venir rápido y encontrar rápidamente las cosas, modificar algo, y demás.\nDentro de los bloques de código también es importante poner títulos o marcadores que nos ayuden a encontrar rápido las cosas. El orden que definí fue:\n\nLibrerías.\nConfiguraciones generales\nCarga de datos\nPreprocesamiento y limpieza de datos\nFunciones\n\n\n\nVer código\n# Librerías -----\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(scales)\nlibrary(extrafont)\nlibrary(readxl)\n\n\n# Configuraciones generales ----------\n\n# Colores\nverde &lt;- \"#01B3B6\"\nnegro &lt;- \"#333132\"\ngris &lt;- \"#AEB6BF\"\n\ncolor3 &lt;- c(verde, gris, negro)\ncolor2 &lt;- c(verde, negro)\n\n# Opciones de visualización --------\noptions(scipen = 999)   # Modifica la visualización de los ejes numérico a valores nominales\n\nloadfonts(quiet = TRUE) # Permite cargar en R otros tipos de fuentes.\n\n# Estilo limpio sin líneas de fondo\nestilo &lt;- theme(panel.grid = element_blank(),\n                plot.background = element_rect(fill = \"#FBFCFC\"),\n                panel.background = element_blank(),\n                text = element_text(family = \"Ubuntu Mono\"))\n\n# Estilo limpio con líneas de referencia verticales en gris claro\nestilov &lt;- theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#FBFCFC\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#ecf0f1\"),\n                 text = element_text(family = \"Ubuntu Mono\"))\n\n# Estilo limpio con líneas de referencia horizontales en gris claro\nestiloh &lt;- theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#FBFCFC\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.y = element_line(color = \"#ecf0f1\"),\n                 text = element_text(family = \"Ubuntu Mono\"))\n\n\n# Creo un objeto con un texto que se va a repetir mucho a lo largo del análisis\nfuente &lt;- \"Club de R para RRHH\\nDatos Ficticios\"\n\n# Creo objetos para formatear las etiquetas numéricas de los ejes x e y\neje_x_per &lt;- scale_x_continuous(labels = scales::percent_format(accuracy = 1))\n\neje_y_per &lt;- scale_y_continuous(labels = scales::percent_format(accuracy = 1))\n\n# Carga de Datos -----\nencuesta &lt;- read_excel(\"data/encuesta.xlsx\")\nplantel  &lt;- read_excel(\"data/plantel.xlsx\")\n\n# Preparación de datos -----------\n\n# Pivotea el dataset a un formato largo\nenc &lt;- encuesta %&gt;% \n  pivot_longer(cols = c(7:11),\n               names_to = \"pregunta\", \n               values_to = \"valor\")\n\n# Cambia nombres y Organiza variables ordinales \n\nenc &lt;- enc %&gt;% \n  rename(id = \"ID\",\n         genero = `¿Cómo definirías tu identidad de género?`,\n         unidad = \"Unidad de Negocio\",\n         pais = \"País\",\n         sector = \"Sector\",\n         cargo = \"Tu cargo/nivel:\") %&gt;% \n  mutate(cargo = factor(cargo,\n                        levels = c(\"Management\", \"Líder\", \"Contribuidor individual\")))\n\n# Crea categorías de resultados\n\nenc &lt;- enc %&gt;% \n  mutate(resultado = if_else(valor == \"Totalmente de acuerdo\", \"Positivo\", \n                             if_else(valor == \"De acuerdo\", \"Positivo\", \n                                     if_else(valor == \"Ni de acuerdo ni en desacuerdo\",\n                                             \"Neutral\", \"Negativo\"\n      )\n    )\n  ),\n         resultado = factor(resultado, \n                            levels = c(\"Positivo\", \"Neutral\", \"Negativo\")))\n\n\n\nY comenten el código por amor a Jebús!"
  },
  {
    "objectID": "es/microaprendizajes/index.html#poner-el-nombre-a-los-bloques-de-código",
    "href": "es/microaprendizajes/index.html#poner-el-nombre-a-los-bloques-de-código",
    "title": "Microaprendizajes de un proyecto",
    "section": "Poner el nombre a los bloques de código",
    "text": "Poner el nombre a los bloques de código\nAlgo muy útil es ponerle nombre a los bloques de código. Por un lado porque es fácil para navegar entre bloques buscándolos en RStudio.\nPor ejemplo, probemos un gráfico simple:\n\n\nVer código\nggplot(enc, aes(x = pais, fill = resultado)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(color3)) +\n  estiloh +\n  eje_y_per +\n  labs(title = \"Resultados por país\",\n       fill = \"Resultado\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nPuede ocurrir que necesitemos reutilizar el gráfico. Hacer la gran stackoverflow (copiar y pegar el código) es una opción, pero puede generar errores y por otro lado implica tiempo de procesamiento.\nEn cambio, con la opción ref.label podemos reutilizar lo que hicimos antes, de una forma más prolija y cómoda pasando el nombre del bloque anterior.\nInternamente, lo que hace R es reutilizar el código creado anteriormente.\n\n\nVer código\n{r ref.label=\"grafico1\"}\n\n\nVoilá!\n\n\nVer código\nggplot(enc, aes(x = pais, fill = resultado)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(color3)) +\n  estiloh +\n  eje_y_per +\n  labs(title = \"Resultados por país\",\n       fill = \"Resultado\",\n       x = \"\", y = \"\",\n       caption = fuente)"
  },
  {
    "objectID": "es/microaprendizajes/index.html#etiquetas-largas",
    "href": "es/microaprendizajes/index.html#etiquetas-largas",
    "title": "Microaprendizajes de un proyecto",
    "section": "Etiquetas largas",
    "text": "Etiquetas largas\nA veces necesitamos presentar en un gráfico o en una tabla la pregunta original de la encuesta. Por ejemplo, una de las “preguntas” de la encuesta dice:\n\nOtra pregunta que tiene muchísimo texto escrito en la encuesta y quedó tan larga que no entra en un solo renglón y que me hace preguntarme cómo la voy a poner en un gráfico\n\nAhora veamos cómo se ven las preguntas en un gráfico si intentamos hacer un ranking.\n\n\nVer código\nenc %&gt;% \n  group_by(pregunta, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = pregunta)) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nQueda hermoso, no? 😱\nPara sortear este problema podemos crear una columna nueva, y usar la función str_wrap() del paquete stringr.\nLo que hace esto es agregar el símbolo \\n que divide el texto en renglones. Con el parámetro width le indicamos la cantidad de caracteres de largo que tendrá cada renglón.\n\n\nVer código\n# Divide el largo de 'función' en varias líneas\nenc$preg2 &lt;- str_wrap(enc$pregunta, width = 40)\n\n# Veamos como queda esto en el df\nhead(enc$preg2,5)\n\n\n[1] \"Una pregunta con un texto muy pero muy\\npero muy largo, de verdad que es muy muy\\nmuy largo\"                                                                                     \n[2] \"Otra pregunta que tiene muchísimo texto\\nescrito en la encuesta y quedó tan larga\\nque no entra en un solo renglón y que me\\nhace preguntarme cómo la voy a poner en\\nun gráfico\"\n[3] \"Los líderes son unos capos\"                                                                                                                                                      \n[4] \"Que grosso es trabajar acá\"                                                                                                                                                      \n[5] \"Esta encuesta es genial\"                                                                                                                                                         \n\n\nY ahora podemos hacer un gráfico que se vea bien:\n\n\nVer código\nenc %&gt;% \n  group_by(preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop))) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nAhora queda mucho mejor 👍\nTambién se puede jugar con la altura del gráfico usando la opción fig.height en las opciones del bloque para que haya más espacio entre las barras.\n\n\nVer código\n{r fig.height=8} # El tamaño es exagerado en este caso\n\n\n\n\nVer código\nranking &lt;- enc %&gt;% \n  group_by(preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop))) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\nranking"
  },
  {
    "objectID": "es/microaprendizajes/index.html#texto-en-los-gráficos",
    "href": "es/microaprendizajes/index.html#texto-en-los-gráficos",
    "title": "Microaprendizajes de un proyecto",
    "section": "Texto en los gráficos",
    "text": "Texto en los gráficos\nEs simple agregar las etiquetas de datos a un gráfico:\n\n\nVer código\nranking +\n  geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            size = 3,                           # Cambia el tamaño de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\") \n\n\n\n\n\n\n\n\n\nMiremos lo que pasa cuando queremos agregar más información al gráfico, por ejemplo, con los resultados por país.\n\n\nVer código\nranking &lt;- enc %&gt;% \n  group_by(pais, preg2, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = reorder(preg2, prop), fill = pais)) +\n  geom_col(position = \"dodge\") +\n  estilov +\n  eje_x_per +\n  labs(title = \"Ranking de Respuestas Positivas\",\n       x = \"\", y = \"\",\n       fill = \"País\",\n       caption = fuente) +\n  scale_fill_brewer(palette = 2)\n\nranking +\n   geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            size = 3,                           # Cambia el tamaño de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\")             # Modifica la fuente\n\n\n\n\n\n\n\n\n\nEl problema es que todas las etiquetas de cada barra están centradas con la etiqueta del eje y. En la guía de geom_text en la documentación de ggplot2 encontramos como solucionar el problema usando el parámetro position_dodge().\n\n\nVer código\nranking &lt;- ranking +\n   geom_text(aes(label = percent(prop, # Muestra los resultados como porcentaje\n                                accuracy = 1)), # Indica la cantidad de decimales\n            position = position_dodge(0.9),     # Acomoda cada etiqueta con las barras\n            size = 3,                           # Cambia el tamaño de la letra\n            hjust = 1.2,                        # Mueve la etiqueta para la izquierda\n            family = \"Ubuntu Mono\")             # Modifica la fuente\n\nranking\n\n\n\n\n\n\n\n\n\nOtra mejora que podemos hacer al gráfico es acomodar los colores en la leyenda (la referencia de los colores) para que tengan la misma secuencia que tiene en el gráfico, es decir que el verde oscuro aparezca primero al igual que la barra con el verde más oscuro en el gráfico.\nEn esta página hay muchas variantes para trabajar con las etiquetas y leyendas.\n\n\nVer código\nranking +\n  guides(fill = guide_legend(reverse=TRUE)) + # Invierte el orden de los colores en la leyenda\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\n\nCuando estamos mapeando una variable categórica en el eje y, R lo ordena alfabéticamente desde abajo hacia arriba.\n\n\nVer código\nenc %&gt;% \n  group_by(sector, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = sector)) +\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Resultado Positivos por Sector\",\n       x = \"\", y = \"\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nPodemos usar la función fct_rev del paquete forcats para poner al revés las etiquetas del eje y cuando estamos mapeando las variables dentro de ggplot\n\n\nVer código\nenc %&gt;% \n  group_by(sector, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant/sum(cant)) %&gt;% \n  filter(resultado == \"Positivo\") %&gt;% \n  ggplot(aes(x = prop, y = fct_rev(sector))) + # Invertimos el orden del eje y\n  geom_col(fill = verde) +\n  estilov +\n  eje_x_per +\n  labs(title = \"Resultado Positivos por Sector\",\n       x = \"\", y = \"\",\n       caption = fuente)"
  },
  {
    "objectID": "es/microaprendizajes/index.html#funciones",
    "href": "es/microaprendizajes/index.html#funciones",
    "title": "Microaprendizajes de un proyecto",
    "section": "Funciones",
    "text": "Funciones\nEsto es un work-in-progress y tengo que agradecer a Mónica Alonso de RLadies Buenos Aires por la ayuda.\nEl problema es que me encontré muchas veces escribiendo esta secuencia de código muchas veces:\n\n\nVer código\n# Calcular pocertajes de respuestas\nenc %&gt;% \n  group_by(genero, resultado) %&gt;% \n  summarise(cant = n()) %&gt;% \n  mutate(prop = cant / sum(cant))\n\n\n# A tibble: 6 × 4\n# Groups:   genero [2]\n  genero    resultado  cant   prop\n  &lt;chr&gt;     &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 Femenino  Positivo   1127 0.764 \n2 Femenino  Neutral     244 0.165 \n3 Femenino  Negativo    104 0.0705\n4 Masculino Positivo   1477 0.823 \n5 Masculino Neutral     222 0.124 \n6 Masculino Negativo     96 0.0535\n\n\nMuchas veces resolví copiando y pegando el código, pero se hace tedioso controlar cada uno de los bloques de código y gráficos. Así que para eso, podemos crear nuestras propias funciones.\n\n\nVer código\ncant_prop_gen &lt;- function(df){\n  df %&gt;% \n    group_by(genero,resultado) %&gt;% \n    summarise(cant = n()) %&gt;% \n    mutate(prop = cant / sum(cant)) \n}\n\n\nY ahora lo podemos incorporar en nuestro flujo de trabajo como cualquier función.\n\n\nVer código\nenc %&gt;% \n  cant_prop_gen() %&gt;% \n  ggplot(aes(x = genero, y = prop, fill = resultado)) +\n  geom_col(position = \"dodge\") +\n  eje_y_per +\n  estiloh +\n  scale_fill_manual(values = color3) +\n  labs(title = \"Resultados por Género\",\n       x = \"\", y = \"\",\n       fill = \"Resultado\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nTodavía estoy resolviendo como crear funciones usando cualquier tipo de variable en la función. Por ahora, lo estoy resolviendo creando una función para cada combinación de variables que agrupo. No es lo ideal, pero es lo que hay. 🤷\nCapaz encuentre lo que necesito en estos libros:\n\nR para Ciencia de Datos\nHands-On Programming with R\nAdvanced R\n\nYa les contaré… stay tuned 📺"
  },
  {
    "objectID": "es/microaprendizajes/index.html#código-inline",
    "href": "es/microaprendizajes/index.html#código-inline",
    "title": "Microaprendizajes de un proyecto",
    "section": "Código Inline",
    "text": "Código Inline\nComo sabemos, algo interesante de RMarkdown es la posibilidad de utilizar el código de los bloques dentro del texto.\nAsí que creemos un pequeño objeto primero para almacenar los resultados positivos y negativos por género.\n\n\nVer código\nresult_genero &lt;- enc %&gt;% \n  cant_prop_gen()\n\nresult_genero\n\n\n# A tibble: 6 × 4\n# Groups:   genero [2]\n  genero    resultado  cant   prop\n  &lt;chr&gt;     &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 Femenino  Positivo   1127 0.764 \n2 Femenino  Neutral     244 0.165 \n3 Femenino  Negativo    104 0.0705\n4 Masculino Positivo   1477 0.823 \n5 Masculino Neutral     222 0.124 \n6 Masculino Negativo     96 0.0535\n\n\nUsando la llamada de datos de un dataframe con nombre_df[fila,columna] puedo usar los resultados almacenados para incluirlos dentro del texto por ejemplo para decir:\nLos resultados positivos para las personas de género femenino es 0.7640678.\nLo ideal es poder ver ese resultado como un porcentaje, así que intuitivamente podemos usar la función percent para lograr eso…\n…y no va a funcionar. Obtenemos el siguiente mensaje de error:\n\n\nVer código\n# Intento de código inline\n`r percent(result_genero[1,4])`\n\n# Quitting from lines 425-441 (r4hr_microaprendizajes.Rmd) \n# Error in is.finite(x) : default method not implemented for type 'list'\n\n\nPara que la función percent funcione la tenemos que combinar con la función pull . Y ahora así sí funciona:\nLos resultados positivos para las personas de género femenino es 76% ."
  },
  {
    "objectID": "es/microaprendizajes/index.html#trust-the-tidyverse",
    "href": "es/microaprendizajes/index.html#trust-the-tidyverse",
    "title": "Microaprendizajes de un proyecto",
    "section": "Trust the Tidyverse",
    "text": "Trust the Tidyverse\n\nLo barato sale caro\nDicho popular\n\n\nLa encuesta que estábamos analizando era anónima, lo cual hacía imposible poder cruzar datos contra el listado de empleados.\nPero, sí podíamos calcular los resultados según la composición del liderazgo. Para eso teníamos que calcular el porcentaje de líderes hombres y mujeres por sector.\n\n\nVer código\n# Cuento la cantidad de líderes por sector y géenero\nplantel &lt;- plantel %&gt;% \n  rename(division = `Unidad de Negocio`, \n         lider = Líder, \n         sexo = Género, \n         sector = Sector, \n         pais = País) %&gt;% \n  filter(lider == \"true\") %&gt;% \n  group_by(pais, division, sector, lider, sexo) %&gt;% \n  tally() %&gt;% \n  ungroup()\n\nplantel\n\n\n# A tibble: 106 × 6\n   pais  division sector           lider sexo          n\n   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;\n 1 Chad  Unidad 1 Comercial        true  Femenino      4\n 2 Chad  Unidad 1 Comercial        true  Masculino     3\n 3 Chad  Unidad 1 R&D              true  Femenino      5\n 4 Chad  Unidad 1 R&D              true  Masculino     1\n 5 Chad  Unidad 2 Administración   true  Femenino      3\n 6 Chad  Unidad 2 Administración   true  Masculino     6\n 7 Chad  Unidad 2 Calidad          true  Femenino      1\n 8 Chad  Unidad 2 Comercial        true  Femenino      5\n 9 Chad  Unidad 2 Comercial        true  Masculino     1\n10 Chad  Unidad 2 Recursos Humanos true  Femenino      3\n# ℹ 96 more rows\n\n\n\n\nVer código\n# Pivoteo el dataset a un dataset ancho\nplantel &lt;- plantel %&gt;% \n  pivot_wider(.,\n              names_from = sexo,\n              values_from = n)\n\n# Reemplaza los NA con un 0\nplantel[is.na(plantel)] &lt;- 0\n\n\n# Calculo porcentaje de líderes hombres\nplantel %&gt;% \n  mutate(prop_lider_hombre = if_else(Femenino == 0, 1, Masculino / (Masculino +Femenino))) %&gt;% \n  select(-lider)\n\n\n# A tibble: 60 × 6\n   pais  division sector           Femenino Masculino prop_lider_hombre\n   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;               &lt;int&gt;     &lt;int&gt;             &lt;dbl&gt;\n 1 Chad  Unidad 1 Comercial               4         3             0.429\n 2 Chad  Unidad 1 R&D                     5         1             0.167\n 3 Chad  Unidad 2 Administración          3         6             0.667\n 4 Chad  Unidad 2 Calidad                 1         0             0    \n 5 Chad  Unidad 2 Comercial               5         1             0.167\n 6 Chad  Unidad 2 Recursos Humanos        3         0             0    \n 7 Chad  Unidad 3 Administración          2         2             0.5  \n 8 Chad  Unidad 3 Calidad                 2         2             0.5  \n 9 Chad  Unidad 3 Comercial               5        20             0.8  \n10 Chad  Unidad 3 HSE                     1         0             0    \n# ℹ 50 more rows"
  },
  {
    "objectID": "es/indicadores_capacitacion/index.html",
    "href": "es/indicadores_capacitacion/index.html",
    "title": "Indicadores de Capacitación",
    "section": "",
    "text": "Con la Capacitación en las empresas pasa algo curioso: hace unos años atrás, entre mis compañeros de la Maestría de Data Mining hice una encuesta sobre beneficios, y una de las preguntas que hacía era “¿Qué beneficio que no tenés hoy te gustaría tener?”. Y 1 de cada 4 respuestas estaba relacionada con Capacitación (capacitación in company, desde cuotas en posgrados, certificaciones, etc.). Y yo pensaba por dentro “Pero… la capacitación no es un beneficio”. Sin embargo las personas perciben a la capacitación como un beneficio.\nLos cambios que impone la tecnología, y la rapidez con la que avanza, hacen que, como dijo Diego Bekerman, las empresas dejen de buscar “graduados de” para buscar “personas que saben de”. Esto plantea una nueva necesidad de Planificación Estratégica de Capital Humano en donde se plantean las capacidades que hoy tienen las personas y se las contrasta con las capacidades futuras que requiere la empresa. Y acá surge una de las primeras cuestiones: Estas capacidades, ¿las desarrollamos internamente o las salimos a buscar al mercado?\nDespués tenemos variables de contexto. No debe haber ni un sólo CEO, Gerente General o Dueño de una empresa que desconozca el valor y la importancia de la capacitación de sus empleados. Sin embargo, es uno de los primeros presupuestos que se corta en épocas de vacas flacas. Y uno de los principales factores que determinan estas decisiones seguramente se relaciona con que no cuentan con suficiente información sobre el impacto de la capacitación en los resultados de la empresa.\nNótese que escribí impacto en los resultados, no ROI. Ampliaremos.\nEntonces tenemos empleados que demandan capacitación, negocios que necesitan nuevas capacidades, y una constante tensión presupuestaria. Sin mencionar el contexto económico recesivo. ¿Cómo podemos usar indicadores para administrar, planificar y conseguir presupuesto para gestionar la capacitación en este contexto?\nEn primer lugar conociendo las necesidades del negocio.Y para esto es necesario entender qué es lo que demandan las personas que dirigen las empresas.\nEn Learning Analytics, John R Mattox II, Mark Van Buren y Jean Martin, plantean que los CEO’s pretenden que midamos:\n\nAplicación: ¿Cómo Podemos aumentar la aplicación de nuevas habilidades en el trabajo\nResultados: ¿En qué grado un programa de capacitación mejorará un resultado de negocio específico?\nValor: ¿Cuál será el Retorno de Inversión?\n\n¿Qué es lo que usualmente medimos en gestión de capacitación?\n\nCosto de capacitación por empleado\nSatisfacción con la capacitación.\nHoras de Capacitación por Empleado\nGastos de Capacitación Externa.\n\nEvidentemente hay un mismatch entre la información que demandan las personas que dirigen las empresas y la información que proveemos desde Recursos Humanos.\nAlec Levenson, uno de los autores más “hardcore evidence” de People Analytics que sigo, de formación en Economía, plantea en una podcast que el ROI no siempre es medible, por ejemplo,de una capacitación en empatía para líderes. Alec explica que el ROI se mide fundamentalmente en cashflow, y que no todo es traducible en términos económicos.\nUn punto interesante que plantea Levenson es dice que si encontramos vínculos entre cómo las personas operan en el negocio, en cómo se comunican, se hacen cargo y se comprometen, y en cómo enfocan su tiempo y energía en alcanzar la estrategia del negocio, y haciendo lo que es necesario hacer para crear ventajas competitivas, es todo lo que necesitamos mostrar. Si logramos establecer una relación consistente entre los comportamientos de las personas y las ventajas competitivas, generamos información más valiosa y expresiva (agrego yo) que el ROI.\n\n\nSi buscamos en nuestros apuntes y libros de la universidad como medir la gestión de capacitación, seguramente nos vamos a encontrar con los modelos de Donald Kirkpatrick y de Jack Phillips.\nEl Modelo de 4 Niveles de Evaluación de Kirkpatrick propone un enfoque para medir el impacto de la capacitación en los siguientes niveles:\nEl primer nivel apunta a medir la satisfacción de los colaboradores con el curso y con el facilitador. Muchas empresas sólo están midiendo este nivel. El aprendizaje busca medir si las personas adquirieron nuevos conocimientos y habilidades.\nRespecto al nivel 3, de medir conductas, Kirkpatrick plantea analizar si hubo un cambio de comportamiento luego de la capacitación. Volvamos a la entrevista de Alec Levenson, ¿cuáles son los comportamientos que crean ventajas competitivas?\nFinalmente el 4° nivel es el de resultados, que ahí buscaremos ver el impacto de las acciones de capacitación en resultados tanto operativos como de clima laboral por ejemplo.\nJack Phillips desarrolló la Metodología ROI que en gran parte se sustenta en el modelo de Kirkpatrick, cambiando ligeramente los primeros 4 niveles, y añadiendo el del ROI.\n\nReacción y acción planificada.\nAprendizaje.\nAplicación.\nImpacto.\nRetorno de Inversión.\n\nEstos 5 niveles son parte de la Metodología ROI que incluye además la planificación, la recolección de datos, su análisis y reporte.\nMi postura es que si hoy sólo estamos midiendo horas de capacitación y costos, lograr avanzar al nivel 3 (Conductas o Aplicación), ya es un enorme salto de calidad de las métricas del área. Si logramos eso, será más fácil medir resultados, y ya habrá tiempo para medir el ROI.\nKirkpatrick desarrolló su modelo en la década del ’50, mientras que Phillips lo hizo a principios de los ’80. En 2007 Josh Bersin publicó The Training Measurement Book, en donde se enfoca principalmente en la planificación y en el alineamiento de la capacitación con las necesidades del negocio.\nEl modelo de Bersin propone 9 métricas críticas para su Modelo de Medición de Impacto. Estas métricas son:\n\nSatisfacción.\nAprendizaje.\nAdopción (tasa del público target que completó el proceso de aprendizaje).\nUtilidad.\nEficiencia.\nAlineamiento.\nLogros de objetivos desde la perspectiva de los clientes.\nDesempeño Individual.\nDesempeño del Negocio.\n\nSi logramos incorporar métricas que incluyan los aspectos de cualquiera de estos modelos, más nuevas tendencias como el Scrap Learning (incluyendo la perspectiva de los jefes) podemos construir un set de información muy valiosa para los stakeholders de la organización. Correr el foco del ROI y enfocarlo en las ventajas competitivas (eso que la empresa hace bien y que la distingue de otras empresas) también nos permite canalizar los esfuerzos de gestión y de análisis en donde más valor aportamos a la rentabilidad del negocio."
  },
  {
    "objectID": "es/indicadores_capacitacion/index.html#de-vuelta-a-la-universidad",
    "href": "es/indicadores_capacitacion/index.html#de-vuelta-a-la-universidad",
    "title": "Indicadores de Capacitación",
    "section": "",
    "text": "Si buscamos en nuestros apuntes y libros de la universidad como medir la gestión de capacitación, seguramente nos vamos a encontrar con los modelos de Donald Kirkpatrick y de Jack Phillips.\nEl Modelo de 4 Niveles de Evaluación de Kirkpatrick propone un enfoque para medir el impacto de la capacitación en los siguientes niveles:\nEl primer nivel apunta a medir la satisfacción de los colaboradores con el curso y con el facilitador. Muchas empresas sólo están midiendo este nivel. El aprendizaje busca medir si las personas adquirieron nuevos conocimientos y habilidades.\nRespecto al nivel 3, de medir conductas, Kirkpatrick plantea analizar si hubo un cambio de comportamiento luego de la capacitación. Volvamos a la entrevista de Alec Levenson, ¿cuáles son los comportamientos que crean ventajas competitivas?\nFinalmente el 4° nivel es el de resultados, que ahí buscaremos ver el impacto de las acciones de capacitación en resultados tanto operativos como de clima laboral por ejemplo.\nJack Phillips desarrolló la Metodología ROI que en gran parte se sustenta en el modelo de Kirkpatrick, cambiando ligeramente los primeros 4 niveles, y añadiendo el del ROI.\n\nReacción y acción planificada.\nAprendizaje.\nAplicación.\nImpacto.\nRetorno de Inversión.\n\nEstos 5 niveles son parte de la Metodología ROI que incluye además la planificación, la recolección de datos, su análisis y reporte.\nMi postura es que si hoy sólo estamos midiendo horas de capacitación y costos, lograr avanzar al nivel 3 (Conductas o Aplicación), ya es un enorme salto de calidad de las métricas del área. Si logramos eso, será más fácil medir resultados, y ya habrá tiempo para medir el ROI.\nKirkpatrick desarrolló su modelo en la década del ’50, mientras que Phillips lo hizo a principios de los ’80. En 2007 Josh Bersin publicó The Training Measurement Book, en donde se enfoca principalmente en la planificación y en el alineamiento de la capacitación con las necesidades del negocio.\nEl modelo de Bersin propone 9 métricas críticas para su Modelo de Medición de Impacto. Estas métricas son:\n\nSatisfacción.\nAprendizaje.\nAdopción (tasa del público target que completó el proceso de aprendizaje).\nUtilidad.\nEficiencia.\nAlineamiento.\nLogros de objetivos desde la perspectiva de los clientes.\nDesempeño Individual.\nDesempeño del Negocio.\n\nSi logramos incorporar métricas que incluyan los aspectos de cualquiera de estos modelos, más nuevas tendencias como el Scrap Learning (incluyendo la perspectiva de los jefes) podemos construir un set de información muy valiosa para los stakeholders de la organización. Correr el foco del ROI y enfocarlo en las ventajas competitivas (eso que la empresa hace bien y que la distingue de otras empresas) también nos permite canalizar los esfuerzos de gestión y de análisis en donde más valor aportamos a la rentabilidad del negocio."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html",
    "href": "es/comparando-visualizaciones/index.html",
    "title": "Comparando Visualizaciones",
    "section": "",
    "text": "Hace unos años atrás, el 22/2/22 para ser exactos, hice un artículo en inglés comparando gráficos, luego de que Paul Van Der Laken PhD recomendara en LinkedIn un artículo de Nick Desbarats señalando los problemas de los boxplots en su fantástico sitio Nightingale Journal of Data Visualization Society.\nLo que pasó fue que en R4HR habíamos hecho un boxplot que nos resultó muy útil para evidenciar las desigualdades salariales entre hombres y mujeres, entonces me convertí en un paladín de los boxplots. Bueno, estoy exagerando, pero la realidad es que no existen gráficos mejores o peores que otros, sino gráficos que sirven a un propósito.\nEn fin, hace poco tuve un intercambio con Nick, y entonces pensé que sería una buena idea reflotar ese artículo en castellano para mi comunidad. Así que aquí lo tienen, un nuevo autoplagio 😎."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#preparación-de-datos",
    "href": "es/comparando-visualizaciones/index.html#preparación-de-datos",
    "title": "Comparando Visualizaciones",
    "section": "Preparación de datos",
    "text": "Preparación de datos\nEstoy cargando datos desde la fuente original. Por eso, esto requiere algo de limpieza de datos. Los datos están filtrados para mostrar solo los resultados de Argentina, y realicé algunos cálculos para estimar los salarios de medio tiempo como equivalentes a un salario de tiempo completo. Esos son los datos que voy a usar para hacer las visualizaciones. Podés descargar una versión limpia de estos datos desde este repositorio de GitHub.\n\n\nVer código\n# Librarias & Data ----\nlibrary(tidyverse)    # Limpieza y Manipulación de Datos\nlibrary(funModeling)  # Exploración y limpieza de datos y mucho más\nlibrary(scales)       # Ajustes a cómo ver las escalas de los ejes\nlibrary(googlesheets4) # Leer archivos de Google Sheets\nlibrary(gargle)       # Para lidiar con los caracteres especiales del castellano\n\n# Data\nsalaries &lt;- read_sheet(\"1aeuu9dVfN42EjyvbmhEcsf0ilSz2DiXU-0MpnF896ss\") %&gt;% \n    select(gender = \"Género\",\n           role = \"¿En qué puesto trabajás?\",\n           gross_salary = \"¿Cuál es tu remuneración BRUTA MENSUAL en tu moneda local? (antes de impuestos y deducciones)\",\n           country = \"País en el que trabajas\",\n           work_type = \"Trabajo\",\n           work_hours = \"Tipo de contratación\") %&gt;% \n  filter(country == \"Argentina\",\n         work_type == \"Relación de Dependencia\",\n         gender %in% c(\"Femenino\", \"Masculino\")) %&gt;% \n  select(-country, -work_type)\n\n## Limpieza de datos (no hay escapatoria de esto) ----\nsalaries &lt;- salaries %&gt;% \n  mutate(gross_salary = as.numeric(unlist(gross_salary)))\n\n# Añade columna para estimar el salario full time de trabajadores part time\nsalaries &lt;- salaries %&gt;% \n  mutate(multiplier = if_else(work_hours == \"Part time\", 1.5, 1),\n         ft_salary = gross_salary * multiplier) %&gt;% \n  select(-work_hours, -multiplier, -gross_salary)\n\n# Filtro y unificación de roles \nsalaries &lt;- salaries %&gt;% \n  filter(role != \"Juzgado Civil y Comercial\",\n         role != \"Programador\",\n         role != \"Cuidado\",\n         role != \"Asesor\",\n         role != \"Jefe de Proyecto\") %&gt;% \n  mutate(role = str_trim(role, side = \"both\"), # Elimina espacios vacíos\n         role = fct_collapse(role, \"Gerente\" = \"Superintendente\"),\n         role = fct_collapse(role, \"Director\" = \"Director ( escalafón municipal)\"),\n         role = fct_collapse(role, \"HRBP\" = c(\"Senior Consultoría\", \"specialist\", \"especialista\",\n                                                  \"Especialista en selección IT\", \"Recruiter\")),\n         role = fct_collapse(role, \"Responsable\" = c(\"Coordinación\", \"Coordinador de Payroll\",\n                                                         \"Encargado\", \"Supervisor\")),\n         role = fct_collapse(role, \"Administrativo\" = c(\"Asistente\", \"Asistente RRHH\", \"Aux\", \n                                                            \"Capacitador\", \"Consultor Ejecutivo\",\n                                                            \"consultor jr\")),\n         role = fct_collapse(role, \"Analista\" = c(\"Asesoramiento\", \"Consultor\", \"Generalista\", \n                                                      \"Reclutadora\", \"Selectora\", \"Senior\"))) \n\n# Filtra roles para analizar\nsalaries &lt;- salaries %&gt;% \n  filter(role %in% c(\"Analista\", \"HRBP\", \"Responsable\",\n                     \"Jefe\", \"Gerente\"))\n\n# Graba el dataframe en un csv para compartir.\nwrite_delim(salaries, file = \"hr_salaries_arg.csv\",\n            delim = \";\")\n\n\nLa siguiente sección es para customizar los gráficos.\n\n\nVer código\noptions(scipen = 999) # Cambia la notación científica por valores nominales\n\n# Estilo limpio con líneas horizontales grises\nstyleh &lt;- theme(panel.grid = element_blank(),\n                plot.background = element_rect(fill = \"#FBFCFC\"),\n                panel.background = element_blank(),\n                panel.grid.major.y = element_line(color = \"#EAEDED\"),\n                axis.ticks.y = element_blank(),\n                plot.title.position = \"plot\")\n\n# Estilo limpio con líneas verticales grises\nstylev &lt;- theme(panel.grid = element_blank(),\n                plot.background = element_rect(fill = \"#FBFCFC\"),\n                panel.background = element_blank(),\n                panel.grid.major.x = element_line(color = \"#EAEDED\"),\n                axis.ticks.x = element_blank(),\n                plot.title.position = \"plot\")\n\n\n# Modifica la forma en que se muestran los ejes\naxis_x_n &lt;- scale_x_continuous(labels = comma_format(big.mark = \".\", decimal.mark = \",\"))\naxis_y_n &lt;- scale_y_continuous(labels = comma_format(big.mark = \".\", decimal.mark = \",\"))\n\n\n# Colores\ngender_colors &lt;- genero &lt;- c(\"#8624F5\", \"#1FC3AA\") # Purple and green (sort of :p)\n\n# Fuente de datos\nfuente &lt;- \"Data Source: Encuesta KIWI de Sueldos de RRHH LATAM 2020\\nR4HR Club de R para RRHH\"\n\n\nVeamos un resumen de los datos.\n\n\nVer código\n# Ordena los puestos por jerarquía\nsalaries &lt;- salaries %&gt;% \n  mutate(role = fct_relevel(role, c(\"Analista\", \"HRBP\", \"Responsable\",\n                                   \"Jefe\", \"Gerente\"))) \n\n# Veamos un resumen de los datos\nsummary(salaries)\n\n\n    gender                      role       ft_salary      \n Length:536         Analista      :223   Min.   :      2  \n Class :character   Responsable   :136   1st Qu.:  56000  \n Mode  :character   Jefe          : 72   Median :  75000  \n                    HRBP          : 57   Mean   :  93288  \n                    Gerente       : 48   3rd Qu.: 105250  \n                    Administrativo:  0   Max.   :2140000  \n                    (Other)       :  0                    \n\n\nHay un par de valores inusuales. Primero, el valor mínimo, que claramente es un error (o alguien con malas intenciones), y luego el valor máximo, que podría ser posible, pero es altamente inusual para el mercado argentino. Si hacemos un histograma, el resultado sería extraño.\n\n\nVer código\nggplot(salaries, aes(x = ft_salary)) +\n  geom_histogram() +\n  labs(title = paste0(\"Distribución de Salario Bruto en HR \", emo::ji(\"scream\")),\n       subtitle = \"Datos de Argentina | en AR$\",\n       x = NULL, y = NULL,\n       caption = fuente) +\n  axis_x_n +\n  styleh\n\n\n\n\n\n\n\n\n\nAcá es donde funModeling hace su magia. La función profiling_num arroja una tabla con un montón de información estadística de resumen.\n\n\nVer código\n(numerical &lt;- profiling_num(salaries))\n\n\n   variable     mean  std_dev variation_coef  p_01  p_05  p_25  p_50   p_75\n1 ft_salary 93287.88 104693.9       1.122267 217.5 35000 56000 75000 105250\n    p_95   p_99 skewness kurtosis   iqr        range_98        range_80\n1 195500 290000 14.41845  275.362 49250 [217.5, 290000] [44500, 150000]\n\n\nDado que quiero analizar los valores centrales de los salarios, voy a eliminar todos los valores por fuera de los percentiles 5 y 95.\n\n\nVer código\n# Guarda los valores de los percentiles 5 y 95 de la tabla numerical\np05 &lt;- numerical[1,6]\np95 &lt;- numerical[1,10]\n\n# Filtra valores dentro del rango de los percentiles p05 y p95\nsalaries &lt;- salaries %&gt;% \n  filter(between(    # Función de soporte\n    ft_salary,       # Variable a filtrar\n    p05,             # Umbral mínimo\n    p95              # Umbral máximo\n  ))\n\n# Elimino objetos que no voy a volver a usar\nrm(numerical, p05, p95)\n\n\nAhora que tenemos una versión más limpia de los datos podemos empezar a comparar las visualizaciones.\n\n\nVer código\nggplot(salaries, aes(x = ft_salary)) +\n  geom_histogram() +\n  labs(title = \"Distribución de Salario Bruto en HR | Datos Limpios\",\n       subtitle = \"Data de Argentina | en AR$\",\n       x = NULL, y = NULL,\n       caption = fuente) +\n  axis_x_n +\n  styleh"
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#boxplots",
    "href": "es/comparando-visualizaciones/index.html#boxplots",
    "title": "Comparando Visualizaciones",
    "section": "Boxplots",
    "text": "Boxplots\nEn el debate en LinkedIn, Nick Desbarats dice que tiene problemas para encontrar casos de uso donde los boxplots fueran la mejor opción, así que compartí el siguiente gráfico:\n\n\nVer código\nggplot(salaries, aes(x = role, y = ft_salary, fill = gender)) +\n  geom_boxplot() +\n  scale_fill_manual(values = gender_colors) +\n  axis_y_n +\n  styleh +\n  labs(title = \"Distribución Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"Género\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nLo que me gusta de este gráfico es que podemos ver la distribución de los salarios por el tamaño de cada mitad de las cajas. Usemos de ejemplo la posición de Jefe. Las medianas entre hombres y mujeres son similares, pero en el caso de las mujeres la mitad inferior es más grande que la de los varones, indicando que el rango de salarios de las mujeres es más amplio. Eso nos dice que hay mujeres en la posición de Jefe con sueldos muy por debajo de la mediana.\nLo opuesto ocurre con profesionales masculinos en el puesto de Jefe. La mitad superior de la caja es más amplia, indicando que hay hombres con sueldos muy por encima de la mediana.\nNick tiene un punto a su favor. ¿Cuántos casos tenemos en cada rol? ¿3, 15, 300? No lo podemos saber con este tipo de gráfico. Entonces él sugirió probar con un gráfico de violín. Así que, veamos qué ocurre."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#violin-plot",
    "href": "es/comparando-visualizaciones/index.html#violin-plot",
    "title": "Comparando Visualizaciones",
    "section": "Violin plot",
    "text": "Violin plot\nLos gráficos de violín son una alternativa a los boxplots. Muestran el rango de valores con su largo, y las distintas concentraciones de datos con su ancho. La sección más ancha del gráfico suele indicar la mediana de los valores numéricos.:\n[\nConvirtamos nuestro boxplot original en un gráfico de violín.\n\n\nVer código\nggplot(salaries, aes(x = role, y = ft_salary, fill = gender)) +\n  geom_violin() +\n  scale_fill_manual(values = gender_colors) +\n  axis_y_n +\n  styleh +\n  labs(title = \"Distribución Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"Género\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nDada la cantidad de roles, no podemos apreciar el valor de este tipo de gráfico. Así que repitamos el ejercicio pero sólo con los Analistas y Gerentes\n\n\nVer código\nsalaries %&gt;% \n  filter(role %in% c(\"Analista\", \"Gerente\")) %&gt;% \n  ggplot(aes(x = role, y = ft_salary, fill = gender)) +\n  geom_violin() +\n  scale_fill_manual(values = gender_colors) +\n  axis_y_n +\n  styleh +\n  labs(title = \"Distribución Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"Género\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nEl ancho de cada gráfico indica que esa zona contiene mayor cantidad de casos. Para Gerentes hombres, podemos apreciar que la mayoría de los casos están cerca de la mediana. El largo o altura del gráfico indica el rango de valores. Para el caso de las Gerentas ese rango va desde aproximadamente AR$ 50.000 hasta cerca de los AR$ 200.000 y el ancho es bastante parejo a lo largo de las observaciones.\nEn el caso de los analistas, en las mujeres vemos que la sección más ancha se encuentra en torno a los AR$ 50.000 y se hace más delgada hacia arriba. En el caso de los varones, la parte más ancha del gráfico está más arriba que el de las mujeres, y el rango se expande hasta valores más altos.\nTal vez para este dataset, el gráfico de violín no sea la mejor opción para ver todos los roles juntos, así que probemos el gráfico de dispersión o scatter plot."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#scatter-plot",
    "href": "es/comparando-visualizaciones/index.html#scatter-plot",
    "title": "Comparando Visualizaciones",
    "section": "Scatter plot",
    "text": "Scatter plot\nUna manera de ver la distribución de los puntos de datos es mediante el scatter plot o gráficos de dispersión. Tendemos a usarlos para visualizar las relaciones entre dos variables numéricas, pero también podemos utilizarlos cuando tenemos una variable nominal.\n\n\nVer código\nggplot(salaries, aes(x = role, y = ft_salary, color = gender)) +\n  geom_point(size = 3,\n             alpha = 0.2,\n             position = position_jitter(0.3)) +\n  scale_color_manual(values = gender_colors) +\n  styleh +\n  axis_y_n +\n  labs(title = \"Distribución Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"Género\",\n       caption = fuente)\n\n\n\n\n\n\n\n\n\nNuevamente, con este dataset el scatter plot puede ser más confuso dado que en ciertos roles, como el de Analista o el Responsable tienen muchas observaciones, se dificulta apreciar las diferencias por color. Pero por ejemeplo, en el caso de los Gerentes se puede apreciar el rango de los salarios y dónde se concentran en el caso de los varones.\nProbemos separar los gráficos en gráficos más chicos para ver si ayuda a clarificar la interpretación de los datos.\n\n\nVer código\n# Calcular mediana de los salarios por género y rol \nmedian_salaries &lt;- salaries %&gt;%\n  group_by(gender, role) %&gt;%\n  summarise(median_salary = median(ft_salary, na.rm = TRUE), .groups = \"drop\")\n\nmedian_salaries &lt;- median_salaries %&gt;%\n  mutate(x = as.numeric(as.factor(gender)) - 0.4,  # Ajusta el inicio de la línea\n         xend = as.numeric(as.factor(gender)) + 0.4) # Ajusta el final de la línea\n\n# Gráfico\n## Scatter plot\nggplot(salaries, aes(x = gender, y = ft_salary, color = gender)) +\n  geom_point(size = 2,\n             alpha = 0.3,\n             position = position_jitter(0.22)) +\n  ## Customiza colores\n  scale_color_manual(values = gender_colors) +\n  ## Añade líneas de medianas\n  geom_segment(data = median_salaries, \n               aes(x = x, xend = xend, \n                   y = median_salary, \n                   yend = median_salary, \n                   color = gender), \n               size = 1,\n               show.legend = FALSE) +\n  ## Customiza el estilo del gráfico\n  styleh +\n  ## Customiza las etiquetas del eje y\n  axis_y_n +\n  ## Modifica títulos y ejes\n  labs(title = \"Distribución Salarial en Roles de HR en Argentina\",\n       subtitle = \"En AR$\",\n       y = \"Sueldo Bruto en AR$\",\n       x = NULL,\n       fill = \"Género\",\n       caption = paste0(fuente,\"\\nSugerencias por Nick Desbarats\")) +\n  ## Divide el gráfico en subgráficos por rol\n  facet_wrap(~role, nrow = 1) +\n  # Modificaciones estéticas adicionales al gráfico sugeridas por Nick Desbarats\n  theme(axis.title.y = element_text(color = \"grey30\", family = \"Poppins\"),\n        axis.text.x = element_blank(),\n        legend.position = \"top\",            # Mueve la leyenda arriba del gráfico\n        legend.justification = \"left\",      # Centra la leyenda horizontalmente\n        legend.box.just = \"left\",           # Alinea el contenido de la caja de la leyenda \n        legend.margin = margin(l = -50, t = 3),\n        panel.spacing = unit(25, \"pt\"),\n        strip.background = element_blank(),\n        stripp.text.x = element_text(face = \"bold\"),\n        axis.ticks.x = element_blank())\n\n\n\n\n\n\n\n\n\nVer código\n# Guarda el gráfico en un archivo png\nggsave(\"jittered_strip.png\", dpi = 300)\n\n\nAhora podemos apreciar de mejor manera todas las posiciones de los puntos de datos, donde los datos están más concentrados y también los diferentes rangos de los salarios tanto para hombres como para mujeres en los diferentes roles. Por lo tanto, es más fácil comparar y analizar los resultados y ver el número de observaciones.\nDado que estoy diseñando todas estas visualizaciones, podría estar sesgado, pero en mi opinión, al ver todos los roles juntos en una visualización, la carga cognitiva aumenta para interpretar la situación salarial tanto para el género como para todos los roles a la vez."
  },
  {
    "objectID": "es/comparando-visualizaciones/index.html#paquetes-de-r-utilizados",
    "href": "es/comparando-visualizaciones/index.html#paquetes-de-r-utilizados",
    "title": "Comparando Visualizaciones",
    "section": "Paquetes de R Utilizados",
    "text": "Paquetes de R Utilizados\nEstos son los paquetes de R usados para hacer este post:\n\nfunModeling: Pablo Casas (2020). funModeling: Exploratory Data Analysis and Data Preparation Tool-Box. R package, version 1.9.4. https://CRAN.R-project.org/package=funModeling\ntidyverse: Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686\nscales: Hadley Wickham and Dana Seidel (2020). scales: Scale Functions for Visualization. R package version 1.1.1. https://CRAN.R-project.org/package=scales\ngooglesheets4: Jennifer Bryan (2021). googlesheets4: Access Google Sheets using the Sheets API V4. R package version 1.0.0. https://CRAN.R-project.org/package=googlesheets4\ngargle: Jennifer Bryan, Craig Citro and Hadley Wickham (2021). gargle: Utilities for Working with Google APIs. R package version 1.2.0. https://CRAN.R-project.org/package=gargle\nemo: Hadley Wickham, Romain François and Lucy D’Agostino McGowan (2021). emo: Easily Insert ‘Emoji’. R package version 0.0.0.9000. https://github.com/hadley/emo"
  },
  {
    "objectID": "es/animando_graficos/index.html",
    "href": "es/animando_graficos/index.html",
    "title": "Animando gráficos con gganimate",
    "section": "",
    "text": "Hace rato que no hacía boludeces, así que mientras pensaba un fin de semana qué podía hacer, Boca jugaba un nuevo partido en el cual empezó perdiendo y terminó ganando, y me dí cuenta que nunca había usado el paquete gganimate para animar una visualización, así que qué mejor que usar un partido de Boca para transmitir las sensaciones del partido a través de un gráfico animado."
  },
  {
    "objectID": "es/animando_graficos/index.html#bocaaa-bocaaaa-bocaaaaaa",
    "href": "es/animando_graficos/index.html#bocaaa-bocaaaa-bocaaaaaa",
    "title": "Animando gráficos con gganimate",
    "section": "Bocaaa, Bocaaaa, Bocaaaaaa… 💙💛💙",
    "text": "Bocaaa, Bocaaaa, Bocaaaaaa… 💙💛💙\nDesde que Diego Martinez, el actual DT de Boca, asumió su cargo en Diciembre de 2023, una de las características que tiene su gestión (además de jugar mejor), es que varios partidos los comenzó perdiendo, y terminó ganando. Al día de hoy, (22 de mayo de 2024), ganó 12 partidos, de los cuales en 5 el primer gol lo hizo el rival.\nAsí que qué mejor ejemplo para graficar este caso de uso que aprovechando el vendaval de sensaciones que es mirar un partido de Boca Jrs. en la era Martinez.\nEn la fecha 2 del torneo local, Boca enfrentó como visitante a Central Córdoba de Santiago del Estero, que convirtieron el primer gol a los 3’ de comenzado el partido, y luego hicieron el 2-0 en el tiempo añadido al final del primer tiempo.\nApenas comenzó el 2° tiempo, Equi Fernandez hizo el 2-1, la Bestia Merentiel lo empató y lo dió vuelta a los 52’ y 80’ respectivamente. Cuando el partido estaba en tiempo añadido, Equi Fernandez puso el 2-4 final.\nAcompáñenme a experimentar el vendaval de sensaciones que es vivir un partido de Boca en un gráfico.\nVamos a usar el siguiente dataset:\n\n\nVer código\n# Carga de datos\nboca &lt;- read_excel(\"boca_vibes.xlsx\")\n\n# Explora las primeras 6 filas\nhead(boca)\n\n\n# A tibble: 6 × 5\n  minuto central_cordoba  boca diferencia resultado  \n   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;      \n1      1               0     0          0 Empata Boca\n2      2               0     0          0 Empata Boca\n3      3               1     0         -1 Pierde Boca\n4      4               1     0         -1 Pierde Boca\n5      5               1     0         -1 Pierde Boca\n6      6               1     0         -1 Pierde Boca\n\n\nEl dataset contiene un detalle de los resultados minuto a minuto, podemos observar el primer gol de Central Córdoba convertido por Rodrigo Uriel Atencio a los 3 minutos que deja a Boca abajo en el marcador.\nPara hacer el primer gráfico necesitamos transformar un poco los datos para que los goles de central_cordoba y de boca nos queden en una misma columna.\n\n\nVer código\npartido &lt;- boca |&gt; \n  pivot_longer(cols = c(central_cordoba, boca), \n               names_to = \"equipo\", \n               values_to = \"goles\") |&gt; \n  mutate(equipo = str_replace(equipo, \"central_cordoba\", \"Central Córdoba\"),\n         equipo = str_replace(equipo, \"boca\", \"Boca Jrs.\"))\n\n# Ver cómo quedó el dataset\nhead(partido)\n\n\n# A tibble: 6 × 5\n  minuto diferencia resultado   equipo          goles\n   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt;\n1      1          0 Empata Boca Central Córdoba     0\n2      1          0 Empata Boca Boca Jrs.           0\n3      2          0 Empata Boca Central Córdoba     0\n4      2          0 Empata Boca Boca Jrs.           0\n5      3         -1 Pierde Boca Central Córdoba     1\n6      3         -1 Pierde Boca Boca Jrs.           0\n\n\nUsemos un gráfico de líneas para visualizar el partido.\n\n\nVer código\n ggplot(partido) +                                           # Datos\n  geom_line(aes(x = minuto, y = goles, color = equipo),      # Tipo de gráfico y variables\n            linewidth = 1.1) +                               # Ancho de la línea\n  scale_color_manual(values = c(\"#103f79\", \"#EA0838\")) +     # Colores custom\n  theme_minimal() +                                          # Estilo del gráfico\n  labs(title = \"Central Córdoba vs. Boca\",\n       x = \"Goles\", y = \"Minuto\",\n       color = \"Equipo\")\n\n\n\n\n\n\n\n\n\nLe podemos incorporar una línea adicional para visualizar cómo iba el partido para Boca, en el cual podemos apreciar cómo arranca perdiendo, cerca del minuto ’50 lo empata, y en el final lo da vuelta.\n\n\nVer código\n# Guardamos el gráfico en un objeto llamado 'p'\np &lt;-  ggplot(partido) +                                           # Datos\n  geom_line(aes(x = minuto, y = goles, color = equipo),      # Tipo de gráfico y variables\n            linewidth = 1.1) +                               # Ancho de la línea\n  scale_color_manual(values = c(\"#103f79\", \"#EA0838\")) +         # Colores custom\n  theme_minimal() +                                          # Estilo del gráfico\n  labs(title = \"Central Córdoba vs. Boca\",\n       x = \"Minuto\", y = \"Goles\",\n       color = \"Equipo\") +\n  geom_line(data = boca, aes(x = minuto, y = diferencia), linewidth = 1.3,\n            linetype = 2)\n\n# Veamos el gráfico\np\n\n\n\n\n\n\n\n\n\nPero venimos a ver un gráfico animado, así que demosle movimiento al gráfico.\n\n\nVer código\n# Animemos el gráfico\n# transition_reveal funciona con gráficos de líneas\np + \n  transition_reveal(along = minuto) # MAGIA!!!!\n\n\n\n\n\n\n\n\n\nY manipulando un poco los datos podemos hacer cosas gloriosas…\n\n\nVer código\n# Añadir una columna para agregar un emoji en función de la diferencia y los goles\nboca &lt;- boca |&gt; \n  # Arranca el partido\n  mutate(estado = if_else(diferencia == 0 , \"meh\", if_else( \n  # Primer gol de Central Córdoba\n    diferencia &lt; 0 & central_cordoba == 1, \"cry\",  if_else(\n  # Segundo gol de Central Córdoba\n      diferencia &lt; 0 & central_cordoba == 2, \"angry\", if_else(\n  # Primer gol de Boca\n        diferencia &lt; 0 & boca == 1, \"fear\", if_else(\n  # Segundo gol de Boca\n          diferencia == 1 & boca == 2, \"biceps\", if_else(\n  # Tercer gol de Boca y cuarto gol\n            diferencia == 1, \"smile\", \"lol\")\n          )\n        )\n      ))))\n\n\n# Mapear cada nombre de emoji a un emoji\n# Link al paquete de emoji: https://github.com/hadley/emo\nboca &lt;- boca |&gt; \n  mutate(emoji = map_chr(estado, emo::ji))\n\n# Veamos como quedan los datos\nhead(boca)\n\n\n# A tibble: 6 × 7\n  minuto central_cordoba  boca diferencia resultado   estado emoji       \n   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;       \n1      1               0     0          0 Empata Boca meh    \"\\U0001f612\"\n2      2               0     0          0 Empata Boca meh    \"\\U0001f612\"\n3      3               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n4      4               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n5      5               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n6      6               1     0         -1 Pierde Boca cry    \"\\U0001f622\"\n\n\nVer código\n# Hagamos el gráfico final con anotaciones\np + \n  # Añadimos anotaciones en función de los goles\n  geom_text(data = boca, aes(x = 15, y = 3.5, \n                             label = paste0(\"Central Córdoba: \", central_cordoba,\n                                            \"\\nBoca: \", boca)),\n            size = 4,        # Tamaño de la letra\n            hjust = 0) +     # Alinea a la izquierda\n# Añadimos anotaciones usando emojis\n  geom_text(data = boca, aes(x = 15, y = 2.5, label = emoji), \n            size = 15) +\n# Añadimos un \"subtítulo\"\n  geom_text(data = boca, aes(x = 0, y = 4.5, label = paste0(\"Resultado: \", resultado)), hjust = 0) +\n# Animemos el gráfico\n   transition_reveal(along = minuto)\n\n\n\n\n\n\n\n\n\nVer código\n# Ya que estamos, guardemos el gráfico en un gif\nanim_save(\"boca_gganimate.gif\", animation = last_animation())\n\n\nSi quieren ver cómo fue el partido, pueden ver el siguiente resumen. Después me cuentan qué transmite más emoción, si mi gráfico o el video 🧐"
  },
  {
    "objectID": "en/doing-silly-things-r/index.html",
    "href": "en/doing-silly-things-r/index.html",
    "title": "Doing silly things in R",
    "section": "",
    "text": "I once watched Ryan Timpe, the Lead Data Scientist at Lego, where he shared how he sometimes took on fun projects to learn new data analysis skills. In his talk at the RStudio Conference, he mentioned analyzing the dialogues from The Golden Girls using text mining techniques to find the most frequent words. Every time one of the characters said the magic words, they’d take a “white shot” of whatever they were drinking.\nThis post is about something similar. I wanted to learn how to use images in my visualizations, and that’s how this project was born—using images of people with “similar” features to mine and incorporating those photos into a scatter plot.\nWhat might seem like a silly project involved:\n\nCreating a Google Form.\nCollecting data from responses.\nProcessing the results.\nIncluding visualizations with people’s images.\n\nProjects like this make learning feel less heavy and give you extra motivation to find solutions and get results."
  },
  {
    "objectID": "en/doing-silly-things-r/index.html#loading-and-preparing-data",
    "href": "en/doing-silly-things-r/index.html#loading-and-preparing-data",
    "title": "Doing silly things in R",
    "section": "Loading and Preparing Data",
    "text": "Loading and Preparing Data\nLet’s start by loading the libraries and importing data from a repository.\n\n\nView code\n# Libraries\nlibrary(tidyverse) # Load, cleand and wrangle data\nlibrary(ggimage)   # To use images withing chart\n\n# Data\nclones &lt;- read_delim(\"https://raw.githubusercontent.com/chechoid/silliest-use-of-r/main/source.csv\", delim = \";\")\n\n\ncomentarios &lt;- clones %&gt;% \n  select(comentarios = `Poné lo que quieras... parecidos, chistes, comentarios, etc...`) %&gt;% \n  filter(!is.na(comentarios))\n\n# Explore the data\nhead(clones)\n\n\n# A tibble: 6 × 24\n  `Marca temporal`    `Facha de Keanu` `Copadez de Keanu` `Facha de Russell`\n  &lt;dttm&gt;                         &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 2021-06-23 12:37:28               10                 10                  7\n2 2021-06-23 12:39:12                4                 10                  5\n3 2021-06-23 12:42:21                8                  9                  8\n4 2021-06-23 12:43:24               10                 10                  1\n5 2021-06-23 12:45:03               10                  8                  4\n6 2021-06-23 12:45:12                5                  9                  1\n# ℹ 20 more variables: `Copadez de Russell` &lt;dbl&gt;, `Facha de Nico` &lt;dbl&gt;,\n#   `Copadez de Nico` &lt;dbl&gt;, `Facha de Roberto` &lt;dbl&gt;,\n#   `Copadez de Roberto` &lt;dbl&gt;, `Facha de Jeff` &lt;dbl&gt;, `Copadez de Jeff` &lt;dbl&gt;,\n#   `Facha de Brad` &lt;dbl&gt;, `Copadez de Brad` &lt;dbl&gt;, `Facha del Mono` &lt;dbl&gt;,\n#   `Copadez del Mono` &lt;dbl&gt;, `Facha de Sergio` &lt;dbl&gt;,\n#   `Copadez de Sergio` &lt;dbl&gt;, `Facha de Ricky` &lt;dbl&gt;,\n#   `Copadez de Ricky` &lt;dbl&gt;, `Facha de Ben` &lt;dbl&gt;, `Copadez de Ben` &lt;dbl&gt;, …\n\n\nThe dataset included columns for each character’s “facha” (gorgeousness) and “copadez” (awesomeness) scores. The next steps were:\n\nRemoving irrelevant columns and adding an ID column.\nPivoting the table so that all the score columns ended up in two columns (one for “facha” and one for “copadez”).\n\n\n\nView code\n# Remove unnecesary columns\nclones &lt;- clones %&gt;% \n  select(-`Marca temporal`, -`Poné lo que quieras... parecidos, chistes, comentarios, etc...`)\n\n# Add id column\nclones &lt;- clones %&gt;% \n  rowid_to_column(var = \"id\")\n\n# Pivot to a lonf format\nclones &lt;- clones %&gt;% \n  pivot_longer(cols = c(\"Facha de Keanu\": \"Copadez de Javier\"),\n               names_to = \"personaje\",\n               values_to = \"puntaje\")\n\n# Explore the dataset again\nhead(clones)\n\n\n# A tibble: 6 × 3\n     id personaje          puntaje\n  &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;\n1     1 Facha de Keanu          10\n2     1 Copadez de Keanu        10\n3     1 Facha de Russell         7\n4     1 Copadez de Russell      10\n5     1 Facha de Nico            1\n6     1 Copadez de Nico          1\n\n\nWe started with 66 rows and 24 columns and ended up with a data frame of 1,452 rows and 3 columns. After removing intermediary words like \"de\" and \"del\" from names, we created separate columns for “facha” and “copadez.”\n\n\nView code\n# Split nominal variables\nclones &lt;- clones %&gt;% \n  mutate(personaje = str_remove(personaje, \"de \"),\n         personaje = str_remove(personaje, \"del \"))\n\n# Explore average score of each character\nclones %&gt;% \n  group_by(personaje) %&gt;% \n  summarise(valor_promedio = mean(puntaje)) %&gt;% \n  ggplot(aes(x = valor_promedio, y = personaje)) +\n  geom_point(size = 2)\n\n\n\n\n\n\n\n\n\nView code\n# Split the column 'personaje' (character) into two columns, one for the metric, the other for the name\nclones &lt;- clones %&gt;% \n  separate(personaje,  into = c(\"metrica\", \"persona\"))\n\n\n# Pivot to wide format \nclones &lt;- clones %&gt;% \n  pivot_wider(id_cols = c(id, persona),\n              names_from = metrica,\n              values_from = puntaje)\n\n# Explore the new data frame\nhead(clones)\n\n\n# A tibble: 6 × 4\n     id persona Facha Copadez\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Keanu      10      10\n2     1 Russell     7      10\n3     1 Nico        1       1\n4     1 Roberto     1       1\n5     1 Jeff        5       5\n6     1 Brad       10      10\n\n\nFinally, we had a dataset with 726 rows—one for each vote per character—and four columns: ID, character (personaje), “facha,” and “copadez.”\n\n\nView code\n# Calculate the average scores for each character and plot results\nresultados &lt;- clones %&gt;% \n  group_by(persona) %&gt;% \n  summarise(facha_promedio = mean(Facha),\n            copadez_promedio = mean(Copadez))\n\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio, color = persona)) +\n  geom_point(size = 3) +\n  labs(title = \"Average Awesomeness and Gorgeousness\",\n       x = \"Avg Awesomeness\",\n       y = \"Avg Gourgeness\",\n       color = \"Person\")\n\n\n\n\n\n\n\n\n\nThis gave us the foundation for our results. To make the chart less boring, let’s spice it up with images."
  },
  {
    "objectID": "en/doing-silly-things-r/index.html#adding-images-to-the-chart",
    "href": "en/doing-silly-things-r/index.html#adding-images-to-the-chart",
    "title": "Doing silly things in R",
    "section": "Adding Images to the Chart",
    "text": "Adding Images to the Chart\nAs mentioned earlier, I used Canva to resize all the images and saved them in a folder called “clones.” Instead of uploading each photo individually, I created a data frame linking the names of the characters to their corresponding image files.\n\n\nView code\n# Create a vector with the name of the people\npersona &lt;- resultados %&gt;% \n  select(persona) %&gt;% \n  pull()\n\n# Create a vector of images\nruta &lt;- \"pics\"       # Picture path\nextension &lt;- \"png\"   # Extension of the image files\n\n# Name of the files\nimagen &lt;- c(\"Ben\", \"Brad\", \"Javier\", \"jeff\", \"keanu\", \"mono\", \"nico\", \n            \"ricky\", \"roberto\", \"russell\", \"sergio\")\n\n# Create the vector of photos with the path and file extension\nfoto &lt;- str_c(ruta, imagen, sep = \"/\")\nfoto &lt;- str_c(foto, extension, sep = \".\")\n\n# Create the data frame and add the scores to it\npics &lt;- data.frame(persona, foto)\n\n# See the results of this process\npics\n\n\n   persona             foto\n1      Ben     pics/Ben.png\n2     Brad    pics/Brad.png\n3   Javier  pics/Javier.png\n4     Jeff    pics/jeff.png\n5    Keanu   pics/keanu.png\n6     Mono    pics/mono.png\n7     Nico    pics/nico.png\n8    Ricky   pics/ricky.png\n9  Roberto pics/roberto.png\n10 Russell pics/russell.png\n11  Sergio  pics/sergio.png\n\n\nWe now had a data frame with 11 rows and 2 columns (name and image path), which we integrated into the dataset with average “facha” (gorgeousness) and “copadez” (awesomeness) scores.\nFinally, it was time to add the images to the chart:\n\n\nView code\n# Join datasets\nresultados &lt;- left_join(resultados, pics)\n\nhead(resultados)\n\n\n# A tibble: 6 × 4\n  persona facha_promedio copadez_promedio foto           \n  &lt;chr&gt;            &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;          \n1 Ben               8.23             6.47 pics/Ben.png   \n2 Brad              8.52             7.55 pics/Brad.png  \n3 Javier            6.89             6.56 pics/Javier.png\n4 Jeff              5.06             6.45 pics/jeff.png  \n5 Keanu             7.77             8.74 pics/keanu.png \n6 Mono              3.30             6.30 pics/mono.png  \n\n\nFinally, it was time to add the images to the chart:\n\n\nView code\n# Final Result\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio)) +\n  geom_image(aes(image=foto), size = 0.08) +\n  theme_minimal() +\n  scale_x_continuous(limits = c(1,10)) +\n  scale_y_continuous(limits = c(1,10)) +\n  labs(title = \"Average Awesomeness and Gorgeousness\",\n       subtitle = \"n = 66\",\n       x = \"Avg Awesomeness\",\n       y = \"Avg Gourgeness\",\n       caption = \"No aunt was part of this analysis\")\n\n\n\n\n\n\n\n\n\nAccording to the data, I’m farther from Nicolás del Caño and Roberto Baradel and closer to Keanu Reeves. So, the data says I look like Keanu. Facts, not opinions 😎."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sergio Garcia Mora aka Checho",
    "section": "",
    "text": "Este blog va a ser un espacio en donde centraré contenido sobre programación en R, mayormente orientado a temas relacionados con Recursos Humanos y People Analytics (actualización 2025: también incluiré contenido en Python).\nHonestamente, a esta altura del partido no me interesa hacer algo solemne para “parecer profesional”, lo que busco más que nada es generar contenido que le sirva a todos los que estén arrancando sus carreras en People Analytics y a quienes están permanentemente aprendiendo.\nTodo el contenido de este blog se puede compartir de manera abierta y libre, citando por supuesto la fuente.\nEn este blog te vas a encontrar con contenido relacionado con R y otros más generales y “conceptuales” sobre People Analytics.\nPara contactarme o saber más de mí podés hacerlo a través de mis redes sociales o las redes de R4HR - Club de R para RRHH.\nEsta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.\nEste blog está hecho en R usando Quarto, un sistema de publicación de código abierto desarrollado por el equipo de RStudio. Para más informacion visita este contenido desarrollado por Isabella Velásquez."
  },
  {
    "objectID": "about.html#de-qué-va-este-blog",
    "href": "about.html#de-qué-va-este-blog",
    "title": "Sergio Garcia Mora aka Checho",
    "section": "",
    "text": "Este blog va a ser un espacio en donde centraré contenido sobre programación en R, mayormente orientado a temas relacionados con Recursos Humanos y People Analytics (actualización 2025: también incluiré contenido en Python).\nHonestamente, a esta altura del partido no me interesa hacer algo solemne para “parecer profesional”, lo que busco más que nada es generar contenido que le sirva a todos los que estén arrancando sus carreras en People Analytics y a quienes están permanentemente aprendiendo.\nTodo el contenido de este blog se puede compartir de manera abierta y libre, citando por supuesto la fuente.\nEn este blog te vas a encontrar con contenido relacionado con R y otros más generales y “conceptuales” sobre People Analytics.\nPara contactarme o saber más de mí podés hacerlo a través de mis redes sociales o las redes de R4HR - Club de R para RRHH.\nEsta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.\nEste blog está hecho en R usando Quarto, un sistema de publicación de código abierto desarrollado por el equipo de RStudio. Para más informacion visita este contenido desarrollado por Isabella Velásquez."
  },
  {
    "objectID": "en/tidytuesday-simpsons/index.html",
    "href": "en/tidytuesday-simpsons/index.html",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Let’s load the data with the tidytuesdayR package (or directly with the raw files if it doesn’t work.\n\n\nVer código\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "en/tidytuesday-simpsons/index.html#the-simpsons-data",
    "href": "en/tidytuesday-simpsons/index.html#the-simpsons-data",
    "title": "Tidy Tuesday - Simpsons",
    "section": "",
    "text": "Let’s load the data with the tidytuesdayR package (or directly with the raw files if it doesn’t work.\n\n\nVer código\n# tuesdata &lt;- tidytuesdayR::tt_load('2025-02-04')\n# ## OR\n# tuesdata &lt;- tidytuesdayR::tt_load(2025, week = 5)\n# \n# simpsons_characters &lt;- tuesdata$simpsons_characters\n# simpsons_episodes &lt;- tuesdata$simpsons_episodes\n# simpsons_locations &lt;- tuesdata$simpsons_locations\n# simpsons_script_lines &lt;- tuesdata$simpsons_script_lines\n\nsimpsons_characters &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_characters.csv')\nsimpsons_episodes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_episodes.csv')\nsimpsons_locations &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_locations.csv')\nsimpsons_script_lines &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-04/simpsons_script_lines.csv')"
  },
  {
    "objectID": "en/tidytuesday-simpsons/index.html#calculate-the-average-rating-by-pairs",
    "href": "en/tidytuesday-simpsons/index.html#calculate-the-average-rating-by-pairs",
    "title": "Tidy Tuesday - Simpsons",
    "section": "Calculate the Average Rating by Pairs",
    "text": "Calculate the Average Rating by Pairs\nWe’ll clean the data a bit more, keeping only the pairs that appear at least 10 times.\n\n\nVer código\ntop_duplas &lt;- duplas_por_episodio %&gt;% \n  count(dupla, name = \"cuenta\") %&gt;% \n  filter(cuenta &gt;= 10)\n\n# Reducimos el dataframe\nduplas_por_episodio &lt;- duplas_por_episodio %&gt;% \n  filter(dupla %in% top_duplas$dupla)\n\n\nNow we can join the data from duplas_por_episodio and in that way, calculate the average rating for echar character duo.\n\n\nVer código\nduplas_con_rating &lt;- duplas_por_episodio %&gt;% \n  inner_join(episodes, by = c(\"episode_id\" = \"id\")) %&gt;% \n  group_by(dupla) %&gt;% \n  summarise(imdb_promedio = mean(imdb_rating, na.rm = TRUE),\n            episodios = n())\n\n# Filter couples with at least 10 episode appearances\nduplas_con_rating &lt;- duplas_con_rating %&gt;%\n  filter(episodios &gt;= 10) %&gt;%\n  arrange(desc(imdb_promedio))\n\n\nAnd now we can make a plot of the 10 couples with the best average score of imdb_ranking.\n\n\nVer código\n# Select the best 10 duos\ntop_10_duplas &lt;- duplas_con_rating %&gt;% \n  head(10)\n\n\n# Chart\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_point(size = 3, color = \"#4f76df\") +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodes: \", episodios)),nudge_y = 0.35,\n            size = 3.5, \n            face = \"bold\",\n            color = \"#4f76df\", \n            family = \"Atma Medium\") +\n  labs(\n    title = \"Top 10 Character Pairs with the Highest Average IMDb Rating\",\n    y = \"Character Pair\",\n    x = \"Average IMDb Rating\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer código\nggsave(\"en_top_duplas.png\", dpi = 300)\n\n\nWhat if we use donuts instead of points?\n\n\nVer código\n# Library\nlibrary(ggimage)\n\n# Add a column with the name of the picture\ntop_10_duplas &lt;- top_10_duplas %&gt;% \n  mutate(imagen = \"dona.png\")\n\n# Chart\nggplot(top_10_duplas, aes(y = reorder(dupla, imdb_promedio), x = imdb_promedio)) +\n  geom_segment(aes(x = 0, xend = imdb_promedio,\n                   y = dupla, yend = dupla), color = \"#4f76df\") +\n  geom_image(aes(image = imagen), size = 0.06) +\n  geom_text(aes(label = paste0(\"Rating: \", round(imdb_promedio, 2), \" Episodes: \", episodios)),\n            nudge_y = 0.15,\n            nudge_x = -2.15,\n            size = 3.7,\n            family = \"Atma Medium\",\n            face = \"bold\",\n            color = \"#4f76df\") +\n  labs(\n    title = \"Top 10 Character Pairs with the Highest Average IMDb Rating\",\n    y = \"Character Pair\",\n    x = \"Average IMDb Rating\"\n  ) +\n  theme(panel.grid = element_blank(),\n                 plot.background = element_rect(fill = \"#ffd90f\"),\n                 panel.background = element_blank(),\n                 panel.grid.major.x = element_line(color = \"#70d1ff\"),\n                 text = element_text(face = \"bold\", family = \"Atma Medium\"),\n                 plot.title.position = \"plot\") +\n  scale_x_continuous(limits = c(0,8.5))\n\n\n\n\n\n\n\n\n\nVer código\nggsave(\"top_duplas_dona.png\", dpi = 300)"
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html",
    "href": "es/cargar_fechas_desde_excel/index.html",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "",
    "text": "¿A quién no le pasó esto alguna vez?\nEsto en R muchas veces también nos trae dolores de cabeza así que en esto post vamos a ver cómo podemos solucionar esto."
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html#paquetes",
    "href": "es/cargar_fechas_desde_excel/index.html#paquetes",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Paquetes",
    "text": "Paquetes\nPara este ejemplo vamos a utilizar 3 paquetes, openxlsx que nos permite cargar y guardar archivos de Excel, dplyr para manipular y limpiar datos (podés ver un tutorial acá). También vamos a usar el paquete janitor para limpiar los nombres de las columnas a un formato más fácil de utilizar (elimina tildes, pasa todo a minúscula y reemplaza espacios por guiones, por ejemplo).\nEl primer paso, en caso que no los tengas aún, es instalar los paquetes:\n\n\nVer código\n# Instalar paquetes\ninstall.packages(\"openxlsx\") # Cargar y guardar archivos de Excel\ninstall.packages(\"dplyr\")    # Manipular y limpiar datos\ninstall.packages(\"janitor\")  # Entre otras cosas, facilitar manipulación de columnas\n\n\nUna vez que termina la instalación, hay que cargarlos. No vamos a cargar el paquete janitor porque sólo vamos a usar una función.\nCargar un paquete “deja activas” todas las funciones del paquete, lo cual implica un consumo de memoria, muchas veces ínfimo, pero consumo al fin, así que en este caso mostraremos como usar una función sin cargar todas las funciones del paquete.\n\n\nVer código\n# Cargar paquetes\nlibrary(openxlsx)\nlibrary(dplyr)"
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html#los-datos",
    "href": "es/cargar_fechas_desde_excel/index.html#los-datos",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Los datos",
    "text": "Los datos\nEl caso que usaremos de ejemplo simula ser una base de Postulantes de una búsqueda que llevamos adelante para una vacante de People Analytics. Primero carguemos los datos que están almacenados en una carpeta llamada data.\n\n\nVer código\n# Cargar los datos en R\ndatos &lt;- read.xlsx(\"data/Postulantes.xlsx\") %&gt;% \n  janitor::clean_names() # Usamos solo la función clean_names() sin cargar todo el paquete janitor\n\n\nAhora veamos los datos que tenemos cargados:\n\n\nVer código\n# Ver los datos cargados\ndatos\n\n\n  fecha_sourcing         busqueda   nombre apellido   telefono            mail\n1          44729 People Analytics   Sergio   Garcia 1111111111 sergio@d4hr.com\n2          44729 People Analytics  Daniela   Garcia 2222222222            &lt;NA&gt;\n3          44729 People Analytics    Yanel Paulette 3333333333            &lt;NA&gt;\n4          44729 People Analytics    Carla   Cirone 4444444444            &lt;NA&gt;\n5          44729 People Analytics Santiago  Lardone 5555555555            &lt;NA&gt;\n  empresa            puesto   github          twitter\n1    R4HR Master of Puppets chechoid @sergiogarciamor\n2    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n3    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n4    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n5    R4HR Master of Puppets     &lt;NA&gt;             &lt;NA&gt;\n                                                  linkedin   fuente status\n1            https://www.linkedin.com/in/sergiogarciamora/  Twitter Activo\n2        https://www.linkedin.com/in/claudiadanielagarcia/ Linkedin Activo\n3               https://www.linkedin.com/in/yanelpaulette/ Linkedin Activo\n4       https://www.linkedin.com/in/carla-cirone-0566b095/ Linkedin Activo\n5 https://www.linkedin.com/in/santiagolardonequinodozrrhh/ Linkedin Activo\n  fecha_ultimo_contacto\n1                 44739\n2                 44739\n3                 44739\n4                 44739\n5                 44739\n\n\nVer código\n# Hagamos un zoom en los campos que contienen fechas\ndatos %&gt;% \n  select(fecha_sourcing, fecha_ultimo_contacto)\n\n\n  fecha_sourcing fecha_ultimo_contacto\n1          44729                 44739\n2          44729                 44739\n3          44729                 44739\n4          44729                 44739\n5          44729                 44739\n\n\nEn la tabla anterior vemos que el valor que obtenemos en la primera columna es 44729, el número que representa a la fecha 17/6/22 como podemos apreciar en el archivo original:\n\nAhora veremos cómo podemos resolver este problema."
  },
  {
    "objectID": "es/cargar_fechas_desde_excel/index.html#solución",
    "href": "es/cargar_fechas_desde_excel/index.html#solución",
    "title": "Cargar Campos de Fecha desde Excel Sin Errores",
    "section": "Solución",
    "text": "Solución\nPara empezar, seleccionemos algunas columnas nomás usando la función select(). Vamos a seleccionar los campos de fecha_sourcing que representa cuándo inició la búsqueda, nombre, empresa, y fecha_ultimo_contacto donde anotamos cuándo fue la última vez que nos pusimos en contacto con cada persona.\n\n\nVer código\n# Seleccionar los campos con fechas, nombre y empres y sobreescribo el data frame\ndatos &lt;- datos %&gt;% \n  select(fecha_sourcing, nombre, empresa, fecha_ultimo_contacto)\n\n# Ver el nuevo dataframe\ndatos\n\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1          44729   Sergio    R4HR                 44739\n2          44729  Daniela    R4HR                 44739\n3          44729    Yanel    R4HR                 44739\n4          44729    Carla    R4HR                 44739\n5          44729 Santiago    R4HR                 44739\n\n\nAhora nos quedamos con un data frame de 5 filas y 4 columnas.\nPara transformar el campo fecha_sourcing de un formato numérico a un formato de tipo fecha, vamos a usar la función as.Date() de R base.\n\n\nVer código\n# Transformar el campo fecha_sourcing a tipo fecha\ndatos %&gt;% \n  mutate(fecha_sourcing = as.Date(fecha_sourcing,          # Sobrescribimos el campo fecha_sourcing\n                                  origin = \"1899-12-30\",   # Fecha de origen para el conteo\n                                  tz = \"UTC\"))             # Huso horario\n\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1     2022-06-17   Sergio    R4HR                 44739\n2     2022-06-17  Daniela    R4HR                 44739\n3     2022-06-17    Yanel    R4HR                 44739\n4     2022-06-17    Carla    R4HR                 44739\n5     2022-06-17 Santiago    R4HR                 44739\n\n\nEl trabajo con fechas siempre fue complejo desde el punto de vista del análisis de datos. Especialmente con los distintos formatos que se usan en el mundo, por ejemplo dd/mm/aaaa en Sudamérica, o mm/dd/aaaa en Estados Unidos por ejemplo. R, cuando un campo fecha carga correctamente, lo transforma a un formato ISO 8601 aaaa-mm-dd.\n\nEl primer número que obtuvimos cuando cargamos la tabla en R (el 44729) significa que desde el 30 de diciembre de 1899 hasta el 17 de Junio de 2022 pasaron 44.729 días. De ahí el número que obtuvimos en la carga.\nEl parámetro tz, nos permite especificar el huso horario del registro. Para algunos casos puede ser relevante, pero para la mayoría de los casos de uso que le daríamos en RRHH, es un parámetro que podemos incluir o no.\n\nCambiar varios campos a la vez\nCon la tabla que estamos usando de ejemplo, no hay mucho problema en repetir el paso ya que únicamente tenemos dos campos de fechas. ¿Pero qué pasa si tenemos 6, 7, o más campos de fechas en un archivo? Repetir estos pasos manualmente va a hacer confuso nuestro código y más complejo de mantener.\nVeamos una forma de cambiar todos los campos de fecha usando algunas funciones auxiliares del paquete dplyr.\n\n\nVer código\n# Cambios los dos campos de fecha a la vez\ndatos %&gt;% \n  mutate(across(starts_with(\"fecha\"),\n                ~as.Date(.x,\n                         tz = \"UTC\",\n                         origin = \"1899-12-30\")))\n\n\n  fecha_sourcing   nombre empresa fecha_ultimo_contacto\n1     2022-06-17   Sergio    R4HR            2022-06-27\n2     2022-06-17  Daniela    R4HR            2022-06-27\n3     2022-06-17    Yanel    R4HR            2022-06-27\n4     2022-06-17    Carla    R4HR            2022-06-27\n5     2022-06-17 Santiago    R4HR            2022-06-27\n\n\nEn este caso usamos la función across() para indicarle a R que ejecute la función (en este ejemplo, as.Date()) en todas las variables que cumplan con algún criterio. En este ejemplo, nos valemos de otra función auxiliar, starts_with(), que como su nombre en inglés lo indica, va a ejecutar la función en todas las columnas que empiecen con el término \"fecha\".\nEste ejemplo funciona porque los campos que contienen una fecha comienzan con el nombre fecha. Por eso es importante al momento de diseñar una base de datos, un formulario, o cualquier registro que utilicemos para que haya una consistencia entre los nombres de los campos para facilitarnos posteriormente el proceso y análisis de datos, independiemente del software que utilicemos.\nPresten atención a que delante de la función as.Date() usamos este símbolo (~ ) llamado virgulilla (en Neuquén, Argentina, le dríamos ñuflo). Con ese símbolo le indicamos a R que esa va a ser la función que vamos a replicar en todos los campos.\nEl argumento .x, representa a todas las columnas que habíamos seleccionado con las funciones across() y starts_with(). Es decir que es la forma que tiene R de simplificar cuáles son los campos que tiene que transformar sin que le tengamos que indicar uno por uno cuales son."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html",
    "href": "es/haciendo-boludeces-en-r/index.html",
    "title": "Haciendo pavadas en R",
    "section": "",
    "text": "Una vez vi una charla de Ryan Timpe, un Data Scientist de Lego, que en una charla en la RStudio Conference contaba cómo a veces hacía proyectos que fueran divertidos para aprender nuevos skills de análisis de datos. En su charla cuenta por ejemplo, que hizo un análisis de los diálogos de la serie The Golden Girls usando técnicas de text mining para detectar cuáles eran las palabras más frecuentes, entonces cada vez que una protagonista decía esa palabra ellos hacían un fondo blanco de lo que estuvieran tomando.\nEste post va de lo mismo. Yo quería aprender a usar imágenes en mis visualizaciones, así nació este proyecto en el que usé imágenes de personas con rasgos “similares” a los míos e incluir las fotos en un gráfico de dispersión.\nEsto que es una boludez implicó:\n\nCrear un formulario en Google Forms\nLevantar los datos de las respuestas\nProcesar los resultados\nE incluir visualizaciones usando las imágenes de las personas.\n\nEste tipo de proyectos lo que permite es que el esfuerzo que dedicás a aprender no se sienta pesado, y que te da una motivación extra para buscar la solución para lograr el resultado."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#génesis-de-la-idea-k-nn",
    "href": "es/haciendo-boludeces-en-r/index.html#génesis-de-la-idea-k-nn",
    "title": "Haciendo pavadas en R",
    "section": "Génesis de la idea: k-nn",
    "text": "Génesis de la idea: k-nn\nLa idea de este análisis surgió un día después de hacer una explicación sobre un método de clustering llamado k-nn. Los métodos de clustering son técnicas de ciencia de datos que permiten hallar grupos entre los datos (llamados clusters en la jerga).\nEl método k-nn, k nearest neighbors o de vecinos más cercanos lo que hace es asignar a cada individuo a un cluster en función de las características de sus “vecinos”. Es decir que determina a qué grupo pertenece cada caso en función a qué casos se parece más.\nLa forma que se me ocurrió para explicar esto de manera visual fue con este dibujo que hice en Paint:\n\nLa explicación es que yo, dentro de ese conjunto de datos, estoy más cerca de pertenecer al cluster del Mono Burgos y de Nicolás del Caño, más que del cluster de Keanu Reeves, Jeff Bridges y Brad Pitt.\nY después tuve una idea. ¿Y si hago esto con datos?"
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#cargando-los-datos-y-preparándolos",
    "href": "es/haciendo-boludeces-en-r/index.html#cargando-los-datos-y-preparándolos",
    "title": "Haciendo pavadas en R",
    "section": "Cargando los datos y preparándolos",
    "text": "Cargando los datos y preparándolos\nEmpecemos cargando las librerías y los datos directamente desde un repositorio:\n\n\nVer código\n# Paquetes\nlibrary(tidyverse) # Cargar, limpiar y preparar datos\nlibrary(ggimage)   # Para usar imágenes en las visualizaciones\n\n# Datos\nclones &lt;- read_delim(\"https://raw.githubusercontent.com/chechoid/silliest-use-of-r/main/source.csv\", delim = \";\")\n\n\ncomentarios &lt;- clones %&gt;% \n  select(comentarios = `Poné lo que quieras... parecidos, chistes, comentarios, etc...`) %&gt;% \n  filter(!is.na(comentarios))\n\n# Exploremos los datos\nhead(clones)\n\n\n# A tibble: 6 × 24\n  `Marca temporal`    `Facha de Keanu` `Copadez de Keanu` `Facha de Russell`\n  &lt;dttm&gt;                         &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 2021-06-23 12:37:28               10                 10                  7\n2 2021-06-23 12:39:12                4                 10                  5\n3 2021-06-23 12:42:21                8                  9                  8\n4 2021-06-23 12:43:24               10                 10                  1\n5 2021-06-23 12:45:03               10                  8                  4\n6 2021-06-23 12:45:12                5                  9                  1\n# ℹ 20 more variables: `Copadez de Russell` &lt;dbl&gt;, `Facha de Nico` &lt;dbl&gt;,\n#   `Copadez de Nico` &lt;dbl&gt;, `Facha de Roberto` &lt;dbl&gt;,\n#   `Copadez de Roberto` &lt;dbl&gt;, `Facha de Jeff` &lt;dbl&gt;, `Copadez de Jeff` &lt;dbl&gt;,\n#   `Facha de Brad` &lt;dbl&gt;, `Copadez de Brad` &lt;dbl&gt;, `Facha del Mono` &lt;dbl&gt;,\n#   `Copadez del Mono` &lt;dbl&gt;, `Facha de Sergio` &lt;dbl&gt;,\n#   `Copadez de Sergio` &lt;dbl&gt;, `Facha de Ricky` &lt;dbl&gt;,\n#   `Copadez de Ricky` &lt;dbl&gt;, `Facha de Ben` &lt;dbl&gt;, `Copadez de Ben` &lt;dbl&gt;, …\n\n\nAhí podemos ver que para cada personaje tenemos una columna con el puntaje de su facha y su puntaje de copadez.\nEl siguiente paso consiste en eliminar algunas columnas que no son relevantes para el análisis, y agregamos una columna de id. Y luego tenemos que “pivotear” la tabla para que nos queden todas las columnas de puntajes de los personajes en dos columnas:\n\n\nVer código\n# Eliminar columnas innecesarias\nclones &lt;- clones %&gt;% \n  select(-`Marca temporal`, -`Poné lo que quieras... parecidos, chistes, comentarios, etc...`)\n\n# Agregar columna de id\nclones &lt;- clones %&gt;% \n  rowid_to_column(var = \"id\")\n\n# Pivotear variables\nclones &lt;- clones %&gt;% \n  pivot_longer(cols = c(\"Facha de Keanu\": \"Copadez de Javier\"),\n               names_to = \"personaje\",\n               values_to = \"puntaje\")\n\n# Veamos como queda el dataset ahora\nhead(clones)\n\n\n# A tibble: 6 × 3\n     id personaje          puntaje\n  &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;\n1     1 Facha de Keanu          10\n2     1 Copadez de Keanu        10\n3     1 Facha de Russell         7\n4     1 Copadez de Russell      10\n5     1 Facha de Nico            1\n6     1 Copadez de Nico          1\n\n\nHabíamos comenzado con un dataset de 66 filas y 24 columnas. Ahora terminamos con un data frame de 1.452 filas en 3 columnas. Ahora necesitamos eliminar las palabras intermedias de y del de los nombres en la columna personaje así después podemos crear una columna para facha, y otra para copadez.\n\n\nVer código\n# Separar variables categóricas\nclones &lt;- clones %&gt;% \n  mutate(personaje = str_remove(personaje, \"de \"),\n         personaje = str_remove(personaje, \"del \"))\n\n# Veamos el puntaje promedio de cada personaje y sus caraceterísticas\nclones %&gt;% \n  group_by(personaje) %&gt;% \n  summarise(valor_promedio = mean(puntaje)) %&gt;% \n  ggplot(aes(x = valor_promedio, y = personaje)) +\n  geom_point(size = 2)\n\n\n\n\n\n\n\n\n\nVer código\n# Dividimos la columna 'personaje' en dos columnas, una para la métrica y otra para el nombre\nclones &lt;- clones %&gt;% \n  separate(personaje,  into = c(\"metrica\", \"persona\"))\n\n\n# Pivotear ancho \nclones &lt;- clones %&gt;% \n  pivot_wider(id_cols = c(id, persona),\n              names_from = metrica,\n              values_from = puntaje)\n\n# Veamos como queda el data frame ahora\nhead(clones)\n\n\n# A tibble: 6 × 4\n     id persona Facha Copadez\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Keanu      10      10\n2     1 Russell     7      10\n3     1 Nico        1       1\n4     1 Roberto     1       1\n5     1 Jeff        5       5\n6     1 Brad       10      10\n\n\nLuego de estos pasos quedamos con un data frame de 726 filas, una para cada votación para cada personaje, y con 4 columnas, id, persona, Facha y Copadez. Con estos datos podemos ver los resultados de cada persona:\n\n\nVer código\n# Calculamos los resultados promedios para cada persona y graficamos los resultados\nresultados &lt;- clones %&gt;% \n  group_by(persona) %&gt;% \n  summarise(facha_promedio = mean(Facha),\n            copadez_promedio = mean(Copadez))\n\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio, color = persona)) +\n  geom_point(size = 3)\n\n\n\n\n\n\n\n\n\nEn esencia, este es el gráfico al que queremos llegar. Así como está es medio aburrido, así que vamos a enchular este gráfico con imágenes."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#trabajando-con-las-imágenes",
    "href": "es/haciendo-boludeces-en-r/index.html#trabajando-con-las-imágenes",
    "title": "Haciendo pavadas en R",
    "section": "Trabajando con las imágenes",
    "text": "Trabajando con las imágenes\nComo contaba antes, primero armé una presentación en Canva y pegué todas las imágenes de cada personaje para que queden más o menos del mismo tamaño. Luego guardé cada imagen en un archivo separado, y en este caso las guardé en una carpeta que se llama clones.\nPodría haber hecho la carga de las fotos una por una, pero quería hacer este trabajo lo más eficiente posible tratando de repetir pasos. Para eso tenemos que crear un data frame que tenga por un lado el nombre de la persona tal cual lo tenemos en la tabla de las votaciones, y que incluya la dirección a la imagen.\n\n\nVer código\n# Creamos un vector con los nombres de las personas\npersona &lt;- resultados %&gt;% \n  select(persona) %&gt;% \n  pull()\n\n# Creo un vector de imágenes\nruta &lt;- \"pics\"        # Ruta de las fotos\nextension &lt;- \"png\"   # Extensión de los archivos de imágenes\n\n# nombres de los archivos\nimagen &lt;- c(\"Ben\", \"Brad\", \"Javier\", \"jeff\", \"keanu\", \"mono\", \"nico\", \n            \"ricky\", \"roberto\", \"russell\", \"sergio\")\n\n# Creo el vector de fotos con dirección y extensión completa\nfoto &lt;- str_c(ruta, imagen, sep = \"/\")\nfoto &lt;- str_c(foto, extension, sep = \".\")\n\n# Creo el dataframe y lo agrego al dataframe resultados\npics &lt;- data.frame(persona, foto)\n\n# Ver el resultado de este proceso\npics\n\n\n   persona             foto\n1      Ben     pics/Ben.png\n2     Brad    pics/Brad.png\n3   Javier  pics/Javier.png\n4     Jeff    pics/jeff.png\n5    Keanu   pics/keanu.png\n6     Mono    pics/mono.png\n7     Nico    pics/nico.png\n8    Ricky   pics/ricky.png\n9  Roberto pics/roberto.png\n10 Russell pics/russell.png\n11  Sergio  pics/sergio.png\n\n\nAhora tenemos un data frame de 11 filas y dos columnas, con el nombre de cada persona, y la dirección al archivo que contiene las imágenes de cada una. Estos datos lo podemos integrar al data frame que veníamos trabajando con los resultados de Facha y Copadez promedio de cada personaje.\n\n\nVer código\n# Unimos los datasets\nresultados &lt;- left_join(resultados, pics)\n\nhead(resultados)\n\n\n# A tibble: 6 × 4\n  persona facha_promedio copadez_promedio foto           \n  &lt;chr&gt;            &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;          \n1 Ben               8.23             6.47 pics/Ben.png   \n2 Brad              8.52             7.55 pics/Brad.png  \n3 Javier            6.89             6.56 pics/Javier.png\n4 Jeff              5.06             6.45 pics/jeff.png  \n5 Keanu             7.77             8.74 pics/keanu.png \n6 Mono              3.30             6.30 pics/mono.png"
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#poniendo-imágenes-al-gráfico",
    "href": "es/haciendo-boludeces-en-r/index.html#poniendo-imágenes-al-gráfico",
    "title": "Haciendo pavadas en R",
    "section": "Poniendo imágenes al gráfico",
    "text": "Poniendo imágenes al gráfico\nY ahora si, a lo que venimos: incluir las fotos en el gráfico\n\n\nVer código\n# El gráfico final\nggplot(resultados, aes(x = copadez_promedio, y = facha_promedio)) +\n  geom_image(aes(image=foto), size = 0.08) +\n  theme_minimal() +\n  scale_x_continuous(limits = c(1,10)) +\n  scale_y_continuous(limits = c(1,10)) +\n  labs(title = \"Facha y Copadez Promedio de cada Personaje\",\n       x = \"Copadez Promedio\", \n       y = \"Facha Promedio\",\n       caption = \"n = 66\\nNinguna tía participó del relevamiento\")\n\n\n\n\n\n\n\n\n\nComo conclusión del análisis los datos dicen que estoy alejado de las características de Nicolás del Caño y Roberto Baradel por ejemplo y tengo características muy similares que Keanu Reeves. O sea que los datos indican que me parezco a Keanu. Dato, no opinión 😎."
  },
  {
    "objectID": "es/haciendo-boludeces-en-r/index.html#qué-saqué-de-todo-esto",
    "href": "es/haciendo-boludeces-en-r/index.html#qué-saqué-de-todo-esto",
    "title": "Haciendo pavadas en R",
    "section": "¿Qué saqué de todo esto?",
    "text": "¿Qué saqué de todo esto?\nEn primer lugar aprender a usar un paquete nuevo, ggimage que permite incluir imágenes en los gráficos. Por otro lado hubo un error en el diseño del formulario (poner “Facha del Mono”) lo que implicó un paso extra en la limpieza de los datos. Ese error en este proyecto me ayudó a prevenir un potencial problema con una encuesta de diversidad para un cliente.\nOtro tema fue la manipulación de los datos, pivotearlos de un formato “ancho” a uno “largo” y después nuevamente a uno “ancho” otra vez. Una vez que logré eso el cálculo de los resultados salió de manera muy simple.\nTodo esto llevó dos días de trabajo, mirar tutoriales y documentación y mucha prueba y error. La verdad es que fue mucho trabajo, pero el hecho de ser un proyecto medio delirante le sacó mucha presión y me dió la motivación para aprender algo nuevo y superar las barreras y errores que me fui encontrando. Creo que el hecho que sea un proyecto divertido me liberó para tratar interpretar los mensajes de error y buscar la solución apropiada.\nEste tipo de proyecto me parece ideal para realizar apenas terminás un tutorial o un curso. Los datos que usamos en un tutorial siempre están bastante limpios, controlados, divinos y cuando trabajás con tus propios datos te encontrás con barreras. Realizar este tipo de análisis sin la presión de “agregar valor” al negocio y pone a prueba las habilidades que tenés.\nAsí que te invito a que hagas un proyecto ridículo y que lo compartas con el mundo.\n\nFinal\nSi querés ver el script final de este post, lo podés encontrar en el repositorio en este link.\nY como regalo final, me reí mucho con los comentarios que hicieron las personas que participaron del relevamiento de datos así que los comparto con ustedes:\n\n\n\n\n\n\n\n\nComentarios\n\n\n\n\nte rompí los patrones a la merd\n\n\njaja me rei mucho!\n\n\nCaruso a la Final!\n\n\nJohnny Depp, 8/8\n\n\nHajajja\n\n\nDe Brad Pitt te copiaste el peinado, no?\n\n\n¿es requisito tener pelo largo para parecer fachero? mostrame indicadores\n\n\nSergio vos no estas bien haciendo esto!!! Jajaja\n\n\nFalta Denicolay\n\n\nJajaj muy bueno\n\n\nHaces todo esto para levantarte minas Mora, lo sabemos!!!\n\n\nME ENCANTÓ! curiosa, dinámica y original iniciativa como siempre!!\n\n\nCopado el test!!\n\n\n¿todos hombres?\n\n\nHajajja\n\n\nWTH??\n\n\nSos un capo!!! me divertí mucho!!!\n\n\nFalta el test de mujeres.....\n\n\nBronn, de game of thrones.\n\n\nMuy buen ejercicio! A algunos personajes el 1 le quedaba grande! habiliten el 0 jaja Éxitos!\n\n\nUn genio Sergio 😂😂😂 Podría ser también a la versión adulta del niño del sexto sentido, el que dice\"veo gente muerta\" ¿? 🤔\n\n\nPuedo decir que la foto que te sacaste, es muy de MA de instagram\n\n\nJaja me hiciste reír. Cómo no soy de Argentina tuve que googlear algunos, pero todo bien. Super entretenido\n\n\n\n\n\n\n\nMuchas gracias por leer!"
  },
  {
    "objectID": "es/maximo-valor-fila/index.html",
    "href": "es/maximo-valor-fila/index.html",
    "title": "Extraer el máximo valor de una fila",
    "section": "",
    "text": "En este pequeño tutorial (por eso el tag de tipito, o sea un tip chiquito), voy a contar cómo resolví un problema que me encontré en el trabajo y me trajo más de un dolor de cabeza.\nEstaba trabajando con una tabla en la que tenía varios cursos, con sus fechas de finalización, y para el análisis que estaba haciendo necesitaba extraer la fecha del último curso completado por cada persona (el valor más alto).\nEl problema es que cuando estaba ejecutando la función max() en vez de obtener el valor más alto de la fila, obtenía el valor más alto de la columna. Así que en este post vamos a ver la función rowwise() que permite resolver este inconveniente.\nEn este ejemplo vamos a reemplazar las fechas por un número, que a los fines prácticos plantea el mismo problema.\n\n\nPrimero carguemos la librería dplyr que además de contener la función rowwise() nos permite trabajar con el pipe %&gt;% para simplificar la lectura del código. Luego crearemos un data frame de ejemplo con datos inventados\n\n\nVer código\n# En caso que no esté instalado 'dplyr' primero ejecutar install.package(\"dplyr\")\nlibrary(dplyr)\n\n# Creación de datos\nejemplo &lt;- data.frame(\"Nombre\" = c(\"Carla\", \"Daniela\", \"Sergio\", \"Yanel\"),\n                    \"Valor A\" = c(12, 8, 300, 17),\n                    \"Valor B\" = c(5, 21, 18, 400),\n                    \"Valor C\" = c(39, 200, 26, 64), \n                    \"Valor D\" = c(100, 43, 86, 12))\n\n\nAhora veamos cómo quedan los datos\n\n\nVer código\n# Ejecutar para ver el contenido del data frame\nejemplo\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D\n1   Carla      12       5      39     100\n2 Daniela       8      21     200      43\n3  Sergio     300      18      26      86\n4   Yanel      17     400      64      12\n\n\nLo que necesitaba lograr (en un archivo con muchas más columnas que en este ejemplo) es poner en una columna nueva el valor más alto para cada persona. Entonces para Carla esperaba que el resultado fuera 100, para Daniela 200 y así sucesivamente.\nInstintivamente lo que hice para intentar obtener el valor más alto de cada caso, fue usar dentro de una función mutate() (para crear una columna nueva) la función max() a un vector con los nombres de las 4 columnas.\n\n\nVer código\nejemplo %&gt;% \n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D Valor Máximo\n1   Carla      12       5      39     100          400\n2 Daniela       8      21     200      43          400\n3  Sergio     300      18      26      86          400\n4   Yanel      17     400      64      12          400\n\n\nClaramente no es es el resultado que esperaba, así que mi reacción fue la siguiente:\n\n\n\n\nEl problema del enfoque anterior es que la función max() busca entre todos los datos que le pasamos, las 4 columnas con los valores numéricos, y lo que nos devuelve el valor máximo de entre todas las celdas. Este es un claro ejemplo de que R está haciendo lo que le dijimos que haga, no lo que estábamos queriendo que haga.\nPara resolver esto, antes de crear una columna nueva con mutate(), usamos la función rowwise().\n\n\nVer código\nejemplo %&gt;% \n  rowwise() %&gt;%   # Con esta función indicamos que queremos los cálculos sobre las filas\n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n# A tibble: 4 × 6\n# Rowwise: \n  Nombre  Valor.A Valor.B Valor.C Valor.D `Valor Máximo`\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1 Carla        12       5      39     100            100\n2 Daniela       8      21     200      43            200\n3 Sergio      300      18      26      86            300\n4 Yanel        17     400      64      12            400\n\n\nLa función rowwise() lo que nos permite hacer es cálculos sobre las filas. Dependiendo el caso de uso se puede usar esta alternativa, o “pivotear” o transponer la tabla para que las columnas queden dentro de las filas y luego combinar group_by() y summarise() para calcular el valor máximo para cada persona.\nEste enfoque sería así:\n\n\nVer código\nlibrary(tidyr)\n\nejemplo_largo &lt;- ejemplo %&gt;% \n  # Pivoteamos los datos a un formato 'largo'\n  pivot_longer(cols = c(\"Valor.A\", \"Valor.B\", \"Valor.C\", \"Valor.D\"), \n               names_to = \"Variable\",\n               values_to = \"Valor\")\n\n# Veamos el dataset transformado\nejemplo_largo\n\n\n# A tibble: 16 × 3\n   Nombre  Variable Valor\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n 1 Carla   Valor.A     12\n 2 Carla   Valor.B      5\n 3 Carla   Valor.C     39\n 4 Carla   Valor.D    100\n 5 Daniela Valor.A      8\n 6 Daniela Valor.B     21\n 7 Daniela Valor.C    200\n 8 Daniela Valor.D     43\n 9 Sergio  Valor.A    300\n10 Sergio  Valor.B     18\n11 Sergio  Valor.C     26\n12 Sergio  Valor.D     86\n13 Yanel   Valor.A     17\n14 Yanel   Valor.B    400\n15 Yanel   Valor.C     64\n16 Yanel   Valor.D     12\n\n\nVer código\n# Ahora hacemos el cálculo combinando 'group_by' y 'summarise'\nejemplo_largo %&gt;% \n  group_by(Nombre) %&gt;% \n  summarise(\"Valor Máximo\" = max(Valor))\n\n\n# A tibble: 4 × 2\n  Nombre  `Valor Máximo`\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Carla              100\n2 Daniela            200\n3 Sergio             300\n4 Yanel              400\n\n\nClaramente este es otro enfoque, y depende de la necesidad es una opción válida. Pero en este caso particular necesitaba mantener una fila para cada persona porque después iba a exportar esta tabla a un archivo que luego es cargado en un tablero en Power BI.\nAsí que, una vez logrado mi objetivo, me dispuse a celebrar como corresponde."
  },
  {
    "objectID": "es/maximo-valor-fila/index.html#datos-de-ejemplo",
    "href": "es/maximo-valor-fila/index.html#datos-de-ejemplo",
    "title": "Extraer el máximo valor de una fila",
    "section": "",
    "text": "Primero carguemos la librería dplyr que además de contener la función rowwise() nos permite trabajar con el pipe %&gt;% para simplificar la lectura del código. Luego crearemos un data frame de ejemplo con datos inventados\n\n\nVer código\n# En caso que no esté instalado 'dplyr' primero ejecutar install.package(\"dplyr\")\nlibrary(dplyr)\n\n# Creación de datos\nejemplo &lt;- data.frame(\"Nombre\" = c(\"Carla\", \"Daniela\", \"Sergio\", \"Yanel\"),\n                    \"Valor A\" = c(12, 8, 300, 17),\n                    \"Valor B\" = c(5, 21, 18, 400),\n                    \"Valor C\" = c(39, 200, 26, 64), \n                    \"Valor D\" = c(100, 43, 86, 12))\n\n\nAhora veamos cómo quedan los datos\n\n\nVer código\n# Ejecutar para ver el contenido del data frame\nejemplo\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D\n1   Carla      12       5      39     100\n2 Daniela       8      21     200      43\n3  Sergio     300      18      26      86\n4   Yanel      17     400      64      12\n\n\nLo que necesitaba lograr (en un archivo con muchas más columnas que en este ejemplo) es poner en una columna nueva el valor más alto para cada persona. Entonces para Carla esperaba que el resultado fuera 100, para Daniela 200 y así sucesivamente.\nInstintivamente lo que hice para intentar obtener el valor más alto de cada caso, fue usar dentro de una función mutate() (para crear una columna nueva) la función max() a un vector con los nombres de las 4 columnas.\n\n\nVer código\nejemplo %&gt;% \n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n   Nombre Valor.A Valor.B Valor.C Valor.D Valor Máximo\n1   Carla      12       5      39     100          400\n2 Daniela       8      21     200      43          400\n3  Sergio     300      18      26      86          400\n4   Yanel      17     400      64      12          400\n\n\nClaramente no es es el resultado que esperaba, así que mi reacción fue la siguiente:"
  },
  {
    "objectID": "es/maximo-valor-fila/index.html#la-solución",
    "href": "es/maximo-valor-fila/index.html#la-solución",
    "title": "Extraer el máximo valor de una fila",
    "section": "",
    "text": "El problema del enfoque anterior es que la función max() busca entre todos los datos que le pasamos, las 4 columnas con los valores numéricos, y lo que nos devuelve el valor máximo de entre todas las celdas. Este es un claro ejemplo de que R está haciendo lo que le dijimos que haga, no lo que estábamos queriendo que haga.\nPara resolver esto, antes de crear una columna nueva con mutate(), usamos la función rowwise().\n\n\nVer código\nejemplo %&gt;% \n  rowwise() %&gt;%   # Con esta función indicamos que queremos los cálculos sobre las filas\n  mutate(\"Valor Máximo\" = max(c(Valor.A, Valor.B, Valor.C, Valor.D)))\n\n\n# A tibble: 4 × 6\n# Rowwise: \n  Nombre  Valor.A Valor.B Valor.C Valor.D `Valor Máximo`\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1 Carla        12       5      39     100            100\n2 Daniela       8      21     200      43            200\n3 Sergio      300      18      26      86            300\n4 Yanel        17     400      64      12            400\n\n\nLa función rowwise() lo que nos permite hacer es cálculos sobre las filas. Dependiendo el caso de uso se puede usar esta alternativa, o “pivotear” o transponer la tabla para que las columnas queden dentro de las filas y luego combinar group_by() y summarise() para calcular el valor máximo para cada persona.\nEste enfoque sería así:\n\n\nVer código\nlibrary(tidyr)\n\nejemplo_largo &lt;- ejemplo %&gt;% \n  # Pivoteamos los datos a un formato 'largo'\n  pivot_longer(cols = c(\"Valor.A\", \"Valor.B\", \"Valor.C\", \"Valor.D\"), \n               names_to = \"Variable\",\n               values_to = \"Valor\")\n\n# Veamos el dataset transformado\nejemplo_largo\n\n\n# A tibble: 16 × 3\n   Nombre  Variable Valor\n   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n 1 Carla   Valor.A     12\n 2 Carla   Valor.B      5\n 3 Carla   Valor.C     39\n 4 Carla   Valor.D    100\n 5 Daniela Valor.A      8\n 6 Daniela Valor.B     21\n 7 Daniela Valor.C    200\n 8 Daniela Valor.D     43\n 9 Sergio  Valor.A    300\n10 Sergio  Valor.B     18\n11 Sergio  Valor.C     26\n12 Sergio  Valor.D     86\n13 Yanel   Valor.A     17\n14 Yanel   Valor.B    400\n15 Yanel   Valor.C     64\n16 Yanel   Valor.D     12\n\n\nVer código\n# Ahora hacemos el cálculo combinando 'group_by' y 'summarise'\nejemplo_largo %&gt;% \n  group_by(Nombre) %&gt;% \n  summarise(\"Valor Máximo\" = max(Valor))\n\n\n# A tibble: 4 × 2\n  Nombre  `Valor Máximo`\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Carla              100\n2 Daniela            200\n3 Sergio             300\n4 Yanel              400\n\n\nClaramente este es otro enfoque, y depende de la necesidad es una opción válida. Pero en este caso particular necesitaba mantener una fila para cada persona porque después iba a exportar esta tabla a un archivo que luego es cargado en un tablero en Power BI.\nAsí que, una vez logrado mi objetivo, me dispuse a celebrar como corresponde."
  },
  {
    "objectID": "es/scrap_learning/index.html",
    "href": "es/scrap_learning/index.html",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "En Recursos Humanos una de las obsesiones principales es medir el Retorno de la Inversión (ROI) de la capacitación, lo cual, si bien es posible de medir, requiere un esfuerzo enorme. En cambio, poder medir cuánta plata se desperdicia por la no aplicación del conocimiento adquirido en las capacitaciones es mucho más sencillo, y también es una métrica muy valiosa para utilizar.\nEl Scrap Learning es una forma de medir cuántos de los conocimientos adquiridos en las capacitaciones no se trasladan al trabajo, lo cual es mucho más sencillo y tan valioso de medir como el ROI.\nLa investigación indica el promedio de mercado de Scrap Learning entre las empresas que no lo miden es del 45%. Es decir que si tenemos un presupuesto anual de $ 500.000 para las capacitaciones, $ 225.000 es dinero mal invertido y por ende, la capacitación deja de ser una inversión para convertirse en un costo.\n\n\n\nUna forma sencilla de medir el Scrap Learning es preguntando a los participantes de un curso cuánto del conocimiento adquirido se aplicará al trabajo. El porcentaje de contenido que NO aplicarán al trabajo forma parte del Scrap Learning.\nEjemplo: Le preguntamos a un participante cuántos de los conocimientos adquiridos en una capacitación estima aplicar en sus tareas cotidianas. Si dice que piensa aplicar el 60% del contenido a su trabajo, el scrap learning es del 40%.\n\n\n\n\n\n\n\n\nUna de las primeras cosas que debemos hacer los Responsables de Capacitación y Desarrollo es aclarar para qué sirve una capacitación. ¿Cuántas veces hemos escuchado “Fulano está desmotivado… mándalo a hacer un curso”? ¿O cuántas veces acordamos con un empleado conflictivo o de bajo desempeño pagarle un posgrado? ¿Hemos enviado alguna vez a una persona a una capacitación sobre una tecnología que no usamos en nuestras empresas?\nIncluso de parte de los colaboradores hay una percepción imprecisa sobre la capacitación. Una encuesta que hicimos a empleados de nuestros clientes, frente a la pregunta “¿Qué beneficio que no tenés hoy, te gustaría tener?”, prácticamente 1 de cada 4 respuestas estaba relacionada con capacitación o beneficios en posgrados.\nEsto deja entrever, que lo primero que necesitamos hacer desde Capacitación y Desarrollo es “re-educar” a la empresa sobre cuál es la utilidad y finalidad de las capacitaciones y en qué casos usarlas.\n\n\n\n“Una capacitación efectiva mejorará el desempeño del participante y del área donde trabaja.”\nPor el contrario, cuando las capacitaciones no son efectivas y el scrap learning es alto, la performance del colaborador y del sector no mejorarán aún cuando asistan al mejor curso del mundo. Una actividad de formación debe aportar valor al participante y a su área. Para ello, hay 3 preguntas claves para hacer:\n\n¿Cuánto espera que su performance mejore relacionado con el contexto del curso relacionado con todos los factores, incluido el programa de desarrollo?\n¿Cuánto de esa mejora se la atribuiría exclusivamente a la capacitación?\n¿Cuánto tiempo dedica realmente a tareas relacionadas con el programa de desarrollo?\n\n\n\n\nEn nuestra experiencia, existen varias causas que provocan el scrap learning. La tabla a continuación resume algunos de los principales factores que inciden en esta métrica.\nEn la primera columna hay causas que están bajo el control del área de Capacitación y Desarrollo, como ser la calidad del instructor, del material, la alineación con las necesidades del negocio, entre otras. Pero sin dudas uno de los factores más importantes e influyentes es la involucración de los Jefes y Gerencias en el proceso de Capacitación.\n\n\n\n\n\nComo en muchas cosas de Recursos Humanos, la clave son los líderes. ¿De qué manera pueden influir en la reducción del scrap learning? Básicamente hay 5 factores preponderantes:\n\nElegir a la persona idónea para asistir a un curso y que sea el indicado para adquirir y aplicar nuevos conocimientos a sus tareas.\nDefinir las expectativas con el participante antes del inicio de la capacitación.\nInvolucrarse con la aplicación de los conocimientos nuevos una vez terminada la actividad de formación.\nRealizar un seguimiento de las expectativas fijadas antes de la capacitación.\nProveer recursos necesarios para dar soporte al rendimiento.\n\nOtro dato clave es que, si el conocimiento adquirido durante una capacitación no se aplica dentro de las 6 semanas posteriores a la capacitación, ningún conocimiento adquirido en esa actividad se trasladará al trabajo.\n\n\n\n\nMedir la información de todos los cursos planificados de la misma manera, usando las mismas herramientas y preguntas. Esto nos brindará consistencia para comparar los resultados y realizar estimaciones más sofisticadas.\nCrear una hoja de cálculo en Excel, o un tablero con métricas con algunas métricas clave: scrap learning, desempeño, e inversión por ejemplo para cada curso.\nCrear una serie de reglas que brinden un marco para el proceso de mejora continuo, por ejemplo:\n\nPara el top 5 de los cursos, no realizar cambios, reinvertir en ellos, continuar desarrollándolos, y si ocurrieran cambios que sean en pos de conseguir una reducción de costos siempre y cuando la calidad no se vea afectada, y de esa manera mejorar el ROI.\nPara el 10% más bajo de los cursos, eliminar cualquier curso que no esté alineado con los objetivos de la empresa. Para aquellos que están alineados con las necesidades de negocio, reinvertir para revisarlos.\nPara el 85% de los cursos que están en el medio, continuar realizándolos, pero buscando opciones que permitan reducir el scrap y maximizar los beneficios.\n\n\n\n\n\nEl Retorno de Inversión (ROI) de una capacitación es una medida compleja de estimar, en cambio, el Scrap Learning es más sencillo de medir y de solucionar.\nMantener un bajo nivel de Scrap Learning, no sólo se materializa en resultados en la organización, sino que además aumenta la confianza sobre el proceso de capacitación generando un “círculo virtuoso” que contribuye a mantenerlo en ese estado.\nÉsta es una métrica poderosa para evaluar la efectividad de las capacitaciones que realizamos dentro de una organización. Como Responsables de Capacitación y Desarrollo, es nuestro deber asegurar la calidad de la capacitación (del instructor, del contenido, y la alineación con necesidades de negocio), pero los jefes juegan un rol clave a la hora de trasladar los conocimientos de la formación al trabajo cotidiano. De esto surge la necesidad de trabajar codo a codo con las áreas para involucrar a sus jefaturas y gerencias, dándoles el soporte necesario para mejorar el impacto de las capacitaciones, mejorar el rendimiento de sus equipos e incrementar sus propios resultados e imagen."
  },
  {
    "objectID": "es/scrap_learning/index.html#para-muestra-basta-con-un-botón",
    "href": "es/scrap_learning/index.html#para-muestra-basta-con-un-botón",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "Una forma sencilla de medir el Scrap Learning es preguntando a los participantes de un curso cuánto del conocimiento adquirido se aplicará al trabajo. El porcentaje de contenido que NO aplicarán al trabajo forma parte del Scrap Learning.\nEjemplo: Le preguntamos a un participante cuántos de los conocimientos adquiridos en una capacitación estima aplicar en sus tareas cotidianas. Si dice que piensa aplicar el 60% del contenido a su trabajo, el scrap learning es del 40%."
  },
  {
    "objectID": "es/scrap_learning/index.html#capacitar-sobre-capacitar",
    "href": "es/scrap_learning/index.html#capacitar-sobre-capacitar",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "Una de las primeras cosas que debemos hacer los Responsables de Capacitación y Desarrollo es aclarar para qué sirve una capacitación. ¿Cuántas veces hemos escuchado “Fulano está desmotivado… mándalo a hacer un curso”? ¿O cuántas veces acordamos con un empleado conflictivo o de bajo desempeño pagarle un posgrado? ¿Hemos enviado alguna vez a una persona a una capacitación sobre una tecnología que no usamos en nuestras empresas?\nIncluso de parte de los colaboradores hay una percepción imprecisa sobre la capacitación. Una encuesta que hicimos a empleados de nuestros clientes, frente a la pregunta “¿Qué beneficio que no tenés hoy, te gustaría tener?”, prácticamente 1 de cada 4 respuestas estaba relacionada con capacitación o beneficios en posgrados.\nEsto deja entrever, que lo primero que necesitamos hacer desde Capacitación y Desarrollo es “re-educar” a la empresa sobre cuál es la utilidad y finalidad de las capacitaciones y en qué casos usarlas."
  },
  {
    "objectID": "es/scrap_learning/index.html#las-preguntas-clave",
    "href": "es/scrap_learning/index.html#las-preguntas-clave",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "“Una capacitación efectiva mejorará el desempeño del participante y del área donde trabaja.”\nPor el contrario, cuando las capacitaciones no son efectivas y el scrap learning es alto, la performance del colaborador y del sector no mejorarán aún cuando asistan al mejor curso del mundo. Una actividad de formación debe aportar valor al participante y a su área. Para ello, hay 3 preguntas claves para hacer:\n\n¿Cuánto espera que su performance mejore relacionado con el contexto del curso relacionado con todos los factores, incluido el programa de desarrollo?\n¿Cuánto de esa mejora se la atribuiría exclusivamente a la capacitación?\n¿Cuánto tiempo dedica realmente a tareas relacionadas con el programa de desarrollo?"
  },
  {
    "objectID": "es/scrap_learning/index.html#factores-a-tener-en-cuenta",
    "href": "es/scrap_learning/index.html#factores-a-tener-en-cuenta",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "En nuestra experiencia, existen varias causas que provocan el scrap learning. La tabla a continuación resume algunos de los principales factores que inciden en esta métrica.\nEn la primera columna hay causas que están bajo el control del área de Capacitación y Desarrollo, como ser la calidad del instructor, del material, la alineación con las necesidades del negocio, entre otras. Pero sin dudas uno de los factores más importantes e influyentes es la involucración de los Jefes y Gerencias en el proceso de Capacitación.\n\n\n\n\n\nComo en muchas cosas de Recursos Humanos, la clave son los líderes. ¿De qué manera pueden influir en la reducción del scrap learning? Básicamente hay 5 factores preponderantes:\n\nElegir a la persona idónea para asistir a un curso y que sea el indicado para adquirir y aplicar nuevos conocimientos a sus tareas.\nDefinir las expectativas con el participante antes del inicio de la capacitación.\nInvolucrarse con la aplicación de los conocimientos nuevos una vez terminada la actividad de formación.\nRealizar un seguimiento de las expectativas fijadas antes de la capacitación.\nProveer recursos necesarios para dar soporte al rendimiento.\n\nOtro dato clave es que, si el conocimiento adquirido durante una capacitación no se aplica dentro de las 6 semanas posteriores a la capacitación, ningún conocimiento adquirido en esa actividad se trasladará al trabajo."
  },
  {
    "objectID": "es/scrap_learning/index.html#recomendaciones",
    "href": "es/scrap_learning/index.html#recomendaciones",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "Medir la información de todos los cursos planificados de la misma manera, usando las mismas herramientas y preguntas. Esto nos brindará consistencia para comparar los resultados y realizar estimaciones más sofisticadas.\nCrear una hoja de cálculo en Excel, o un tablero con métricas con algunas métricas clave: scrap learning, desempeño, e inversión por ejemplo para cada curso.\nCrear una serie de reglas que brinden un marco para el proceso de mejora continuo, por ejemplo:\n\nPara el top 5 de los cursos, no realizar cambios, reinvertir en ellos, continuar desarrollándolos, y si ocurrieran cambios que sean en pos de conseguir una reducción de costos siempre y cuando la calidad no se vea afectada, y de esa manera mejorar el ROI.\nPara el 10% más bajo de los cursos, eliminar cualquier curso que no esté alineado con los objetivos de la empresa. Para aquellos que están alineados con las necesidades de negocio, reinvertir para revisarlos.\nPara el 85% de los cursos que están en el medio, continuar realizándolos, pero buscando opciones que permitan reducir el scrap y maximizar los beneficios."
  },
  {
    "objectID": "es/scrap_learning/index.html#conclusión",
    "href": "es/scrap_learning/index.html#conclusión",
    "title": "Scrap Learning: La Capacitación Desaprovechada",
    "section": "",
    "text": "El Retorno de Inversión (ROI) de una capacitación es una medida compleja de estimar, en cambio, el Scrap Learning es más sencillo de medir y de solucionar.\nMantener un bajo nivel de Scrap Learning, no sólo se materializa en resultados en la organización, sino que además aumenta la confianza sobre el proceso de capacitación generando un “círculo virtuoso” que contribuye a mantenerlo en ese estado.\nÉsta es una métrica poderosa para evaluar la efectividad de las capacitaciones que realizamos dentro de una organización. Como Responsables de Capacitación y Desarrollo, es nuestro deber asegurar la calidad de la capacitación (del instructor, del contenido, y la alineación con necesidades de negocio), pero los jefes juegan un rol clave a la hora de trasladar los conocimientos de la formación al trabajo cotidiano. De esto surge la necesidad de trabajar codo a codo con las áreas para involucrar a sus jefaturas y gerencias, dándoles el soporte necesario para mejorar el impacto de las capacitaciones, mejorar el rendimiento de sus equipos e incrementar sus propios resultados e imagen."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html",
    "href": "es/vino-y-capacitacion/index.html",
    "title": "Gestionar capacitación buscando el mejor vino",
    "section": "",
    "text": "Yo durante mi luna de miel en Finca Adelma.\n\n\nEl objetivo de este post es mostrar cómo se puede aplicar un análisis de un tema cualquiera, a un problema de RRHH.\nLa razón detrás de esta idea es que cuando estamos aprendiendo a usar cualquier programa de análisis de datos, llámese R, Python, Power BI o Excel, encontramos mucho contenido sobre muchos tipos de análisis, pero muy poco contenido relacionado con RRHH. Y eso es algo que podemos hacer por nuestra cuenta.\nCon esto en mente, lo que vamos a hacer es ver cómo podemos aprovechar un análisis en el cual buscamos en qué región de Mendoza podemos hallar los mejores malbecs1, haciendo un ránking de las mejores regiones. Luego veremos cómo ese mismo tipo de análisis lo podemos usar para detectar cuáles son los mejores proveedores de capacitación de una empresa."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#librerías-y-datos",
    "href": "es/vino-y-capacitacion/index.html#librerías-y-datos",
    "title": "Gestionar capacitación buscando el mejor vino",
    "section": "Librerías y datos",
    "text": "Librerías y datos\nVamos a usar varios paquetes dentro de tidyverse y cargamos los datos directamente desde el repositorio de GitHub del proyecto TidyTuesday.\n\n\nVer código\nlibrary(tidyverse)\n\n# Carga de datos\nwine_ratings &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv\")\n\n# Filtramos los datos de la provincia de Mendoza\nwine_ar &lt;- wine_ratings %&gt;% \n  filter(province == \"Mendoza Province\") \n\n\nEl dataset original contiene 129971 filas y 14. Después de filtrar los datos sólo por Mendoza Province nos quedamos con 3264 filas que representan los puntajes que personas expertas le han dado a los vinos. De ahora en más seguiremos trabajando con el dataset wine_ar.\n\n\nVer código\n# Exploremos el contenido del dataset\nglimpse(wine_ar)\n\n\nRows: 3,264\nColumns: 14\n$ ...1                  &lt;dbl&gt; 17, 224, 231, 253, 261, 266, 273, 275, 284, 294,…\n$ country               &lt;chr&gt; \"Argentina\", \"Argentina\", \"Argentina\", \"Argentin…\n$ description           &lt;chr&gt; \"Raw black-cherry aromas are direct and simple b…\n$ designation           &lt;chr&gt; \"Winemaker Selection\", \"Lunta\", NA, \"Reserve\", \"…\n$ points                &lt;dbl&gt; 87, 90, 85, 85, 89, 89, 89, 89, 92, 92, 93, 93, …\n$ price                 &lt;dbl&gt; 13, 22, 10, 15, 37, 14, 19, 30, 215, 30, 42, 55,…\n$ province              &lt;chr&gt; \"Mendoza Province\", \"Mendoza Province\", \"Mendoza…\n$ region_1              &lt;chr&gt; \"Mendoza\", \"Luján de Cuyo\", \"Mendoza\", \"Luján de…\n$ region_2              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ taster_name           &lt;chr&gt; \"Michael Schachner\", \"Michael Schachner\", \"Micha…\n$ taster_twitter_handle &lt;chr&gt; \"@wineschach\", \"@wineschach\", \"@wineschach\", \"@w…\n$ title                 &lt;chr&gt; \"Gaucho Andino 2011 Winemaker Selection Malbec (…\n$ variety               &lt;chr&gt; \"Malbec\", \"Malbec\", \"Bonarda\", \"Malbec\", \"Red Bl…\n$ winery                &lt;chr&gt; \"Gaucho Andino\", \"Mendel\", \"Andean Sky\", \"Cueva …\n\n\nSolo de explorar el dataset se me hace agua la boca. En fin, sigamos…"
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#calcular-puntaje-promedio-de-vinos-por-regiones",
    "href": "es/vino-y-capacitacion/index.html#calcular-puntaje-promedio-de-vinos-por-regiones",
    "title": "Gestionar capacitación buscando el mejor vino",
    "section": "Calcular puntaje promedio de vinos por regiones",
    "text": "Calcular puntaje promedio de vinos por regiones\nEl paso siguiente es filtrar por la cepa Malbec y luego podemos calcular un promedio de los puntajes de la columna points agrupados por la columna region_1 así podemos establecer un ranking de las regiones que tienen los mejores Malbecs de Mendoza.\n\n\nVer código\n# Filtramos por Malbec\nmalbec &lt;- wine_ar %&gt;% \n  filter(variety == \"Malbec\")\n\n# Creamos un ranking de las mejores regiones productoras de Malbec\npromedio_regiones &lt;- malbec %&gt;% \n  filter(!is.na(region_1)) %&gt;%  # Eliminamos filas sin datos\n  group_by(region_1) %&gt;%        # Agrupamos por region\n  summarise(puntaje_promedio = mean(points)) %&gt;% # Calculamos el promedio\n  arrange(desc(puntaje_promedio)) # Ordenamos de mayor a menor\n\n# Ver el resultado\npromedio_regiones\n\n\n# A tibble: 13 × 2\n   region_1         puntaje_promedio\n   &lt;chr&gt;                       &lt;dbl&gt;\n 1 Perdriel                     90.5\n 2 La Consulta                  90.1\n 3 Valle de Uco                 89.5\n 4 Agrelo                       89.3\n 5 Luján de Cuyo                88.8\n 6 Uco Valley                   88.4\n 7 San Carlos                   88.3\n 8 Tupungato                    88.2\n 9 Medrano                      88  \n10 Vista Flores                 87.8\n11 Mendoza                      87.1\n12 Maipú                        87  \n13 Altos de Mendoza             86  \n\n\nDe esta manera descubrimos, para mi sorpresa incluso, que en Perdriel (una localidad dentro de Luján de Cuyo) podemos encontrar los mejores malbecs de la provincia.\nY ahora esto lo podemos visualizar en un gráfico.\n\n\nVer código\nggplot(promedio_regiones, aes(x = puntaje_promedio, \n                              y = reorder(region_1, puntaje_promedio))) + # Ordenamos las regiones por puntaje_promedio\n  geom_col(fill = \"#82163D\") + # Color malbec ;p\n  theme_minimal()  + # Modificamos el estilo del gráfico\n  # Añadimos el título al gráfico y a los ejes\n  labs(title = \"Ranking de regiones de Mendoza con los mejores Malbec\", \n       x = \"Puntaje Promedio\",\n       y = \"Región de Mendoza\") +\n  theme(title = element_text(color = \"#82163D\"),\n        plot.title.position = \"plot\") +\n  # Añadimos el puntaje a cada barra\n  geom_text(aes(label = round(puntaje_promedio,1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) \n\n\n\n\n\n\n\n\n\nVer código\n# Guardamos el gráfico en un archivo png\nggsave(\"output/ranking_regiones.png\", dpi = 300, create.dir = TRUE)\n\n\nAsí podemos ver fácilmente las localidades con los mejores vinos malbec, y podríamos planificar el viaje asegurándonos de visitar las mejores bodegas.\nDespués me agradecen."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#los-datos",
    "href": "es/vino-y-capacitacion/index.html#los-datos",
    "title": "Gestionar capacitación buscando el mejor vino",
    "section": "Los datos",
    "text": "Los datos\nPara realizar este ejercicio, vamos a usar un dataset ficticio, que simula compilar resultados de encuestas de capacitación, e incluye métricas como:\n\nsatisfaction: evalúa en qué medida el curso gustó o no.\nfacilitator_score: puntúa la calidad del facilitador/a de la actividad.\nmaterials_satisfaction: mide la satisfacción con los materiales provistos por el proveedor del curso.\nwilling_recommend: evalúa si recomendaría el curso o no.\narea_goals_alignment: mide en qué porcentaje el curso está alineado con los objetivos del área.\nwork_aplication: en qué medida el contenido del curso se puede trasladar al trabajo.\nscrap_learning: mide cuánto del contenido de la actividad no tiene aplicación en el trabajo (leer más en este artículo).\n\n\n\nVer código\n# Carga de datos\ntraining &lt;- read_delim(\"data/training_ratings.csv\",\n                       delim = \";\")\n\n# Explorar dataset\nglimpse(training)\n\n\nRows: 101\nColumns: 11\n$ id_training            &lt;dbl&gt; 129, 129, 129, 129, 145, 41, 41, 41, 41, 41, 41…\n$ program                &lt;chr&gt; \"5 por qué/ Problem Solving\", \"5 por qué/ Probl…\n$ id_emp                 &lt;dbl&gt; 892, 898, 1499, 1695, 967, 804, 879, 1454, 1455…\n$ satisfaction           &lt;dbl&gt; 8, 7, 2, 5, 6, 10, 5, 9, 8, 4, 2, 8, 6, 10, 8, …\n$ facilitator_score      &lt;dbl&gt; 4, 2, 8, 10, 10, 6, 6, 7, 4, 7, 1, 10, 6, 8, 4,…\n$ materials_satisfaction &lt;dbl&gt; 8, 9, 5, 9, 9, 7, 4, 1, 1, 8, 5, 1, 9, 7, 1, 9,…\n$ willing_reccomend      &lt;dbl&gt; 8, 7, 8, 1, 4, 5, 1, 2, 10, 8, 7, 8, 5, 5, 5, 9…\n$ area_goals_alignment   &lt;dbl&gt; 0.4, 0.5, 0.9, 0.6, 0.4, 0.1, 0.6, 0.5, 0.6, 0.…\n$ work_aplication        &lt;dbl&gt; 1.0, 0.6, 0.4, 0.9, 0.9, 0.1, 0.8, 0.1, 0.3, 0.…\n$ scrap_learning         &lt;dbl&gt; 0.0, 0.4, 0.6, 0.1, 0.1, 0.9, 0.2, 0.9, 0.7, 0.…\n$ supplier               &lt;chr&gt; \"INTERNO\", \"INTERNO\", \"INTERNO\", \"INTERNO\", \"IN…\n\n\nComo podemos apreciar, hay muchas dimensiones en las que nos podemos enfocar para medir la calidad de nuestros proveedores de capacitación. Para este ejercicio vamos a analizar a los proveedores según qué tan alineados están con los objetivos del área.\n¿Por qué vamos a analizar a los proveedores según su alineación con los objetivos?\n\n\n\n\n\n\nParéntesis: Nombres de los proveedores de capacitación\nCasi todos los datos de este dataset son inventados por mí, los puntajes fueron generados aleatoriamente, pero los nombres de los proveedores y de los cursos los saqué de los proveedores y cursos que teníamos en Pilkington de la época que trabajé ahí (2010-2016).\nAsí que para no herir susceptibilidades, ni que se malinterprete la información que vamos a generar, vamos a usar el paquete noah que lo que hace es generar nombres aleatorios para enmascarar los nombres reales, y mostrar un nombre simpático en vez del real.\n\n\n\n\n\n\n\nVer código\n# Cargar la librería\n# install.packages(\"noah\")\nlibrary(noah)\n\n# Crear columna con nombres random\ntraining &lt;- training %&gt;% \n    mutate(pseudo_supplier = pseudonymize(supplier)) \n\n# Guardamos el archivo nuevo\nwrite_delim(training, \"output/training_data_fake_names.csv\", delim = \";\")\n\n# Veamos los nombres nuevos que tienen los proveedores con este cambio\nfake_names &lt;- unique(training$pseudo_supplier)\n\nfake_names\n\n\n [1] \"Overt Asp\"           \"Waggish Cow\"         \"Hulking Vaquita\"    \n [4] \"Familiar Wildcat\"    \"Famous Xerinae\"      \"Half Newt\"          \n [7] \"Fantastic Jacana\"    \"Jaded Dhole\"         \"Lonely Woodpecker\"  \n[10] \"Known Swordtail\"     \"Placid Guppy\"        \"Mammoth Heron\"      \n[13] \"Scarce Koi\"          \"Bad Flyingfish\"      \"Inquisitive Octopus\"\n[16] \"Furtive Jaguar\"     \n\n\n¿Quién no querría hacer un curso en Overt Asp? 😁\nCierro paréntesis."
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#calcular-proveedores-mejor-alineados-con-los-objetivos-del-área",
    "href": "es/vino-y-capacitacion/index.html#calcular-proveedores-mejor-alineados-con-los-objetivos-del-área",
    "title": "Gestionar capacitación buscando el mejor vino",
    "section": "Calcular proveedores mejor alineados con los objetivos del área",
    "text": "Calcular proveedores mejor alineados con los objetivos del área\nEl siguiente paso es calcular el promedio de alineación con objetivos por cada proveedor. De nuevo, podría ser por cualquier métrica, pero para este artículo elejimos esa.\nComo la idea del análisis es analizar proveedores externos. Vamos a filtrar los cursos dictados internamente, y luego vamos a calcular el promedio de alineación con objetivos para cada proveedor.\n\n\nVer código\n# Crear un dataset de proveedores externos\nexternal_vendors &lt;- training %&gt;% \n  filter(supplier != \"INTERNO\") # Elimina las filas de cursos internos\n\n# Calculamos el puntaje promedio de alineación para cada proveedor\nvendor_alignment_score &lt;-  external_vendors %&gt;% \n  group_by(pseudo_supplier) %&gt;% \n  summarise(puntaje_promedio = mean(area_goals_alignment)) %&gt;%\n  arrange(desc(puntaje_promedio))\n\n# Veamos el ranking\nvendor_alignment_score\n\n\n# A tibble: 15 × 2\n   pseudo_supplier     puntaje_promedio\n   &lt;chr&gt;                          &lt;dbl&gt;\n 1 Waggish Cow                    0.833\n 2 Placid Guppy                   0.7  \n 3 Scarce Koi                     0.7  \n 4 Hulking Vaquita                0.633\n 5 Furtive Jaguar                 0.614\n 6 Familiar Wildcat               0.6  \n 7 Fantastic Jacana               0.6  \n 8 Famous Xerinae                 0.583\n 9 Inquisitive Octopus            0.575\n10 Lonely Woodpecker              0.562\n11 Bad Flyingfish                 0.5  \n12 Half Newt                      0.433\n13 Mammoth Heron                  0.4  \n14 Jaded Dhole                    0.375\n15 Known Swordtail                0.3  \n\n\nDe esta manera podemos ver que Waggish Cow es el mejor proveedor con un puntaje de 83.3% y que el peor proveedor es Known Swordtail.\nCon estos datos podemos hacer un gráfico de la misma manera que lo hicimos con el gráfico de vinos.\n\n\nVer código\nggplot(vendor_alignment_score, aes(x = puntaje_promedio, \n                              y = reorder(pseudo_supplier, puntaje_promedio))) + # Ordenamos los vendors por puntaje_promedio\n  geom_col(fill = \"#103F79\") +\n  theme_minimal()  + # Modificamos el estilo del gráfico\n  # Añadimos el título al gráfico y a los ejes\n  labs(title = \"Ranking de proveedores de capacitación\",\n       subtitle = \"Ordenados por Alineación con Objetivos del Área\",\n       x = \"Puntaje Promedio\",\n       y = \"Vendor\",\n       caption = \"Datos generados aleatoriamente\") +\n  theme(title = element_text(color = \"#103F79\"),\n        plot.title.position = \"plot\") +\n  # Añadimos el puntaje a cada barra\n  geom_text(aes(label = scales::percent(puntaje_promedio,\n                                        accuracy = 0.1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1))\n\n\n\n\n\n\n\n\n\nVer código\n# Guardamos el gráfico en un archivo png\nggsave(\"output/ranking_proveedores_basico.png\", dpi = 300, create.dir = TRUE)\n\n\nIncluso podemos ir un paso más allá y agregar una línea que nos indique el target de alineación mínimo. De esta manera podremos saber qué proveedores debemos mantener sí o sí independiemente del costo, y cuáles son los vendors que tenemos que reemplazar.\n\n\nVer código\nggplot(vendor_alignment_score, aes(x = puntaje_promedio, \n                              y = reorder(pseudo_supplier, puntaje_promedio))) + # Ordenamos los vendors por puntaje_promedio\n  geom_col(fill = \"#103F79\") +\n  theme_minimal()  + # Modificamos el estilo del gráfico\n  # Añadimos el título al gráfico y a los ejes\n  labs(title = \"Ranking de proveedores de capacitación\",\n       subtitle = \"Ordenados por Alineación con Objetivos del Área\",\n       x = \"Puntaje Promedio\",\n       y = \"Vendor\",\n       caption = \"Datos generados aleatoriamente\") +\n  theme(title = element_text(color = \"#103F79\"),\n        plot.title.position = \"plot\") +\n  # Añadimos el puntaje a cada barra\n  geom_text(aes(label = scales::percent(puntaje_promedio,\n                                        accuracy = 0.1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  # Definimos un umbral de 60% con una línea punteada amarilla\n  geom_vline(xintercept = 0.6,\n             color = \"#F3B229\",\n             linetype = 2,\n             linewidth = 1)\n\n\n\n\n\n\n\n\n\nVer código\n# Guardamos el gráfico en un archivo png\nggsave(\"output/ranking_proveedores.png\", dpi = 300, create.dir = TRUE)\n\n\nIncluso podríamos asignar colores distintos a los proveedores cuyo puntaje sea inferior al 40% para indicar de esa manera qué proveedores deberían ser reemplazados.\n\n\nVer código\n# Guardemos el gráfico en un objeto para simplificar la lectura\np &lt;- ggplot(vendor_alignment_score, aes(x = puntaje_promedio, \n                              y = reorder(pseudo_supplier, puntaje_promedio))) + \n  # Definimos los cortes en función del puntaje promedio\n  geom_col(aes(fill = cut(puntaje_promedio,\n                           c(-Inf,0.4, Inf)))) \n# Los valores van de menos infinito, a 0.4, y luego hasta el infinito\n\n# Veamos este paso\np\n\n\n\n\n\n\n\n\n\nVer código\n# Ahora asignemos el color en función de los valores de puntaje_promedio\n# Si el valor es mayor a 0.4 (40%) entonces el color es azul.\n# Si el valor es menor a 0.4, entonces el color de la barra será naranja.\np &lt;- p +\n  scale_fill_manual(values = c(\"(-Inf,0.4]\" = \"#F7B234\",\n                               \"(0.4, Inf]\" = \"#103F79\"),\n                    labels = c(\"Reemplazar\", \"Mantener\")\n                    )\n# Veamos como queda hasta ahora\np\n\n\n\n\n\n\n\n\n\nVer código\n# Gráfico final con todos los lujos\np +\n  # Añadimos el título al gráfico y a los ejes\n  labs(title = \"Ranking de proveedores de capacitación\",\n       subtitle = \"Ordenados por Alineación con Objetivos del Área\",\n       x = \"Puntaje Promedio\",\n       y = \"Vendor\",\n       caption = \"Datos generados aleatoriamente\",\n       fill = \"Acción\") +\n  # Añadimos el puntaje a cada barra\n  geom_text(aes(label = scales::percent(puntaje_promedio,\n                                        accuracy = 0.1)),\n            size = 2.5,\n            color = \"white\",\n            hjust = 1.2) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  # Definimos un umbral de 60% con una línea punteada amarilla\n  geom_vline(xintercept = 0.6,\n             color = \"#F3B229\",\n             linetype = 2,\n             linewidth = 1) +\n  theme_minimal() +  # Modificamos el estilo del gráfico\n  guides(fill = guide_legend(reverse=TRUE)) +\n  theme(title = element_text(color = \"#103F79\"),\n        plot.title.position = \"plot\",\n        legend.position = \"top\") \n\n\n\n\n\n\n\n\n\nVer código\nggsave(\"output/ranking_proveedores_final.png\")"
  },
  {
    "objectID": "es/vino-y-capacitacion/index.html#footnotes",
    "href": "es/vino-y-capacitacion/index.html#footnotes",
    "title": "Gestionar capacitación buscando el mejor vino",
    "section": "Notas",
    "text": "Notas\n\n\nMendoza es la provincia más importante en producción de vinos de Argentina, y la cepa más representativa del país es el malbec.↩︎"
  }
]